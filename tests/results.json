[[{"Document Type and Number:\n\n":{"Abstract":"Cheng, Yu-ting (Hefei, CN)","Application Number":"03/14/2023","Assignee":"G11C29/00; G11C29/50","Attorney, Agent or Firm":"CROSS-REFERENCE TO RELATED APPLICATIONSThe present application is a continuation application of International Patent Application No. PCT/CN2021/114124, titled \u201cTEST METHOD AND TEST APPARATUS FOR SEMICONDUCTOR DEVICE\u201d and filed on Aug. 23, 2021, which claims the priority to Chinese Patent Application No. 202110773197.2, titled \u201cTEST METHOD AND TEST APPARATUS FOR SEMICONDUCTOR DEVICE\u201d and filed on Jul. 8, 2021. The entire contents of International Patent Application No. PCT/CN2021/114124 and Chinese Patent Application No. 202110773197.2 are incorporated herein by reference.","Claims":"TECHNICAL FIELDThe present disclosure relates to the technical field of semiconductors, and specifically, to a test method and a test apparatus for a semiconductor device.BACKGROUNDA dynamic random access memory (DRAM) includes a plurality of memory cells for storing data, and each memory cell may include a transistor and a capacitor. The transistor is used as a control gate through which data flows into or flows out of the memory cell, and the capacitor is used to store data in the form of an electrical charge. However, an initial charge stored in the capacitor of each memory cell may gradually disappear due to current leakage in the typical PN junction of the MOS transistor, resulting in the loss of data. Such a memory cell is referred to as a variable retention time (VRT) memory cell.In general, storage devices have different process variables and different characteristics during the package process. For example, during the package process, some storage regions of a storage device or a memory may be exposed to high temperatures, while others may be exposed to low temperatures. Such variables have a great impact on the possibility of the VRT error in the storage devices, and the VRT errors may occur at different ratios in the storage devices.Therefore, it is necessary to accurately determine VRT memory cells in the storage device.It should be noted that information disclosed in the above background section is used merely for a better understanding of the background of the present disclosure, and therefore may include information that does not constitute the prior art known to those of ordinary skill in the art.SUMMARYAccording to a first aspect of the present disclosure, a test method for a semiconductor device is provided. The test method includes:presetting a first retention time range and a first step size;forming a plurality of test values based on the first retention time range and the first step size, and sequentially testing a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data;presetting a second retention time range and a second step size;forming a plurality of test values based on the second retention time range and the second step size, and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; anddetermining, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.According to another aspect of the present disclosure, a test apparatus for a semiconductor device is provided. The test apparatus includes:one or more processors; anda storage apparatus, configured to store one or more programs, wherein the one or more programs, when executed by the one or more processors, cause the one or more processors to execute operations of:presetting a first retention time range and a first step size, and presetting a second retention time range and a second step size;forming a plurality of test values based on the first retention time range and the first step size, and sequentially testing a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data;forming a plurality of test values based on the second retention time range and the second step size, and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; anddetermining, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.According to a third aspect of the present disclosure, a computer-readable storage medium is provided. The computer-readable storage medium has computer programs stored thereon, the programs, when executed by a processor, implement any test method for a semiconductor device described above.BRIEF DESCRIPTION OF THE DRAWINGSThe accompanying drawings, which are incorporated into and constitute a part of the description, illustrate the embodiments of the present disclosure and together with the description, serve to explain the principles of the present disclosure. Apparently, the accompanying drawings in the following description show merely some embodiments of the present disclosure, and persons of ordinary skill in the art may still derive other drawings from these accompanying drawings without creative efforts.FIG. 1 is a flowchart of a test method for a semiconductor device according to an embodiment of the present disclosure;FIG. 2 is a flowchart of a test method for a semiconductor device according to another embodiment of the present disclosure;FIG. 3 is a schematic diagram of a test apparatus for a semiconductor device according to an embodiment of the present disclosure; andFIG. 4 is a block diagram of a test apparatus for a semiconductor device according to an embodiment of the present disclosure.DETAILED DESCRIPTIONExemplary implementations are described below more comprehensively with reference to the accompanying drawings. However, the exemplary implementations can be implemented in various forms and should not be construed as being limited to examples described herein. On the contrary, these implementations are provided such that the present disclosure is more comprehensive and complete, and fully conveys the concept of the exemplary implementations to those skilled in the art.Moreover, the described features, structures, or characteristics may be incorporated into one or more implementations in any suitable manner. In the following description, many specific details are provided to give a full understanding of the embodiments of the present disclosure. However, those skilled in the art will be aware that the technical solutions of the present disclosure may be practiced with one or more of the specific details omitted, or other methods, components, apparatuses, steps, and the like may be used. In other instances, well-known methods, apparatuses, implementations, or operations are not shown or described in detail to avoid obscuring aspects of the present disclosure.Some of the block diagrams shown in the accompanying drawings are functional entities, and do not necessarily correspond to physically independent entities. That is, these functional entities may be implemented in the form of software, or implemented in one or more hardware modules or integrated circuits, or implemented in different networks and/or processor apparatuses and/or microcontroller apparatuses.The flowcharts shown in the accompanying drawings are merely examples, and neither have to include all the content and operations/steps, nor have to be performed in the order described. For example, some operations/steps may further be decomposed, while some operations/steps may be combined or partially combined, such that an actual execution order may change with an actual situation.The inventors have found that currently, there are three types of test retention times, and main methods for screening out memory cells with a short retention time are as follows:First, whether a retention time of a memory cell passes a specific retention time is determined. For example, if the specific retention time is 64 ms, the retention time passes if it is greater than 64 ms, or does not pass if it is less than 64 ms. The shortcomings of this test method are: The test results are different during later tests, the correlation is poor, and the test results are not accurate. Because the VRT phenomenon itself is changing, accurate results cannot be obtained through one test.Second, whether a retention time of a memory cell passes a specific retention time is determined for many times. It is considered that the memory cell does not pass the specific value if it fails to pass the specific value once. This test method is time consuming, and the useful information that can be obtained is very small.Third, tests are performed in ascending order or descending order of the retention times. For example, whether a retention time passes 16 ms, 24 ms, 32 ms, and 40 ms is sequentially determined. It is considered that the retention time fails to pass when it stays at a retention time. For example, if it passes 24 ms but fails 32 ms, it is considered that the retention time passed by this memory cell is 24 ms. This method is time consuming, and a minimum retention time cannot be determined due to the presence of test noises and the VRT phenomenon.In addition, the prior art has the following disadvantage: It is difficult to acquire position information of the failure memory cell. Different memory cells have different amounts of test data, for example, in the methods 2 and 3, a lot of data is tested or obtained data about the retention time changes (i.e., is inaccurate). Consequently, position information of the failure memory cell cannot be acquired accurately.Due to the presence of VRT, the test noise increases and high requirements are imposed on the temperature. Therefore, how to accurately test and screen out the failure memory cells is critical. In view of the foregoing technical problems, an embodiment of the present disclosure first provides a test method for a semiconductor device. As shown in FIG. 1, the test method includes:Step S100: Preset a first retention time range and a first step size.Step S200: Form a plurality of test values based on the first retention time range and the first step size, and sequentially test a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data.Step S300: Preset a second retention time range and a second step size.Step S400: Form a plurality of test values based on the second retention time range and the second step size, and sequentially test the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data.Step S500: Determine, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.In the test method for a semiconductor device provided in the present disclosure, a plurality of test values are formed based on a first retention time range and a first step size, and a plurality of memory cells in the semiconductor device are sequentially tested based on the plurality of test values in ascending order; during tests corresponding to each test value, a memory cell whose retention time is less than the test value is determined, and a position and corresponding test value of the memory cell whose retention time is less than the test value are recorded, to form first test data; a plurality of test values are formed based on a second retention time range and a second step size, and the plurality of memory cells in the semiconductor device are sequentially tested based on the plurality of test values in descending order; during tests corresponding to each test value, a memory cell whose retention time is less than the test value is determined, and a position and corresponding test value of the memory cell whose retention time is less than the test value is recorded, to form second test data; and positions and corresponding test values of memory cells whose retention times fail to pass the tests are determined based on the first test data and the second test data. In this way, performing tests in ascending order or descending order of the test values is integrated with VRT cycles, the minimum retention time of the memory cell can be effectively and accurately tested, and the position information of the failure memory cells is effectively recorded without damaging the test memory; the efficiency and accuracy of testing the retention times are improved; and only the most useful position information is stored, such that the memory usage may be reduced to the greatest extent. The method can be used for wafer test and aging test stages (post-packaged RDBI aging test).The steps in the test method for a semiconductor device provided in the present disclosure are described below in detail.In step S100, the first retention time range and the first step size are preset.Specifically, the retention time of the memory cell is affected by the temperature, the manufacturing process, the test method, or other unknown causes. Because the test temperature range is large and different test temperatures lead to different retention times, and the test machine itself has restrictions on the number of tests, a range and step size are first roughly estimated.The machine has restrictions on the number of tests, for example, 32 test values are limited for the aging test, and 64 test values are limited for the wafer test. Fewer test values lead to inaccurate retention time, while too many test values exceed the number of tests limited by the machine. Therefore, through optimization, the retention time range and the step size may be close to the number of tests limited by the machine, that is, the test accuracy is relatively high, but also can cover the entire retention time range.Accordingly, first, a retention time range and a step size may be roughly estimated, and then tests are performed at a plurality of ambient temperatures. The plurality of memory cells in the semiconductor device that use the retention time and step size are tested based on the roughly estimated retention time range and step size, to obtain test data. The roughly estimated retention time range and step size are optimized based on the test data, to obtain the optimized preset first retention time range and first step size.In step S200, the plurality of test values are formed based on the first retention time range and the first step size, and the plurality of memory cells in the semiconductor device are sequentially tested based on the plurality of test values in ascending order; during the tests corresponding to each test value, the memory cell whose retention time is less than the test value is determined, and the position and corresponding test value of the memory cell whose retention time is less than the test value are recorded, to form the first test data.Specifically, the plurality of test values are formed based on the first retention time range and the first step size; then each test value is selected in ascending order to test the plurality of memory cells in the semiconductor device.During the tests corresponding to each test value, whether the retention time of each of the plurality of memory cells in the semiconductor device is greater than or equal to the test value is determined.If the retention time of the memory cell is greater than or equal to the test value, whether the test value is less than a maximum value of the first retention time range is determined.If the retention time of the memory cell is less than the test value, the test value that the memory cell fails to pass and position information of the memory cell are output.If the test value is less than the maximum value of the first retention time range, a next test value is selected in ascending order of the test values, and whether retention times of the plurality of memory cells in the semiconductor device pass the test value is tested based on the selected next test value.The first test data is formed based on the corresponding test values and position information of the memory cells output in the tests corresponding to all the test values, that is, the corresponding test values and position information of the memory cells that fail to pass the test values are recorded. Only the memory cells that fail to pass the test values are recorded in the first test data. Only the most useful position information is stored, such that the memory usage is reduced to the greatest extent.In step S300, the second retention time range and the second step size are preset.Specifically, first, a retention time range and a step size may be roughly estimated, and then tests are performed at a plurality of ambient temperatures. The plurality of memory cells in the semiconductor device that use the retention time and step size are tested based on the roughly estimated retention time range and step size, to obtain test data. The roughly estimated retention time range and step size are optimized based on the test data, to obtain the optimized preset second retention time range and second step size.The first retention time range may be the same as the second retention time range, and the first step size may be the same as the second step size. That is, the first retention time range and the first step size may be directly used as the second retention time range and the second step size.In step S400, the plurality of test values are formed based on the second retention time range and the second step size, and the plurality of memory cells in the semiconductor device are sequentially tested based on the plurality of test values in descending order; during the tests corresponding to each test value, the memory cell whose retention time is less than the test value is determined, and the position and corresponding test value of the memory cell whose retention time is less than the test value are recorded, to form the second test data.Specifically, the plurality of test values are formed based on the second retention time range and the second step size; then each test value is selected in descending order of the plurality of test values to test the plurality of memory cells in the semiconductor device.During the tests corresponding to each test value, whether the retention time of each of the plurality of memory cells in the semiconductor device is greater than or equal to the test value is determined.If the retention time of the memory cell is greater than or equal to the test value, whether the test value is less than or equal to a minimum value of the second retention time range is determined.If the retention time of the memory cell is less than the test value, the test value that the memory cell fails to pass and position information of the memory cell are output.If the test value is greater than the minimum value of the second retention time range, a next test value is selected in descending order of the test values, and whether retention times of the plurality of memory cells in the semiconductor device pass the test value is tested based on the selected next test value.If the test value is less than or equal to the minimum value of the second retention time range, the test may be ended.The second test data is formed based on the corresponding test values and position information of the memory cells output in the tests corresponding to all the test values, that is, the corresponding test values and position information of the memory cells that fail to pass the test values are recorded. Only the memory cells that fail to pass the test values are recorded in the second test data. Only the most useful position information is stored, such that the memory usage is reduced to the greatest extent.In an embodiment of the present disclosure, as shown in FIG. 2, step S400 may be performed after the test process in step S200 is completed, to be specific, the plurality of memory cells in the semiconductor device are first sequentially tested in ascending order of the plurality of test values, and then are sequentially tested in descending order of the plurality of test values. This adds an interaction verification process.Specifically, if the test value is greater than or equal to the maximum value of the first retention time range, whether the test value is less than or equal to the minimum value of the second retention time range is determined.If the test value is greater than the minimum value of the second retention time range, step S400 is performed, to be specific, each test value is selected in descending order of the plurality of test values to test the plurality of memory cells in the semiconductor device.In another embodiment of the present disclosure, step S200 may be performed after the test process in step S400 is completed, to be specific, the plurality of memory cells in the semiconductor device are first sequentially tested in descending order of the plurality of test values, and then are sequentially tested in ascending order of the plurality of test values. This adds an interaction verification process.Specifically, if the test value is less than or equal to the minimum value of the second retention time range, whether the test value is greater than or equal to the maximum value of the first retention time range is determined.If the test value is less than the maximum value of the first retention time range, step S200 is performed, to be specific, each test value is selected in ascending order of the plurality of test values to test the plurality of memory cells in the semiconductor device.In step S500, positions and corresponding test values of memory cells whose retention times fail to pass the tests are determined based on the first test data and the second test data.Specifically, the position and corresponding test value of the memory cell that fails to pass the retention time may be determined based on the first test data, and the position and corresponding test value of the memory cell that fails to pass the retention time may be determined based on the second test data; and a union of the memory cells that are determined based on the first test data and the second test data and whose retention times fail to pass the tests is calculated and used as a test result.In another embodiment of the present disclosure, the test method further includes:determining the number of tests, where each time a test is performed based on a test value, one test is recorded;determining whether the number of tests reaches a maximum value before sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; and determining whether the number of tests reaches the number of tests limited by the machine; andif no, continuing the test; orif yes, ending the test.The first step size and the second step size are preset based on the number of tests. Fewer test values lead to inaccurate retention time, while too many test values exceed the number of tests limited by the machine. Therefore, through optimization based on the number of tests limited by the machine, the first step size and the second step size may be close to the number of tests limited by the machine, that is, the test accuracy is relatively high, but also can cover the entire retention time range.An apparatus embodiment of the present disclosure is described below, which can be used to perform the test method for a semiconductor device of the present disclosure.An embodiment of the present disclosure further provides a test apparatus for a semiconductor device. As shown in FIG. 3, the test apparatus 900 includes:a parameter preset module 910, configured to: preset a first retention time range and a first step size, and preset a second retention time range and a second step size;a first test module 920, connected to the parameter preset module 910, where the first test module 920 is configured to: form a plurality of test values based on the first retention time range and the first step size, and sequentially test a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data;a second test module 930, connected to the parameter preset module 910 and the first test module 920, where the second test module 930 is configured to: form a plurality of test values based on the second retention time range and the second step size, and sequentially test the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; andan output module 940, connected to the first test module 920 and the second test module 930, where the output module 940 is configured to determine, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.According to the test apparatus for a semiconductor device provided in the present disclosure, the parameter preset module presets a first retention time range and a first step size, and presets a second retention time range and a second step size; the first test module forms a plurality of test values based on the first retention time range and the first step size, and sequentially tests a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determines, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and records a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data; the second test module forms a plurality of test values based on the second retention time range and the second step size, and sequentially tests the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determines, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and records a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; and the output module determines, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests. In this way, performing tests in ascending order or descending order of the test values is integrated with VRT cycles, the minimum retention time of the memory cell can be effectively and accurately tested, and the position information of the failure memory cells is effectively recorded without damaging the test memory; the efficiency and accuracy of testing the retention times are improved; and only the most useful position information is stored, such that the memory usage may be reduced to the greatest extent. The method can be used for wafer test and aging test stages (post-packaged RDBI aging test).Since the functional modules of the test apparatus for a semiconductor device in the example embodiment of the present disclosure correspond to the step sizes of the example embodiment of the test method for a semiconductor device, for the details not disclosed in the apparatus embodiment of the present disclosure, refer to the embodiment of the test method for a semiconductor device of the present disclosure.An exemplary embodiment of the present disclosure provides an apparatus for testing semiconductor devices. Referring to FIG. 4, the apparatus for testing semiconductor devices 400 may be provided as a terminal device. The apparatus for testing semiconductor devices 400 may include a processor 401, and one or more processors may be set as required. The apparatus for testing semiconductor devices 400 may further include a memory 402 configured to store an executable instruction, such as an application program, of the processor 401. One or more memories may be set as required. The memory may store one or more application programs. The processor 401 is configured to execute the instruction to perform the foregoing method.Persons skilled in the art should understand that the embodiments of the present disclosure may be provided as a method, an apparatus (device), or a computer program product. Therefore, the present disclosure may use a form of hardware only examples, software only examples, or examples with a combination of software and hardware. Moreover, the present disclosure may be in a form of a computer program product that is implemented on one or more computer-usable storage media that include computer-usable program code. The computer storage media include volatile and non-volatile, removable and non-removable media implemented in any method or technology for storing information (such as computer-readable instructions, data structures, program modules, or other data), including but not limited to, a RAM, a ROM, an EEPROM, a flash memory or other storage technologies, a CD-ROM, a digital versatile disk (DVD) or other optical disc storage, a magnetic cassette, a magnetic tape, magnetic disk storage or other magnetic storage apparatuses, or any other medium that can be used to store desired information and can be accessed by a computer. In addition, as is well known to persons of ordinary skill in the art, the communication media usually contain computer-readable instructions, data structures, program modules, or other data in modulated data signals such as carrier waves or other transmission mechanisms, and may include any information transfer medium.In an exemplary embodiment, a non-transitory computer-readable storage medium including instructions is provided. Referring to FIG. 4, for example, the non-transitory computer-readable storage medium may be the memory 402 including instructions. The foregoing instructions may be executed by the processor 401 of the apparatus for testing semiconductor devices 400 to complete the foregoing method. For example, the non-transitory computer-readable storage medium may be a ROM, a RAM, a CD-ROM, a magnetic tape, a floppy disk, an optical data storage device, or the like.The present disclosure is described with reference to the flowcharts and/or block diagrams of the method, the apparatus (device), and the computer program product according to the embodiments of the present disclosure. It should be understood that computer program instructions may be used to implement each process and/or each block in the flowcharts and/or the block diagrams and a combination of a process and/or a block in the flowcharts and/or the block diagrams. These computer program instructions may be provided for a general-purpose computer, a dedicated computer, an embedded processor, or a processor of any other programmable data processing device to generate a machine, such that the instructions executed by a computer or a processor of any other programmable data processing device generate an apparatus for implementing a specific function in one or more processes in the flowcharts and/or in one or more blocks in the block diagrams.These computer program instructions may also be stored in a computer readable memory that can instruct the computer or any other programmable data processing device to work in a specific manner, such that the instructions stored in the computer readable memory generate an artifact that includes an instruction apparatus. The instruction apparatus implements a specific function in one or more processes in the flowcharts and/or in one or more blocks in the block diagrams.These computer program instructions may also be loaded onto a computer or another programmable data processing device, such that a series of operations and steps are performed on the computer or another programmable device, thereby generating computer-implemented processing. Therefore, the instructions executed on the computer or another programmable device provide steps for implementing a function specified in one or more processes in the flowcharts and/or in one or more blocks in the block diagrams.It should be noted that although several modules or units of the apparatus for action execution are mentioned in detail above, this division is not mandatory. In fact, according to the embodiments of the present disclosure, the features and functions of two or more modules or units described above may be embodied in one module or unit. Conversely, the features and functions of one module or unit described above may be further divided into a plurality of modules or units.Through the foregoing description of the embodiments, persons skilled in the art may easily understand that the exemplary embodiments described herein may be implemented by software, or may be implemented by software in combination with necessary hardware. Therefore, the technical solutions according to the embodiments of the present disclosure may be implemented in a form of a software product. The software product may be stored in a non-volatile storage medium or network, and includes a plurality of instructions to cause a computing device (which may be a personal computer, a server, a touch terminal, a network device, or the like) to perform the method according to the embodiments of the present disclosure.Those skilled in the art may easily figure out other implementations of the present disclosure after considering the specification and practicing the content disclosed herein. The present disclosure is intended to cover any variations, purposes or adaptive changes of the present disclosure. Such variations, purposes or applicable changes follow the general principle of the present disclosure and include common knowledge or conventional technical means in the technical field which is not disclosed in the present disclosure. The specification and embodiments are merely considered as illustrative, and the real scope and spirit of the present disclosure are pointed out by the appended claims.It should be noted that, the present disclosure is not limited to the precise structures that have been described above and shown in the accompanying drawings, and can be modified and changed in many ways without departing from the scope of the present disclosure. The scope of the present disclosure is defined by the appended claims.","Document Type and Number":"The present disclosure provides a test method and a test apparatus for a semiconductor device. The test method includes: forming a plurality of test values based on a first retention time range and a first step size, and sequentially testing a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data; a similar method is applied to form second test data; and determining, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.","Export Citation":"CHANGXIN MEMORY TECHNOLOGIES, INC. (Hefei, CN)","Filing Date":"Download PDF 11605443","Foreign References":"International Search Report and English Translation cited in PCT/CN2021/114124 dated Apr. 6, 2022, 15 pages.","International Classes":"20150279485ADVANCED MEMORY TEST DIAGNOSTICS2015-10-01Weksler714/7209099203Method for testing retention characteristics of semiconductor device having a volatile device cell and semiconductor test apparatus2015-08-04Kim et al.7450458Dynamic random access memories and method for testing performance of the same2008-11-11Mori365/20120060203590Dynamic random access memories and method for testing performance of the same2006-09-14Mori et al.20030156453Integrated memory and method for operating an integrated memory2003-08-21Pochmuller6272588Method and apparatus for verifying and characterizing data retention time in a DRAM using built-in test circuitry2001-08-07Johnston365/201","Inventors":"17/648206","Other References":"TU, CHRISTINE TRINH LE","Parent Case Data":"The invention claimed is:1.A test method for a semiconductor device, comprising: presetting a first retention time range and a first step size; forming a plurality of test values based on the first retention time range and the first step size, and sequentially testing a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data; presetting a second retention time range and a second step size; forming a plurality of test values based on the second retention time range and the second step size, and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; and determining, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.2.The test method according to claim 1, wherein the presetting a first retention time range and a first step size comprises: presetting a retention time, a step size and a plurality of test ambient temperatures; testing, at each of the plurality of test ambient temperatures based on the retention time and the step size, a plurality of memory cells in the semiconductor device that use the retention time and the step size, to obtain test data; and presetting the first retention time range and the first step size based on the test data, the retention time, and the step size.3.The test method according to claim 1, wherein the presetting a second retention time range and a second step size comprises: presetting a retention time, a step size and a plurality of test ambient temperatures; testing, at each of the plurality of test ambient temperatures based on the retention time and the step size, a plurality of memory cells in the semiconductor device that use the retention time and the step size, to obtain test data; and presetting the second retention time range and the second step size based on the test data, the retention time, and the step size.4.The test method according to claim 1, wherein the first retention time range is the same as the second retention time range, and the first step size is the same as the second step size.5.The test method according to claim 1, wherein the forming a plurality of test values based on the first retention time range and the first step size, and sequentially testing a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data comprises: forming the plurality of test values based on the first retention time range and the first step size; sequentially selecting each test value in ascending order of the plurality of test values to test the plurality of memory cells in the semiconductor device; determining, during the tests corresponding to each test value, whether a retention time of each of the plurality of memory cells in the semiconductor device is greater than or equal to the test value; when the retention time of each of the plurality of memory cells is greater than or equal to the test value, determining whether the test value is less than a maximum value of the first retention time range; or when the retention time of each of the plurality of memory cells is not greater than or equal to the test value, outputting a test value and position information of the memory cell; when the test value is less than the maximum value of the first retention time range, sequentially selecting a next test value to test the plurality of memory cells in the semiconductor device based on the selected next test value; and forming the first test data based on test values and position information of memory cells output in tests corresponding to all the test values.6.The test method according to claim 5, wherein the forming a plurality of test values based on the second retention time range and the second step size, and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determining, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and recording a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data comprises: forming the plurality of test values based on the second retention time range and the second step size; sequentially selecting each test value in descending order of the plurality of test values to test the plurality of memory cells in the semiconductor device; determining, during the tests corresponding to each test value, whether a retention time of each of the plurality of memory cells in the semiconductor device is greater than or equal to the test value; when the retention time of each of the plurality of memory cells is greater than or equal to the test value, determining whether the test value is less than or equal to a minimum value of the second retention time range; or when the retention time of each of the plurality of memory cells is not greater than or equal to the test value, outputting a test value and position information of the memory cell; when the test value is greater than the minimum value of the second retention time range, sequentially selecting a next test value to test the plurality of memory cells in the semiconductor device based on the selected next test value; and forming the second test data based on test values and position information of memory cells output in the tests corresponding to all the test values.7.The test method according to claim 6, wherein the test method further comprises: when the test value is greater than or equal to the maximum value of the first retention time range, determining whether the test value is less than the minimum value of the second retention time range; and when the test value is greater than the minimum value of the second retention time range, sequentially selecting each test value in descending order of the plurality of test values to test the plurality of memory cells in the semiconductor device.8.The test method according to claim 1, wherein the test method further comprises: determining the number of tests; determining whether the number of tests reaches a maximum value before sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order and sequentially testing the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; and when the number of tests has not reached the maximum value, continuing the test; or when the number of tests reaches the maximum value, ending the test.9.The test method according to claim 8, wherein the first step size and the second step size are preset based on the number of tests.10.The test method according to claim 1, wherein the determining, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests comprises: determining, based on the first test data, a position and corresponding test value of a memory cell whose retention time fails to pass the test; determining, based on the second test data, a position and corresponding test value of a memory cell whose retention time fails to pass the test; and calculating a union of the memory cells that are determined based on the first test data and the second test data and whose retention times fail to pass the tests, and using the union as a test result.11.A test apparatus for a semiconductor device, comprising: a parameter preset module, configured to: preset a first retention time range and a first step size, and preset a second retention time range and a second step size; a first test module, connected to the parameter preset module, wherein the first test module is configured to: form a plurality of test values based on the first retention time range and the first step size, and sequentially test a plurality of memory cells in the semiconductor device based on the plurality of test values in ascending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form first test data; a second test module, connected to the parameter preset module and the first test module, wherein the second test module is configured to: form a plurality of test values based on the second retention time range and the second step size, and sequentially test the plurality of memory cells in the semiconductor device based on the plurality of test values in descending order; determine, during tests corresponding to each test value, a memory cell whose retention time is less than the test value, and record a position and corresponding test value of the memory cell whose retention time is less than the test value, to form second test data; and an output module, connected to the first test module and the second test module, wherein the output module is configured to determine, based on the first test data and the second test data, positions and corresponding test values of memory cells whose retention times fail to pass the tests.","Primary Examiner":"Cooper Legal Group , LLC (Hinckley, OH, US)","Publication Date":"01/18/2022","Title":"Test method and test apparatus for semiconductor device","US Patent References":"CN101908382A2010-12-08Data classification analyzing method and device for chip failureCN103811079A2014-05-21\u534a\u5bfc\u4f53\u5668\u4ef6\u7684\u6d4b\u8bd5\u65b9\u6cd5\u548c\u534a\u5bfc\u4f53\u6d4b\u8bd5\u88c5\u7f6eCN112037844A2020-12-04Variable retention time pattern analysis method, device, equipment and readable storage medium","View Patent Images":"Click for automatic bibliographygeneration"},"German Patent DE102005049220":{"Abstract":"The method involves using a heated liquid bath in a test tube (9) and a test rod (11) fed into the test tube. The test rod (11) and test tube are heated to and held at a test temperature, the test object is introduced into the test tube from a storage container (2) then the test rod is applied to the test object. When the tip (12) of the rod touches the bottom of the tube a signal for full dissolution of the test object is triggered and passed to a control and evaluation unit that can indicate full decay of the test object : An independent claim is also included for a device for testing the decay time of solid test specimens in liquids.","Application Number":"DE102005049220","Assignee":"PHARMA TEST APPBAU GMBH (DE)","Attorney, Agent or Firm":"H\u00fcbner Neumann Radwer (Berlin)","Claims":"1. Verfahren zum Feststellen der Zerfallszeit einesfesten Pr\u00fcflings,insbesondere von Tabletten und lipophile Suppositorien, in Fl\u00fcssigkeitenmittels eines beheizbaren Fl\u00fcssigkeitsbadesin einem mit einer Pr\u00fcffl\u00fcssigkeitf\u00fcllbarenPr\u00fcfrohresund eines in dem Pr\u00fcfrohrgef\u00fchrtenPr\u00fcfstabes, dadurchgekennzeichnet, dass das mit der Pr\u00fcffl\u00fcssigkeit bef\u00fcllte Pr\u00fcfrohr unddie Pr\u00fcfst\u00e4be auf Pr\u00fcftemperaturgebracht und bei dieser Temperatur gehalten werden, anschlie\u00dfend derPr\u00fcflingaus einem Depotbeh\u00e4lter indas Pr\u00fcfrohreingelegt wird und danach der Pr\u00fcfstabauf den Pr\u00fcflingaufgesetzt und im Moment des Aufsetzens der Spitze des Pr\u00fcfstabesauf dem Boden des Pr\u00fcfrohresein Signal f\u00fcrdas vollst\u00e4ndigenAufl\u00f6sensdes Pr\u00fcflingsausgel\u00f6stund an eine Steuer- und Auswerteeinheit gegeben wird, die den Zerfalldes Pr\u00fcflingsanzeigt un/oder aus der Zeitspanne zwischen dem Signal aus einemmanuell oder automatisch ausgel\u00f6stenStart des Tests und dem Signal vom Moment des Aufl\u00f6sens desPr\u00fcflingseine Zeitdauer f\u00fcrdessen Zerfall generiert.2. Verfahren nach Anspruch 1, dadurch gekennzeichnet,dass der Start des Tests manuell durch Bet\u00e4tigen einer Taste der Auswerte-und Steuereinheit oder automatisch im Moment des Aufsetzens des Pr\u00fcfstabesauf dem Pr\u00fcflingausgel\u00f6stwird.3. Verfahren nach Anspruch 1, dadurch gekennzeichnet,dass der Start des Tests manuell durch Bet\u00e4tigen einer Taste der Auswerte-und Steuereinheit oder automatisch im Moment der \u00d6ffnung desDepotbeh\u00e4ltersausgel\u00f6stwird.4. Verfahren nach Anspruch 1, dadurch gekennzeichnet,dass das Signal f\u00fcrden Moment des vollst\u00e4ndigenAufl\u00f6sensdes Pr\u00fcflingsdurch \u00dcberbr\u00fccken vonzwei Kontaktstiften durch eine Pr\u00fcfstabmasse am Kopf des Pr\u00fcfstabesausgel\u00f6stwird.5. Verfahren nach Anspruch 1, dadurch gekennzeichnet,dass das Signal f\u00fcrden Moment des vollst\u00e4ndigenAufl\u00f6sensdes Pr\u00fcflingsmittels eines optischen Sensors, einer Lichtschranke oder durcheine Schalterbet\u00e4tigungmittels eines stempelf\u00f6rmigausgebildeten Kopf des Pr\u00fcfstabesausgel\u00f6stwird.6. Vorrichtung zum Testen der Zerfallszeit eines festenPr\u00fcflings,insbesondere von Tabletten und lipophilen Suppositorien, in einerPr\u00fcffl\u00fcssigkeitmit einem Depotbeh\u00e4lter(2) f\u00fcrden Pr\u00fcfling,einem beheizbaren Fl\u00fcssigkeitsbad(1), mindestens einem Pr\u00fcfrohr (9) und einemdarin gef\u00fchrtenPr\u00fcfstab(11) sowie einer Verbindung zu einer Auswerte- und Steuereinheit,dadurch gekennzeichnet, dass an einer Abdeckung des Fl\u00fcssigkeitsbades(1) das in die Fl\u00fcssigkeiteintauchende und mit Pr\u00fcffl\u00fcssigkeitf\u00fcllbare Pr\u00fcfrohr (9)angeordnet ist, an einer Zentriers\u00e4ule (4) der Depotbeh\u00e4lter (2)und ein Pr\u00fcfstabhalter(10) mit dem daran angeordneten Pr\u00fcfstab (11) auf- undabbewegbar angeordnet sind, mit dem Pr\u00fcfstabhalter (10) derPr\u00fcfstab(11) in das Pr\u00fcfrohr(9) einf\u00fchrbar istund ein Signal f\u00fcrden Beginn des Tests manuell durch Bet\u00e4tigen der Auswerte- und Steuereinheit oderautomatisch durch daf\u00fcrvorgesehene Mittel an die Auswerte- und Steuereinheit ausl\u00f6sbar istund im Moment des Aufsetzens einer Pr\u00fcfstabspitze (12) auf demBoden des Pr\u00fcfrohres(9) ein Signal f\u00fcrden Zerfall des Pr\u00fcflingsausl\u00f6sbarist und die Auswerte- und Steuereinheit mit diesem Signal den Zerfalldes Pr\u00fcflingsanzeigt und/oder dessen Zerfallszeit generiert.7. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass ein optischer Sensor, eine Lichtschranke oder ein \u00dcberbr\u00fccken vonKontaktstiften (14) mittels einer am Pr\u00fcfstab (11) angeordneten Pr\u00fcfstabmasse(13) oder ein Bet\u00e4tigeneines Schalters mittels eines stempelf\u00f6rmig ausgebildeten Kopfes desPr\u00fcfstabes(11) das Signal f\u00fcrden Zerfall des Pr\u00fcflingsanzeigt.8. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass die Abdeckung des Fl\u00fcssigkeitsbades(1) aus einem Abdeckungsunterteil (7) und einemAbdeckungsoberteil (8) besteht, wobei ein zwischen demAbdeckungsunerteil (7) und Abdeckungsoberteil (8)angeordneter Niederhalter (16) das Pr\u00fcfrohr (9) in seinerPosition im Fl\u00fcssigkeitsbad(1) h\u00e4lt.9. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass der Depotbeh\u00e4lter(2) und der Pr\u00fcfstabhalter(10) mittels eines Hubmotors oder manuell zusammen odereinzeln auf- und abbewegbar und an der Zentriers\u00e4ule (4) arretierbarsind.10. Vorrichtung nach einem der Anspr\u00fcche 6 oder 9, dadurch gekennzeichnet,dass der Pr\u00fcfstabhalter(10) nach Bet\u00e4tigungeines Arretierbolzens (3) bis auf den Depotbeh\u00e4lter (2)abbewegbar ist.11. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass die L\u00e4ngedes Pr\u00fcfstabes(11) mittels einer Schraube (17) einstellbar ist.12. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass der Depotbeh\u00e4lter(2) mindestens eine mit einer Scheibe (15) verschlie\u00dfbare \u00fcber der \u00d6ffnung desPr\u00fcfrohres(9) angeordnet \u00d6ffnung aufweistund die Scheibe (15) mittels eines Drehknaufes (18)bedienbar ist.13. Vorrichtung nach Anspruch 6, dadurch gekennzeichnet,dass der Start des Tests automatisch durch \u00dcberbr\u00fccken von an dem Kopf des Pr\u00fcfstabes (11)und dem Depotbeh\u00e4lter(2) angeordneten Kontakten zum Zeitpunkt des Aufsetzensder Pr\u00fcfstabspitze(12) auf dem Pr\u00fcflingausl\u00f6sbarist.14. Vorrichtung nach Anspruch 6 und 12, dadurch gekennzeichnet,dass der Start des Tests automatisch bei Bet\u00e4tigung des Drehknaufes (18)zum \u00d6ffnendes Depotbeh\u00e4lters(2) durch \u00dcberbr\u00fccken vonan dem Drehknauf (18) angeordneten Kontakten ausl\u00f6sbar ist.","Description":"DieErfindung betrifft ein Verfahren zum Testen der Zerfallszeit festerPr\u00fcflinge,insbesondere von Tabletten und lipophilen Suppositorien, in Fl\u00fcssigkeitenund eine Vorrichtung zur Durchf\u00fchrungdes Verfahrens.Mitdem Verfahren und der Vorrichtung sollen insbesondere Tablettenund lipophile Suppositorien in ihrem Aufl\u00f6severhalten einem Test unterBedingungen unterzogen werden, wie sie beispielsweise denen im K\u00f6rper desMenschen entsprechen.DerartigeTestger\u00e4tesind seit langem bekannt.Ausdem DE-GM 86 15 404 geht ein Zerfallstestger\u00e4t hervor, das eine Trageeinrichtungmit einem auf- und abbeweglich gelagerten Tr\u00e4ger f\u00fcr ein die zu testenden Bestandteileaufnehmendes Beh\u00e4ltnisund ein Fl\u00fcssigkeitsbadaufweist. In das Fl\u00fcssigkeitsbad tauchtdas Beh\u00e4ltnisein. Das Testger\u00e4tist mit einer durch einen Motor angetriebenen Hubvorrichtung versehen.Diese bewegt den Tr\u00e4germit dem Beh\u00e4ltniszwischen zwei Extremlagen auf und ab. Eine zweite mit dem Tr\u00e4ger gekoppelteHubvorrichtung hebt nach Ablauf einer f\u00fcr den Test vorgegebenen Zeitselbstt\u00e4tigdas Beh\u00e4ltnisaus dem Fl\u00fcssigkeitsbad.Danach kann der Zerfallszustand des Testobjektes visuell festgestelltwerden.Dermit der zweiten Hubvorrichtung verh\u00e4ltnism\u00e4\u00dfig hohe Aufwand soll mit einemZerfallstestger\u00e4treduziert werden, wie es in der DE-OS 38 04 688 offenbart wird.Auch bei diesem Zerfallstestger\u00e4t istdas Ergebnis des Tests von der visuellen Wahrnehmung der das Ger\u00e4t bedienendenPerson abh\u00e4ngig.Beiden auf dem Markt befindlichen Zerfallstestger\u00e4ten des Typs ZT 500 der ERWEKAGmbH k\u00f6nnenLaufzeit- und L\u00f6semediumtemperaturvorgew\u00e4hltwerden. Ein akustisches Signal am Ende der vorgegebenen Testzeiterinnert die Bedienperson, dass der Testkorb aus dem L\u00f6semediumzu entnehmen ist. Der Zerfallsprozess ist bei diesem Ger\u00e4t visuellzu beobachten und manuell zu dokumentieren. Bedien- und Beobachtungsfehlersind bei diesem Ger\u00e4tin der Praxis nicht auszuschlie\u00dfen.Einunter der Typenbezeichnung ZT 300 auf dem Markt befindliches Ger\u00e4t erm\u00f6glicht einautomatisches Senken des Testkorbes bei Beginn des Tests und dessenautomatisches Herausheben bei Erreichen der vorgegebenen Testzeit.Durch visuelle Beobachtung des Zerfallsprozesses und dessen Ergebnissind auch bei diesem Ger\u00e4tsubjektive Fehler nicht auszuschlie\u00dfen.Mitdem unter der Bezeichnung ZT 70 angebotenen Testger\u00e4t kann dieaktuelle Zerfallszeit eines Testobjektes durch ein System, bestehendaus einem Ringmagneten und einem Sensor, bestimmt werden, wobeider Sensor die jeweilige Feldst\u00e4rke unterder jeweiligen Teststation misst.Mitdiesem Ger\u00e4tverbindet sich jedoch das Problem, dass rein technisch betrachtetdas vollst\u00e4ndigeAufl\u00f6sendes Pr\u00fcflingssignalisiert wird, obwohl kleine Teilchen davon noch vorhanden seink\u00f6nnen.Aufgabeder Erfindung ist es daher, ein Verfahren und eine Vorrichtung zumTesten der Zerfallszeit fester Pr\u00fcflinge in Fl\u00fcssigkeitenbereitzustellen, bei dem der Zeitpunkt des vollst\u00e4ndigen Zerfallsdes Pr\u00fcflingsmit hoher Genauigkeit festgestellt werden kann und subjektive Fehlerder bedienenden Person bei der Ermittlung der Zeitdauer des Zerfallsdes Pr\u00fcflingsweitestgehend ausgeschlossen sind.Erfindungsgem\u00e4\u00df wird dieAufgabe durch ein Verfahren mit den Merkmalen des Anspruches 1 gel\u00f6st. VorteilhafteAusgestaltungen des erfindungsgem\u00e4\u00dfen Verfahrens ergeben sichaus den Merkmalen der Anspr\u00fcche2 bis 5.Erfindungsgem\u00e4\u00df wird dieAufgabe des weiteren durch eine Vorrichtung mit den Merkmalen des Anspruches6 gel\u00f6st.Vorteilhafte Ausgestaltungen der erfindungsgem\u00e4\u00dfen Vorrichtung ergeben sich ausden Merkmalen der Anspr\u00fcche7 bis 14.Mitdem erfindungsgem\u00e4\u00dfen Verfahrenund der Vorrichtung verbindet sich der Vorzug, dass der Zeitpunktdes Zerfalls fester Pr\u00fcflingeunter Ausschluss subjektiver Fehler der bedienenden Person mit hoherGenauigkeit festgestellt werden kann. Insbesondere ist es mit derErfindung m\u00f6glich,bei Einhaltung der Vorgaben des Europ\u00e4ischen Arzneibuches bez\u00fcglich derApparatur zur Messung der Erweichungszeit von lipophilen SuppositorienErgebnisse mit hoher Genauigkeit zu erzielen.Imfolgenden soll die Erfindung an Hand von Zeichnungen n\u00e4her erl\u00e4utert werden.Es zeigen:1 dieVorderansicht der Vorrichtung2 dieVorrichtung gem\u00e4\u00df 1 im SchnittA-A3 dieVorrichtung gem\u00e4\u00df 1 teilweise imSchnitt mit Pr\u00fcfst\u00e4ben in denPr\u00fcfrohren.Die 1, 2 und 3 zeigeneine Vorrichtung zum Testen der Zerfallszeit lipophiler Suppositorienin Wasser.Wieaus 1 und 2 ersichtlich ist, besteht dieVorrichtung aus dem Fl\u00fcssigkeitsbeh\u00e4lter 1 mitden aus Glas bestehenden Pr\u00fcfrohren 9,der am Boden des Fl\u00fcssigkeitsbeh\u00e4lters 1 gelagertenZentriers\u00e4ule 4 sowiedem Depotbeh\u00e4lter 2,der mittels des Arretierbolzens 5 an dem Pr\u00fcfstabhalter 10 arretierbarist. Die auf dem Fl\u00fcssigkeitsbeh\u00e4lter 1 angeordneteAbdeckung besteht aus dem Unterteil 7 und dem zentrischgelagerten Oberteil 8. Das Unterteil 7 der Abdeckungdient der Aufnahme der Pr\u00fcfrohre 9, diedurch die zwischen dem Unterteil 7 und dem Oberteil 8 angeordnetenNiederhalter 16 in ihrer Position im Fl\u00fcssigkeitsbeh\u00e4lter 1 gehaltenwerden. Vorzugsweise befinden sich sechs Pr\u00fcfrohre 9 im Fl\u00fcssigkeitsbeh\u00e4lter 1,denen der Depotbeh\u00e4lter 2 f\u00fcr die Zuf\u00fchrung derPr\u00fcflingezugeordnet ist.AmPr\u00fcfstabhalter 10 sinddie f\u00fcrdie einzelnen Pr\u00fcfrohre 9 notwendigenPr\u00fcfst\u00e4be 11 angeordnet.Die 3 zeigt die Pr\u00fcfrohre 9 mitdarin befindlichen Pr\u00fcfst\u00e4ben 11.Im vorliegenden Ausf\u00fchrungsbeispielentspricht die Geometrie der Pr\u00fcfstabspitzen 12 undder Pr\u00fcfrohre 9 derVorschrift des Europ\u00e4ischenArzneibuches f\u00fcrdie Messung des Erweichungspunktes lipophiler Suppositorien in Wasser. DieL\u00e4nge derPr\u00fcfst\u00e4be 11 istmittels der Einstellschraube 17 mit hoher Genauigkeit festlegbar.Die Pr\u00fcfst\u00e4be 11 sind \u00fcber einehier nicht dargestellte elektronische Verbindung mit einer Auswerte-und Steuereinheit verbunden.DerDepotbeh\u00e4lter 2 undder Pr\u00fcfstabhalter 10 sindim vorliegenden Ausf\u00fchrungsbeispielmanuell an der Zentriers\u00e4ule 4 auf-und abbewegbar. Die Vertikalbewegung kann jedoch auch mittels eines Hubmotorserfolgen. Den Pr\u00fcfst\u00e4ben 11 sindzur Ermittlung des Zeitpunktes des Zerfalls des Pr\u00fcflings jeweilszwei Kontaktstifte 14 zugeordnet, die aus dem Pr\u00fcfstabhalter 10 herausragen.DerFl\u00fcssigkeitsbeh\u00e4lter 1 istbeheizbar und zu diesem Zweck mit einem in der Auswerte- und Steuereinheitangeordneten Thermostat \u00fcberdie Stutzen 19 und 20 verbunden.ZumTesten der Zerfallszeit lipophiler Suppositorien wird die L\u00e4nge derPr\u00fcfst\u00e4be 11 anHand der Einstellschraube 17 entsprechend der L\u00e4nge desjeweiligen Suppositoriums so eingestellt, dass genau im Moment desvollst\u00e4ndigenZerfalls des Suppositoriums die Pr\u00fcfstabmasse 13 aufdie beiden Kontaktstifte 14 trifft und diese \u00fcberbr\u00fcckt.F\u00fcr die Durchf\u00fchrung desTests ist der Fl\u00fcssigkeitsbeh\u00e4lter 1 mitWasser gef\u00fcllt.Zun\u00e4chstbefinden sich der Pr\u00fcfstabhalter 10 mitden Pr\u00fcfst\u00e4ben 11 undder Depotbeh\u00e4lter 2 ohnePr\u00fcflingeauf der Zentriers\u00e4ule 4 inder unteren Position. Der Depotbeh\u00e4lter 2 ist mittelsdes Arretierbolzens 5 am Pr\u00fcfstabhalter 10 arretiert.Die Pr\u00fcfst\u00e4be 11 befindensich jeweils in den Pr\u00fcfrohren 9.DiePr\u00fcfrohre 9 mitden dazugeh\u00f6rigenPr\u00fcfst\u00e4ben 11 werdenim Fl\u00fcssigkeitsbeh\u00e4lter 1 aufdie f\u00fcrdas Aufl\u00f6senvon Suppositorien geforderte Pr\u00fcftemperaturgebracht und in dieser gehalten. Nach Einhaltung der daf\u00fcr vorgegebenenZeit wird der Pr\u00fcfstabhalter 10 mittelsdes Bolzens 3 entriegelt und zusammen mit dem Depotbeh\u00e4lter 2 ineiner oberen Position der Zentriers\u00e4ule 4 eingerastet.Die Pr\u00fcfrohre 9 werdenjetzt mit Pr\u00fcffl\u00fcssigkeit,beispielsweise Wasser, bef\u00fcllt.Der Depotbeh\u00e4lter 2 wirdanschlie\u00dfendvom Pr\u00fcfstabhalter 10 durchBet\u00e4tigendes Arretierbolzens 5 entriegelt und nach unter gelassen. Dieau\u00dfenam Boden des Depotbeh\u00e4lters 2 angeordnetenScheiben 15 verschlie\u00dfendie \u00fcberden Pr\u00fcfrohren 9 befindlichen \u00d6ffnungendes Depotbeh\u00e4lters 2.Nach dem Erreichen der Pr\u00fcftemperaturin den Pr\u00fcfrohren 9 werdendie Suppositorien in die Depotbeh\u00e4lter 2 eingelegt undzwar jeweils ein Suppositorium f\u00fcrein Pr\u00fcfrohr 9.Durch Bet\u00e4tigender Scheiben 15 mittels des Drehknaufes 18 werdendie am Boden des Depotbeh\u00e4lters 2 befindlichen \u00d6ffnungenfreigegeben und die Suppositorien fallen in die mit Wasser odereiner anderen Pr\u00fcffl\u00fcssigkeitgef\u00fclltenPr\u00fcfrohre 9.Anschlie\u00dfend wirdder Pr\u00fcfstabhalter 10 durchBet\u00e4tigendes Arretierbolzens 3 von der Zentriers\u00e4ule 4 entriegelt undauf den Depotbeh\u00e4lter 2 aufgesetzt.Die Pr\u00fcfstabspitze 12 sitztnun auf dem oberen Ende des zu testenden Suppositoriums auf. DerStart des Tests wird in diesem Moment manuell durch Bet\u00e4tigen derStarttaste der hier nicht dargestellten Auswerte- und Steuereinheitausgel\u00f6st. Durchdas Eigengewicht des Pr\u00fcfstabes 11 beginnt beider vorgegebenen Temperatur der Zerfallsprozess des Suppositoriums.Der Pr\u00fcfstab 11 rutschtim Pr\u00fcfrohr 9 langsamnach unten. Sobald das Suppositorium vollst\u00e4ndig zerfallen ist, trifftdie Pr\u00fcfstabspitze 12 aufden Boden des Pr\u00fcfrohres 9 auf.In diesem Moment sitzt die Pr\u00fcfstabmasse 13 aufden beiden Kontaktstiften 14 auf und \u00fcberbr\u00fcckt diese. Durch das \u00dcberbr\u00fccken derbeiden Kontaktstifte 14 wird ein elektrisches Signal zurAuswerte- und Steuereinheit geleitet, die f\u00fcr jedes der Pr\u00fcfrohre 9 denZerfall des Suppositoriums anzeigt und die Zerfallszeit generiert.EineAusf\u00fchrungsformder Vorrichtung sieht vor, den Start des Tests automatisch durch \u00dcberbr\u00fccken vonan dem Kopf des Pr\u00fcfstabes 11 unddem Depotbeh\u00e4lter 2 angeordnetenKontakten zum Zeitpunkt des Aufsetzens der Pr\u00fcfstabspitze 12 aufdem Suppositorium auszul\u00f6sen.Nacheiner weiteren Ausf\u00fchrungsformder Vorrichtung kann der Start des Tests auch manuell zum Zeitpunktder Bet\u00e4tigungdes Drehknaufes 18 zum \u00d6ffnendes Depotbeh\u00e4lters 2 oderautomatisch durch \u00dcberbr\u00fccken vonan dem Drehknauf 18 angeordneten Kontakten ausgel\u00f6st werden.DasSignal f\u00fcrdie Auswerte- und Steuereinheit, das den vollst\u00e4ndigen Zerfall des Suppositoriumsanzeigt, kann selbstverst\u00e4ndlichauch noch auf eine andere Weise erzeugt werden, beispielsweise mittelseiner Lichtschranke, eines optischen Sensors oder durch Bet\u00e4tigen einesSchalters mittels eines stempelf\u00f6rmigausgebildeten Kopfes des Pr\u00fcfstabes 11.1Fl\u00fcssigkeitsbad2Depotbeh\u00e4lter3Arretierbolzen4Zentrierstab5Arretierbolzen6Diodenstecker7Abdeckungsunterteil8Abdeckungsoberteil9Pr\u00fcfrohr10Pr\u00fcfstabhalter11Pr\u00fcfstab12Pr\u00fcfstabspitze13Pr\u00fcfstabmasse14Kontaktstifte15Verschlussscheibe16Niederhalter17Einstellschraube18Drehknauf19Stutzen20Stutzen","Domestic Patent References":"DE2409222C1N/ADE2530065A1N/A","Export Citation":"Click for automatic bibliographygeneration","Filing Date":"10/10/2005","International Classes":"G01N13/00 G01N33/15 (IPC1-7): G01N13/00 G01N33/15","Inventors":"FAEHLER FRANZ JUERGEN (DE)","Publication Date":"04/19/2007","Title":"Testing decay time of solid test specimens in liquids involves triggering signal for full dissolution of test object and passing to control and evaluation unit when tip of test rod touches test tube bottom"},"United States Patent 10248552":{"Abstract":"There is provided a computer-implemented method of testing an application. The method obtains first temporary test scripts for testing at least one test case of a first version of the application, and the first temporary test scripts are recorded with first mark data used for testing the first version of the application. The method obtains a first correspondence between the first mark data and test data. The method substitutes the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application.","Application Number":"15/214552","Assignee":"International Business Machines Corporation (Armonk, NY, US)","Attorney, Agent or Firm":"IBM Corporation - Patent Center (Endicott, NY, US)","Claims":"What is claimed is:1.A computer system for testing an application, comprising: at least one processor, a memory coupled to the at least one processor, computer program instructions stored in the memory and executed by the at least one processor, to perform steps of: obtaining first temporary test scripts for testing at least one test case of a first version of the application, the first temporary test scripts being recorded with first mark data used for testing the first version of the application; obtaining a first correspondence between the first mark data and test data; substituting the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application; in response to the first mark data being included in a second mark data, wherein the second mark data is used for testing a second version of the application, obtaining second temporary test scripts for testing at least one test case of the second version of the application, the second temporary test scripts being recorded with the second mark data; obtaining a stored first correspondence; obtaining a second correspondence between increased test data and increased data in the second mark data comparing with the first mark data; and substituting the test data and the increased test data for the second mark data in the second temporary test scripts based on both the first and second correspondences to obtain second test scripts for testing the at least one test case of the second version of the application.2.The computer system of claim 1, wherein the at least one processor executes the computer program instructions to perform steps of: testing the at least one test case of the first version of the application by using the obtained first test scripts.3.The computer system of claim 1, wherein the at least one processor executes the computer program instructions to, in response to a second mark data being included in the first mark data, wherein the second mark data is used for testing a second version of the application, perform steps of: obtaining second temporary test scripts for testing at least one test case of the second version of the application, the second temporary test scripts being recorded with the second mark data; obtaining the stored first correspondence; substituting the test data for the second mark data in the second temporary test scripts based on the first correspondence to obtain second test scripts for testing the at least one test case of the second version of the application.4.The computer system of claim 3, wherein the at least one processor executes the computer program instructions to perform steps of: testing the at least one test case of the second version of the application by using the obtained second test scripts.5.The computer system of claim 1, wherein the at least one processor executes the computer program instructions to perform steps of: testing the at least one test case of the second version of the application by using the obtained second test scripts.6.The computer system of claim 3, wherein both the first and second mark data are sets of data with data type, structure and unique values required by the application.7.A computer program product for testing an application, comprising a computer readable storage medium, the computer readable storage medium storing program instructions thereon, the program instructions executed by at least one processor, causing the at least one processor to: obtain first temporary test scripts for testing at least one test case of a first version of the application, the first temporary test scripts being recorded with first mark data used for testing the first version of the application; obtain a first correspondence between the first mark data and test data; substitute the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application; in response to the first mark data being included in a second mark data, wherein the second mark data is used for testing a second version of the application, obtain second temporary test scripts for testing at least one test case of the second version of the application, the second temporary test scripts being recorded with the second mark data; obtain a stored first correspondence; obtain a second correspondence between increased test data and increased data in the second mark data comparing with the first mark data; and substitute the test data and the increased test data for the second mark data in the second temporary test scripts based on both the first and second correspondences to obtain second test scripts for testing the at least one test case of the second version of the application.8.The computer program product of claim 7, wherein the program instructions, when executed on the processor, cause the processor to: in response to a second mark data being included in the first mark data, wherein the second mark data is used for testing a second version of the application, perform steps of: obtaining second temporary test scripts for testing at least one test case of the second version of the application, the second temporary test scripts being recorded with the second mark data; obtaining the stored first correspondence; substituting the test data for the second mark data in the second temporary test scripts based on the first correspondence to obtain second test scripts for testing the at least one test case of the second version of the application.","Description":"BACKGROUND OF THE INVENTIONThe present disclosure relates to the technical field of software testing, and more particularly, to a method, a computer system, and a computer program product for testing a network-based application.During development of a network-based application (hereinafter referred to as an application), programmers usually use specific test tools, browsers, and other tools to simulate actual scenarios, to test functionality of the application in a network device such as a server and/or a client linked to the server, so as to verify whether the intended functionality can be achieved.SUMMARYAccording to an embodiment of the present disclosure, there is provided a computer-implemented method for testing an application. The method obtains first temporary test scripts for testing at least one test case of a first version of the application, wherein the first temporary test scripts are recorded with first mark data used for testing the first version of the application. The method obtains a first correspondence between the first mark data and test data. The method substitutes the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application.According to another embodiment of the present disclosure, there is provided a computer system for testing an application, comprising: at least one processor, a memory coupled to the at least one processor, computer program instructions stored in the memory and executed by the at least one processor, to perform steps of: obtaining first temporary test scripts for testing at least one test case of a first version of the application, wherein the first temporary test scripts are recorded with first mark data used for testing the first version of the application; obtaining a first correspondence between the first mark data and test data; substituting the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application.According to a further embodiment of the present disclosure, there is provided a computer program product for testing an application, comprising a computer readable storage medium, the computer readable storage medium storing program instructions thereon, the program instructions executed by at least one processor, causing the processor to: obtain first temporary test scripts for testing at least one test case of a first version of the application, wherein the first temporary test scripts are recorded with first mark data used for testing the first version of the application; obtain a first correspondence between the first mark data and test data; substitute the test data for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 shows an exemplary computer system which is applicable to implement at least some of the embodiments of the present disclosure;FIG. 2 is a block diagram depicting a computer system for testing an application according to an embodiment of the present disclosure;FIG. 3 is a flowchart illustrating a computer-implemented method of testing an application according to an embodiment of the present disclosure;FIG. 4 shows a test form displayed on a test device for recording a test script according to an embodiment of the present disclosure;FIG. 5 is a flowchart illustrating a computer-implemented method of testing an application according to another embodiment of the present disclosure;FIG. 6 shows a test form displayed on a test device for recording a test script according to another embodiment of the present disclosure;FIG. 7 is a flowchart illustrating a computer-implemented method of testing an application according to a further embodiment of the present disclosure;FIG. 8 shows a test form displayed on the test device for recording a test script according to a further embodiment of the present disclosure;FIG. 9 is a flow chart depicting a live demonstration of the method and the system for testing the application according to the present disclosure; andFIG. 10 is another flow chart depicting a live demonstration of the method and the system for testing the application according to the present disclosure.DETAILED DESCRIPTIONIt should be noted that references throughout this specification to features, advantages, or similar language herein do not imply that all of the features and advantages that may be realized with the embodiments disclosed herein should be, or are in, any single embodiment of the invention. Rather, language referring to the features and advantages is understood to mean that a specific feature, advantage, or characteristic described in connection with an embodiment is included in at least one embodiment of the present invention. Thus, discussion of the features, advantages, and similar language, throughout this specification may, but do not necessarily, refer to the same embodiment.Furthermore, the described features, advantages, and characteristics of the invention may be combined in any suitable manner in one or more embodiments. One skilled in the relevant art will recognize that the invention may be practiced without one or more of the specific features or advantages of a particular embodiment. In other instances, additional features and advantages may be recognized in certain embodiments that may not be present in all embodiments of the invention.These features and advantages will become more fully apparent from the following drawings, description and appended claims, or may be learned by the practice of the invention as set forth hereinafter.Some preferable embodiments will be described in more detail with reference to the accompanying drawings, in which the preferable embodiments of the present disclosure have been illustrated. However, the present disclosure can be implemented in various manners, and thus should not be construed to be limited to the embodiments disclosed herein. On the contrary, those embodiments are provided for the thorough and complete understanding of the present disclosure, and completely conveying the scope of the present disclosure to those skilled in the art.Referring now to FIG. 1, in which an exemplary computer system/server 12 which is applicable to implement the embodiments of the present invention is shown. Computer system/server 12 is only illustrative and is not intended to suggest any limitation as to the scope of use or functionality of embodiments of the invention described herein.As shown in FIG. 1, computer system/server 12 is shown in the form of a general-purpose computing device. The components of computer system/server 12 may include, but are not limited to, one or more processors or processing units 16, a system memory 28, and a bus 18 that couples various system components including system memory 28 to processor 16.Bus 18 represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus.Computer system/server 12 typically includes a variety of computer system readable media. Such media may be any available media that is accessible by computer system/server 12, and it includes both volatile and non-volatile media, removable and non-removable media.System memory 28 can include computer system readable media in the form of volatile memory, such as random access memory (RAM) 30 and/or cache memory 32. Computer system/server 12 may further include other removable/non-removable, volatile/non-volatile computer system storage media. By way of example only, storage system 34 can be provided for reading from and writing to a non-removable, non-volatile magnetic media (not shown and typically called a \u201chard drive\u201d). Although not shown, a magnetic disk drive for reading from and writing to a removable, non-volatile magnetic disk (e.g., a \u201cfloppy disk\u201d), and an optical disk drive for reading from or writing to a removable, non-volatile optical disk such as a CD-ROM, DVD-ROM or other optical media can be provided. In such instances, each can be connected to bus 18 by one or more data media interfaces. As will be further depicted and described below, memory 28 may include at least one program product having a set (e.g., at least one) of program modules that are configured to carry out the functions of embodiments of the invention.Program/utility 40, having a set (at least one) of program modules 42, may be stored in memory 28 by way of example, and not limitation, as well as an operating system, one or more application programs, other program modules, and program data. Each of the operating system, one or more application programs, other program modules, and program data or some combination thereof, may include an implementation of a networking environment. Program modules 42 generally carry out the functions and/or methodologies of embodiments of the invention as described herein.Computer system/server 12 may also communicate with one or more external devices 14 such as a keyboard, a pointing device, a display 24, etc.; one or more devices that enable a user to interact with computer system/server 12; and/or any devices (e.g., network card, modem, etc.) that enable computer system/server 12 to communicate with one or more other computing devices. Such communication can occur via Input/Output (I/O) interfaces 22. Still yet, computer system/server 12 can communicate with one or more networks such as a local area network (LAN), a general wide area network (WAN), and/or a public network (e.g., the Internet) via network adapter 20. As depicted, network adapter 20 communicates with the other components of computer system/server 12 via bus 18. It should be understood that although not shown, other hardware and/or software components could be used in conjunction with computer system/server 12. Examples, include, but are not limited to: microcode, device drivers, redundant processing units, external disk drive arrays, RAID systems, tape drives, and data archival storage systems, etc.FIG. 2 is a block diagram of a computer system for testing an application according to an embodiment of the present disclosure. The system as shown in the FIG. 2 includes a test device 202, a server device 204, a database 206, a mark database 208, a data extractor 203, and an automatic code generator 205. The test device 202 may be a personal computer (PC), a tablet computer, or any other computing device, which performs a test on a network-based application. The test may be, but not limited to, a HTTP test. A software program (also referred to as performance test tool software, or test tool, or tool software) is run on the test device 202. The software program is for example, but not limited to, the IBM Rational Performance Tester (RPT, a trademark of International Business Machine Corporation (IBM) located in the U.S.A.), Apache JMeter (a Java based test tool developed by Apache Organization), etc.A network-based application to be tested is run on the server device 204. A development engineer can access the server device 204 through a browser executed on the test device 202, and perform a performance-or-stress-related test on the application through the performance test tool software.The database 206 is used for storing various types of data used by the application to be tested. A tested application will use different data types, such as integer, floating point, character string, date, and so on. The database 206 is also used for storing test data. The test data is a simulation of real data that contains different data types, and of amount and distribution of client data.The mark database 208 is used for storing mark data. The mark data is a set of data with data types, structure and unique values required by the application to be tested. The mark data have the same data type with that of the test data. The test data and the mark data are used by test cases pre-built by the development engineer for testing the application executed on the server device 204.The data extractor 203 is used for extracting the data types and structures used for the tested application from data storage locations such as the database 206, and generating the test data and mark data based on the test scenario. For example, the data extractor 203 detects the data type of a character string with a length of 10 bits in the database 206, then it randomly generates a series of test data such as \u201cSTRING0001\u201d, \u201cSTRING0002\u201d, . . . , \u201cSTRING000N\u201d, etc. A special, unique value (the mark data) with the data type of the character string such as, but not limited to, \u201cdirty_data_001\u201d can also be randomly generated. However, the method of the data extractor 203 generating the test data and the mark data is not construed as a limitation on the scope of the disclosure.The generated mark data can be stored in the mark database 208, and the generated test data can be stored in the database 206. According to one embodiment of the present disclosure, the database 206 and the mark database 208 may be combined into a single database. However, the storage location of the test data and the mark data does not limit the scope of the present disclosure. According to one embodiment of the present disclosure, they may be stored as data files in a memory of the test device 202 and/or server device 204, or they may be stored on other data processing devices communicatively connected to the test device 202 and/or the server device 204.The automatic code generator 205 is used for reading temporary test scripts with the mark data, and scanning each part of the temporary test scripts, finding the mark data, and substituting the corresponding test data for the mark data based on the correspondence between the mark data and the test data.The data extractor 203 and the automatic code generator 205 may be computer program modules which are stored in the memory 28 and executed in the processor unit 16 of computer system 12 as shown in FIG. 1, and also may be implemented by dedicated circuit hardware formed by curing a computer program in a general purpose hardware (e.g., processor), and its implementation is not construed as a limitation to the present disclosure.According to one embodiment of the present disclosure, an application to be tested on the server device 204 includes a plurality of test cases 210. Each of the test cases is a test unit. For example, in a certain application, \u201cLog-Query-Exit\u201d is a test case. The test cases according to the embodiment of the present disclosure may comprise a plurality of test cases with logic relationships, and they are executed in order. For example, among three test cases including a first test case of \u201cLog-Insert data-Exit\u201d, a second test case of \u201cLog-Data Query-Exit\u201d and a third test case of \u201cLog-Delete data-Exit\u201d, the first test case is a basis, while the execution of the second and third test cases relies on the first test case.In a procedure of testing the application, the development engineer needs to manually record temporary test scripts with sample data firstly, then to replace the sample data with the test data to obtain test scripts for testing the application. However, since the number of the test cases is huge, recording of the test scripts is of heavy workload.FIG. 3 is a flowchart illustrating a computer-implemented method of testing an application according to an embodiment of the present disclosure. As shown in the FIG. 3, the method of testing an application according to the embodiment of the present disclosure comprises the following steps. At step S302, first temporary test scripts for testing at least one test case of a first version of the application are obtained. The first temporary test scripts are recorded with the first mark data used for testing the first version of the application, when the at least one test case of the first version of the application is tested, so the first temporary test scripts comprise the first mark data. At step S304, a first correspondence between the first mark data used for testing the first version of the application and test data is obtained. At step S306, the test data is substituted for the first mark data in the first temporary test scripts based on the first correspondence to obtain first test scripts for testing the at least one test case of the first version of the application.The method of testing the application according to the present disclosure further comprises: storing the first correspondence between the first mark data and the test data, for example, in the database such as database 206, which is stored in the storage or memory. The method of testing the application according to the present disclosure further comprises: testing the at least one test case of the first version of the application based on the first test scripts.For sake of clarity, the embodiments of the present disclosure will be described by means of an example of a bank client information system. According to an embodiment of the present disclosure, the data should be prepared before testing the application. The data to be prepared includes the test data and the mark data. Since the test data and the mark data have exactly the same data types and structures, they are actually two sets of different product data. The mark data and the test data can be manually prepared by the development engineer, and they also can be automatically generated by the data extractor 203 extracting the data types and structures used by the tested application from the database such as databases 206 based on test scenarios.According to the embodiment of the present disclosure, with respect to the application of the bank client information system, the mark data can be prepared as for example, but not limited to, \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d, \u201cNON_EXIST_DEGREE\u201d, and so on, as shown in Table 1 as below.TABLE 1NON_EXIST_NAME1970-19-70NON_EXIST_DEGREE. . . The prepared mark data are used to label client information \u201cclient name\u201d, \u201cdate of birth\u201d, and \u201ceducation background\u201d, respectively. These mark data has unique values and also has the corresponding data types and structure. To distinguish it from the mark data on the next stage, the mark data as prepared above are referred to as \u201cthe first mark data\u201d.According to the embodiment of the present disclosure, the test data may be prepared as a plurality of data files, each file corresponding to one of the first mark data as prepared above. For example, the file of test data prepared for \u201cclient name\u201d may be illustrated in Table 2 as below.TABLE 2Tom SmithGrace LinJim ChouAndy ZhuJerry JohnJoshua Wesley. . . For example, the file of test data prepared for \u201cdate of birth\u201d may be illustrated in Table 3 as below.TABLE 31976 May 11978 Mar. 201980 Apr. 21985 Sep. 101999 Oct. 1. . . For example, the file of test data prepared for \u201ceducation background\u201d may be illustrated in Table 4 as below.TABLE 4Ph.DMaster DegreeCollegeHigh schoolJunior schoolN/A. . . According to the embodiment of the present disclosure, the correspondence between the test data and the first mark data is established after completion of data preparation or at the same time when the data are prepared. The correspondence is illustrated in Table 5 as below.TABLE 5NON_EXIST_NAME1970-19-70NON_EXIST_DEGREE. . .Table 2Table 3Table 4. . . According to the embodiment of the present disclosure, the above table which indicates the correspondence between the first mark data and the files of the test data is stored in for example the database 206. To distinguish it from the correspondence on the next stage, the correspondence as prepared above are referred to as \u201cthe first correspondence\u201d.The operations of recording the test scripts according to the embodiment of the present disclosure will be described as follows. Specifically, an operation of obtaining first test scripts for testing at least one test case of the first version of the application will be described. The first temporary test scripts are recorded with the first mark data used for testing the at least one test case of the first version of the application when the at least one test case of the first version of the application is tested, and the first temporary test scripts comprise the first mark data used for testing the first version of the application.Now it is assumed that the first version of the application of the bank client information system runs on the server device 204, and the test tool software for testing the first version of the application of the bank client information system runs on the test device 202. For sake of clarity of description, it is assumed that an operation of \u201cLog-Update-Exit\u201d is selected as the test case, and the mark data shown in the Table 1 are selected as the first mark data used for testing the first version of the application.FIG. 4 shows a test form displayed on the test device for recording test scripts according to the embodiment of the present disclosure. The development engineer accesses the application by inputting a network address such as the URL of the application of the bank client information system running on the server device 204, in an address bar of the browser running on the test device 202. A form 400 shown in FIG. 4 could be displayed on a screen of the test device 202 via the above accessing operation.In the form 400 shown in FIG. 4, profile information of a client, such as \u201cclient name\u201d, \u201cdate of birth\u201d, and \u201ceducation background\u201d is illustrated. The development engineer clicks on a \u201creset\u201d key to reset the value of each of the above field variables. After clicking on the \u201creset\u201d key, the development engineer enters the first mark data \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d and \u201cNON_EXIST_DEGREE\u201d into input boxes corresponding to \u201cclient name\u201d, \u201cdate of birth\u201d, \u201ceducation background\u201d respectively, and then clicks on a \u201csubmit\u201d button.After clicking on the \u201csubmit\u201d button, the browser on the test device 202 generates an HTTP request. The HTTP request is sent to the application of the bank client information system running on the server device 204 to request an operation of updating the client information.The test tool software on the test device 202 intercepts and records the HTTP request, thereby forming a first temporary test script. According to the embodiment of the present disclosure, the HTTP request may be shown below. http://www.abcbank.com/client/profile?act=update&name=NON_EXIST_NAME&birth=1970-19-70&edu=NON_EXIST_DEGREEAs can be seen, each of the field variables \u201cclient name\u201d, \u201cdate of birth\u201d, and \u201ceducation background\u201d is labeled with the first mark data \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d, and \u201cNON_EXIST_DEGREE\u201d, respectively.The test tool software receives a first correspondence between the first mark data and the files of test data used for testing the first version of the application. Specifically, the automatic code generator 505 of the test tool software obtains the first correspondence between the first mark data used for testing the first version of the application of the bank client information system and the files of test data, as shown in Table 5, by accessing the database 206.The test tool software substitutes the corresponding test data for the first mark data in the first temporary test script based on the obtained first correspondence to obtain s first test script for testing the test case of the first version of the application of the bank client information system. Specifically, the automatic code generator 205 of the test tool software substitutes the test data in the files shown in Table 2, Table 3, and Table 4 for each of the first mark data in the above HTTP request, and forms the first test script for testing the test case of the first version of the application.The way of recording the first temporary test script is not construed as a limitation on the scope of the present disclosure. According to another embodiment of the present disclosure, an operation of recording the first temporary test script may also be automatically implemented on the test device 202 with the test tool software. All the current stress/performance test tools provide functionality of recording test scripts. During the recording, the test tools are able to record all HTTP Requests/Responses as the test scripts for playback in the test tools (test tools simulating thousands of users). Before the test, the first mark data in the first temporary test scripts need to be replaced with the prepared test data to simulate client scenarios.In the method of testing the application according to the present disclosure, the test cases of the first version of application are tested by using the obtained first test scripts.The above situation can also be illustrated by the following non-limiting example. For example, when the data are prepared, the first mark data \u201cdirty_data_001\u201d and the corresponding test data \u201ctest_data_001\u201d are generated. In the temporary test script of the test case of the first version of the application, \u201cvar1=dirty_data_001\u201d is recorded. Then, the first correspondence between the first mark data \u201cdirty_data_001\u201d and the corresponding test data \u201ctest_data_001\u201d is referred to so that the test data \u201ctest_data_001\u201d is substituted for the first mark data \u201cdirty_data_001\u201d, and the test script \u201cvar1=test_data_001\u201d is obtained.In the procedure of testing the application, the development engineer may modify the program codes of the application based on the test results of the test cases of the first version of the application to eliminate errors in the application or improve the functionality of the application, thereby to form a second version of the application. Especially, in the DevOps (Development & Operations) and other agile developments, such modifications to the application bring many changes to parameters in the HTTP communications. For example, an existed parameter in a HTTP request may be renamed, deleted, or moved to other locations in a new HTTP communication, and a new parameter may also be introduced in the new HTTP communication.Since the changes of the parameters in the HTTP requests/responses are unpredictable, after a change happens, the network performance test tools such as the RPT, and JMeter cannot automatically absorb the new changes of the HTTP parameters for a new software version. Accordingly, a lot of manual adjustments are needed so as to accommodate the changed HTTP parameters. With DevOps, Agile Development, and Continuous Integration widely used in the network developments, this situation occurs more frequently in the HTTP tests, greatly reducing efficiency of the test.According to the other embodiment of the present disclosure, the operations of recording the test scripts under a condition that the positions and/or names of the field variables may change or the number of variables may decrease or increase will be described. Specifically, the operations of obtaining the second test scripts for testing the at least one test case of the second version of application will be described hereinafter.In this case, there are two situations. The first situation is that the second mark data is included in a second mark data, e.g. the number of the second specific mark data used for testing the second version of the application decreases or does not change as compared to that of the first mark data used for testing the first version of the application. In this case, the second mark data are included in the first mark data. That means that, the data in the second mark data are less than or equal to that in the first mark data, or the second mark data are a subset of the first mark data.The second situation is that the first mark data is included in the second mark data, e.g. the number of the second mark data used for testing the second version of the application increases as compared to that of the first mark data used for testing the first version of the application. In this case, the second mark data contain the first mark data. That means that, the data in the second mark data are more than that in the first mark data, or the second mark data contain new mark data that are not in the set of the first mark data.Firstly, the first situation will be described. In this case, since the second mark data is included in the first mark data, e.g. the number of the second mark data used for testing the second version of the application decreases or does not change as compared to that of the first mark data used for testing the first version of the application, the second temporary test scripts are recorded with the second mark data when the at least one test case of the second version of the application is tested, in which the data in the second mark data are less than or equal to that in the first mark data.FIG. 5 is a flowchart illustrating a computer-implemented method of testing an application according to another embodiment of the present disclosure. As shown in the FIG. 5, the method of testing the application according to the other embodiment of the present disclosure comprises: in response to the second mark data being included in the first mark data, at step S502, second temporary test scripts for testing at least one test case of the second version of the application are obtained. The second temporary test scripts are recorded with the second mark data used for testing the at least one test case of the second version of the application when the at least one test case of the second version of the application is tested, so the second temporary test scripts include the second mark data used for testing the second version of the application. At step S504, the stored first correspondence between the first mark data and the test data is obtained. At step S506, the test data are substituted for the second mark data in the second temporary test scripts based on the first correspondence to obtain second test scripts for testing the at least one test case of the second version of the application.FIG. 6 shows a test form displayed on the test device for recording test scripts according to the other embodiment of the present disclosure. The development engineer accesses the application by inputting the network address such as the URL of the application of the bank client information system running on the server device 204 in the address bar of the browser running on the test device 202. A form 600 shown in FIG. 6 is displayed on the screen of the test device 202 via the above accessing operation.In the form 600 shown in FIG. 6, the profile information of a client such as \u201cclient name\u201d and \u201cdate of birth\u201d is illustrated. As compared to the form 400 shown in FIG. 4, the \u201ceducation background\u201d is canceled. In this embodiment, since the variable field \u201ceducation background\u201d is canceled, the second mark data \u201cNON_EXIST_DEGREE\u201d and its corresponding file of test data (Table 4) are not necessary. That is, the second mark data is included in the first mark data. In this case, the second mark data are a subset of the first mark data. Thus, the second temporary test scripts for testing the second version of the application are recorded by using part of the first mark data used for testing the first version of the application.In this case, the recording process of the second temporary test scripts is the same as that of the first temporary test scripts. For sake of brevity, the detailed recording process is omitted.The test tool software receives the first correspondence between the first mark data used for testing the first version of the application and the files of test data. Specifically, the automatic code generator 205 of the test tool software obtains the first correspondence between the first mark data used for testing the first version of the application of the bank client information system and the files of test data, as shown in Table 5, by accessing the database 206.The test tool software substitutes the test data for the second mark data used for testing the second version of the application in the second temporary test scripts based on the obtained first correspondence to obtain second test scripts for testing the at least one test case of the second version of the application. Specifically, the automatic code generator 205 of the test tool software substitutes the test data in the files shown in Table 2 and Table 3 for each of the second mark data in the HTTP requests, and forms the second test scripts for testing the second version of the application.In the method of testing the application according to the present disclosure, the test cases of the second version of application are tested by using the obtained second test scripts.According to another embodiment of the present disclosure, the above situation can also be illustrated by the following non-limiting example. For example, when the data are prepared, the first mark data \u201cdirty_data_001\u201d and the corresponding test data \u201ctest_data_001\u201d are generated. In the temporary test scripts of the test cases of the first version of the application, \u201cvar1=dirty_data_001\u201d is recorded. It is assumed that in the test of the test cases of the second version of the application, the name of the field variable changes from \u201cvar1\u201d to \u201cvar2\u201d, that is, the (manually or automatically) recorded test script is \u201cvar2=dirty_data_001\u201d. In this case, the first correspondence between the first mark data \u201cdirty_data_001\u201d and the corresponding test data \u201ctest_data_001\u201d is referred to so that the test data \u201ctest_data_001\u201d is substituted for the first mark data \u201cdirty_data_001\u201d, and the test script \u201cvar2=test_data_001\u201d is obtained. That is, even if a variation occurs to the name and location of the parameter variables, the identical mark data and the corresponding test data are used.The second situation will be described hereinafter. In this case, since the first mark data is included in the second mark data, the second temporary test scripts cannot be recorded with only the first mark data when the at least one test case of the second version of the application is tested.According to a further embodiment of the present disclosure, it is necessary to prepare more mark data than the first mark data to form the second mark data used for testing the second version of the application. In this case, the second temporary test scripts are recorded with the first mark data used for testing the first version of the application and the mark data increased as compared to the first mark data, when the test cases of the second version of the application are tested. Thereby, the second temporary test scripts include the first mark data and the mark data increased as compared to the first mark data.FIG. 7 is a flowchart illustrating a computer-implemented method of testing the application according to the further embodiment of the present disclosure. As shown in the FIG. 7, the method of testing the application according to the further embodiment of the present disclosure comprises: in response to the first mark data being included in the second mark data: at step S702, second temporary test scripts for testing at least one test case of the second version of the application are obtained. The second temporary test scripts are recorded with the second mark data, when the at least one test case of the second version of the application is tested. The second temporary test scripts include the first mark data used for testing the first version of the application and mark data increased as compared to the first mark data. At step S704, the stored first correspondence between the first mark data and the test data is obtained. At step S706, a second correspondence between the mark data increased as compared to the first mark data and increased test data is obtained. At step S708, the test data and the increased test data are substituted for the second mark data in the second temporary test scripts based on the first and second correspondences to obtain second test scripts for testing the at least one test case of the second version of the application.The method of testing the application according to the present disclosure further includes: testing the test cases of the second version of the application based on the obtained second test scripts.FIG. 8 shows a test form displayed on the test device for recording the test scripts according to the further embodiment of the present disclosure. For example, the development engineer accesses the application by inputting the network address such as the URL of the application of the bank client information system running on the server device 204 in the address bar of a browser running on the test device 202. A form 800 shown in FIG. 8 could be displayed on the screen of the test device 202 via the above accessing operation.In the form 800 shown in FIG. 8, the profile information of a client, such as \u201cclient name\u201d, \u201cdate of birth\u201d, \u201ceducation background\u201d, and \u201cresidence address\u201d is illustrated. As compared to the form 400 shown in FIG. 4, \u201cresidence address\u201d is added.With respect to such a case, during the data preparation, increased mark data and increased test data file corresponding to the profile information of \u201cresidence address\u201d of the client should be prepared, as shown in Tables 6 and 7.TABLE 6NON_EXIST_ADDRESS TABLE 7AAABBBCCCDDDEEEFFFGGG. . . A correspondence between the increased market data and the increased file of test data is established and stored, as shown in Table 8 below.TABLE 8NON_EXIST_ADDRESSTable 7 According to the embodiment of the present disclosure, the above-added form representing the correspondence (hereinafter referred to as the second correspondence) between the increased file of test data and the increased market data is stored for example in the database 506.The development engineer clicks on the \u201creset\u201d key to reset the values of the client information. After clicking on the \u201creset\u201d key, the development engineer enters the second mark data \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d, \u201cNON_EXIST_DEGREE\u201d, and \u201cNON_EXIST_ADDRESS\u201d into the input boxes corresponding to the field variables \u201cclient name\u201d, \u201cdate of birth\u201d, \u201ceducation background\u201d, and \u201cresidence address\u201d respectively, and clicks on the \u201csubmit\u201d button.After clicking on the \u201csubmit\u201d button, the browser on the test device 202 generates an HTTP request. The HTTP request is sent to the application of the bank client information system running on the server device 204 to request an operation of updating the client information. The test tool software on the test device 202 intercepts and records the HTTP request, thereby forming the second temporary test script. According to the embodiment of the present disclosure, the HTTP request can be shown as: http://www.abcbank.com/client/profile?act=update&name=NON_EXIST_NAME&birth=1970-19-70&edu=NON_EXIST_DEGREE&addr=NON_EXIST_ADDRESSAs can be seen from the above, each of the field variables \u201cclient name\u201d, \u201cdate of birth\u201d, \u201ceducation background\u201d, and \u201cresidence address\u201d of the client information is labeled with the second mark data \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d, \u201cNON_EXIST_DEGREE\u201d, and \u201cNON_EXIST_ADDRESS\u201d respectively.The test tool software obtains the first correspondence between the first mark data used for testing the first version of the application and the files of test data, as shown in Table 5, and obtains the second correspondence between the mark data increased as compared to the first mark data and the increased file of test data, as shown in Table 8. Specifically, the automatic code generator 205 of the test tool software obtains the above first and second correspondences by accessing the database 206.The test tool software substitutes the test data for the first mark data and the mark data increased as compared to the first mark data in the second temporary test scripts based on the obtained first and second correspondences (Table 5, Table 8) to obtain the second test scripts for testing the at least one test case of the second version of the application. Specifically, the automatic code generator 205 of the test tool software substitutes the test data in the files as shown in Table 2, Table 3, Table 4, and Table 7 for each of the mark data as shown in Table 1 and Table 6 in the above HTTP request, and forms the second test scripts for testing the test cases of the second version of the application.The way of recording the second temporary test scripts is not construed as a limitation to the scope of the present disclosure. According to another embodiment of the present disclosure, the operation of recording the second temporary test scripts may also be automatically implemented by the test device 204 with the test tool software. All current stress/performance test tools provide functionality of recording test scripts. During the recording, the test tools will record all HTTP Requests/Responses as test scripts for playback in the test tools. Before the test, the mark data in the test scripts should be replaced with the prepared test data to simulate client scenarios.In the method of testing the application according to the present disclosure, the test cases of the second version of application are tested by using the obtained second test scripts. Example of the above HTTP requests is not construed as a limitation to the scope of the present disclosure, which may be an HTTP response, or any other network communication. The above mark data, such as, \u201cNON_EXIST_NAME\u201d, \u201c1970-19-70\u201d, \u201cNON_EXIST_DEGREE\u201d, \u201cNON_EXIST_ADDRESS\u201d are not construed as limitation to the scope of the present disclosure, and any other special unique value may be used.In the method of testing the application according to the present disclosure, the test cases comprise a plurality of test cases with logical relations. In the method of testing the application according to the present disclosure, the first and second mark data are sets of data with the data types, data structures and unique values required by the application to be tested.Each of the above steps can be implemented by executing computer program instructions stored in the memory 28 by the processor unit 16 of a computer system 12 as shown in FIG. 1.FIG. 9 is a flow chart depicting a live demonstration of the method and the system for testing the application according to the present disclosure. In the FIG. 9, each node is an open source tool. As shown in the FIG. 9, there are three phases in the live demonstration, which are Test Scenario Definitions for defining the testing cases, Perf BVT (Build Verification Test) test for a single user, and Load/Perf/Longevity test for multiple users, respectively.In the FIG. 9, BDD (Behavior Driven Development) is principally an idea about how the software development should be managed by both business interests and technical insight. Cucumber is a kind of open source software that implements the concept of the BDD. \u201cSelenium\u201d is an open source software testing framework for the web applications. Selenium provides a record/playback tool for authoring tests without learning a test scripting.BrowserMob proxy is a free (Apache 2.0 license) utility that works well with the Selenium. It can capture performance data for web applications via a HAR format, as well as manipulate browser behavior and traffic, such as rewriting HTTP requests and responses. Here, \u201c.HAR file\u201d is a file format that indicates the HTTP Archive (HAR) format.Apache JMeter is an Apache project that can be used as a load testing tool for analyzing and measuring the performance of a variety of services, with a focus on the web applications.FIG. 10 is another flow chart depicting a live demonstration of the method and the system for testing the application according to the present disclosure. In the FIG. 10, the reference numeral 1001 indicates a mark database for storing the mark data, the reference numeral 1002 indicates a knowledge base for the product (application) to be tested.In the block 1003 corresponding to the data extractor 203 and the automatic code generator 205, two temporary files 1004 and 1005 may be generated based on the data from the mark database 1001 and the knowledge base 1002. The file 1004 is an attribute file for replaying test scripts. In the embodiments of the present disclosure, the test scripts are recorded with the mark data, and these mark data need to be replaced by general test data during the replaying of the test scripts. For example, as described above, the client name is recorded with the mark data \u201cNON_EXIST_NAME\u201d, and during the replaying of the test scripts, the mark data \u201cNON_EXIST_NAME\u201d will be replaced by names of \u201cTom Smith\u201d, \u201cGrace Lin\u201d, etc. All these general test data are stored in the attribute file 1004.The file 1005 is a mark data description file, which indicates how to replace the mark data by the general test data. In the file 1005, \u201cattr1_data_source\u201d indicates the location information of the client name attribute file, \u201cparam_value_001\u201d indicates a mark data which is the \u201cNON_EXIST_NAME\u201d in the above example, \u201cname\u201d indicates an attribute name, \u201ctype\u201d indicates an attribute type, \u201cRequest\u201d indicates what to do when the mark data appears in a HTTP request, \u201cResponse\u201d indicates what to do when the mark data appears in a HTTP response, \u201caction\u201d indicates how to deal with the mark data, such as \u201creplace\u201d, \u201creplace next\u201d, . . . , \u201cudv\u201d indicates the name of variables for replacing, and \u201ctarget\u201d indicates a range for applying the action.In the block 1006, the test cases are defined and recorded. In the block 1007, the test scripts are generated based on the files 1004, 1005, and the defined and recorded test cases. In the block 1008, the test scripts are written into an engineering file \u201c.JMX\u201d of the test tool JMETER. In the block 1009, the JMETER replays the test scripts based on the engineering file \u201c.JMX\u201d and the attribute file 1004.According to the embodiments of the present disclosure, the test tools of the present disclosure may be, but not limited to, one of the RPT, and JMETER.According to another embodiment of the present disclosure, the test tools of the present disclosure may also be any program codes made by those skilled in the art to achieve the same functions.According to another embodiment of the present disclosure, there is also provided a computer system for testing an application. The computer system may be implemented by a computer system 12 as shown in FIG. 1, which includes for example a memory 28, at least one processor 16, and a display 24, and the like.According to a further embodiment of the present disclosure, there is also provided a computer program product for testing an application. The computer program product includes a computer readable storage medium, the computer readable storage medium storing computer program instructions thereon, the computer program instructions are executed by at least one processor, such that the at least one processor could execute the method of testing the application according to the embodiments of the present disclosure.According to the method, computer system and computer program product for testing the application, the network-based test scripts could automatically absorb the new changes frequently occurred in the new construction of the application.The computer-implemented method, computer system and computer program product for testing the application according to the embodiments of the present disclosure have been described in details in combination with the drawings as above.The present invention may be a system, a method, and/or a computer program product. The computer program product may include a computer readable storage medium (or media) having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be, for example, but is not limited to, an electronic storage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing. A non-exhaustive list of more specific examples of the computer readable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a portable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable combination of the foregoing. A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through a waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.Computer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the Internet, a local area network, a wide area network and/or a wireless network. The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. A network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing/processing device.Computer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware instructions, state-setting data, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++ or the like, and conventional procedural programming languages, such as the \u201cC\u201d programming language or similar programming languages. The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). In some embodiments, electronic circuitry including, for example, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry, in order to perform aspects of the present invention.Aspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.These computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.The computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or other device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.The flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.The descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical improvement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.It should be noted that this description is not intended to limit the invention. On the contrary, the embodiments presented are intended to cover some of the alternatives, modifications, and equivalents, which are included in the spirit and scope of the invention as defined by the appended claims. Further, in the detailed description of the disclosed embodiments, numerous specific details are set forth in order to provide a comprehensive understanding of the claimed invention. However, one skilled in the art would understand that various embodiments may be practiced without such specific details.Although the features and elements of the embodiments disclosed herein are described in particular combinations, each feature or element can be used alone without the other features and elements of the embodiments or in various combinations with or without other features and elements disclosed herein.This written description uses examples of the subject matter disclosed to enable any person skilled in the art to practice the same, including making and using any devices or systems and performing any incorporated methods. The patentable scope of the subject matter is defined by the claims, and may include other examples that occur to those skilled in the art. Such other examples are intended to be within the scope of the claims.","Export Citation":"Click for automatic bibliographygeneration","Filing Date":"07/20/2016","Foreign References":"WO2015112170A12015-07-30CONTINUOUS INTEGRATION WITH REUSABLE CONTEXT AWARE JOBS","International Classes":"G06F11/00; G06F11/36","Inventors":"Yi, Ang (Beijing, CN)","Other References":"\u201cParameterized Builds\u201d, Parameterized Builds\u2014CircleCI, May 11, 2015, 6 pages, .\u201cParameterizing a load or stress test\u201d, May 11, 2015, 4 pages, .Yi et al., \u201cGenerating Test Scripts for Testing a Network-Based Application\u201d, U.S. Appl. No. 15/825,507, filed Nov. 29, 2017, 42 pages.IBM Appendix P, list of patents and patent applications treated as related, filed herewith, 2 pages.","Primary Examiner":"MASKULINSKI, MICHAEL C","Publication Date":"04/02/2019","Title":"Generating test scripts for testing a network-based application","US Patent References":"10108536Integrated automated test case generation for safety-critical software2018-10-23Li10042744Adopting an existing automation script to a new framework2018-08-07Herrin20180096051TEST DATA MANAGEMENT2018-04-05Barbas9910941Test case generation2018-03-06Dusanapudi9317406Generating test scripts through application integration2016-04-19Pilot et al.20150227452SYSTEM AND METHOD FOR TESTING SOFTWARE APPLICATIONS2015-08-13Raghavan717/1249087137Detection of custom parameters in a request URL2015-07-21Amit et al.20150169432INTEGRATION TESTING METHOD AND SYSTEM FOR WEB SERVICES2015-06-18Sinyagin et al.9021440System and method for automated test script generation2015-04-28Chandrasekaran717/1248799714Generating test scenarios from application-layer messages2014-08-05Guruswamy et al.8739125Automated and unattended process for testing software applications2014-05-27Petrovicky et al.20130263089GENERATING TEST CASES FOR FUNCTIONAL TESTING OF A SOFTWARE APPLICATION2013-10-03Banerjee et al.20130104105TEST DATA SUPPLY CHAIN MANAGER FOR AN INTEGRATED TESTING PLATFORM2013-04-25Brown717/12420130055028METHODS AND SYSTEMS FOR CREATING SOFTWARE TESTS AS EXECUTABLE RESOURCES2013-02-28Patil et al.7680668Method for generating a language-independent regression test script2010-03-16Voruganti20040044993Testing versions of applications2004-03-04Muller717/1245754755Method and system for generating test scripts1998-05-19Smith, Jr.714/38.1","View Patent Images":"Download PDF 10248552"},"United States Patent 10380004":{"Abstract":"In at least one embodiment, a system performs regression testing of software using selected test cases. In at least one embodiment, the system selects the test case for regression testing based on whether the test case correlates with modified code. In at least one embodiment, a test case correlates with the modified code if the test case tests all or a proper subset of the modified code. In at least one embodiment, if a test case does not test any of the modified code, then the test case is not used in the regression testing of the modified code.","Application Number":"14/210627","Assignee":"DEVFACTORY FZ-LLC (Dubai Media, AE)","Attorney, Agent or Firm":"TERRILE, CANNATTI & CHAMBERS, LLP (AUSTIN, TX, US)","Claims":"What is claimed is:1.A method testing code after modification of multiple portions of the code, the method comprising: performing by a computer system programmed with code stored in a memory and executable by a processor of the computer system for: accessing the code after modification of the multiple portions of the code, which includes modification of multiple classes of the code; determining which of the multiple portions of the code, including the modified multiple classes, were modified; accessing data correlating one or more test cases to respective portions of the code, wherein each test case that is correlated to a portion of the code tests the correlated portion of code during a test of the code; identifying one or more correlated test cases, wherein the correlated test cases are the one or more test cases that correlate with the multiple portions of the code, including the multiple classes, that were modified; iterating through multiple test cases to determine which of the multiple test cases are prerequisites to the one or more identified correlated test cases; continue iterating through the multiple test cases to determine which of the multiple tests cases are prerequisites to the one or more determined prerequisite test cases; repeating the continue iterating element until all prerequisite test cases are determined; and testing the code using only the one or more correlated test cases and the one or more prerequisite test cases.2.The method of claim 1 wherein each portion of the portions of code consist of one or more members of a group consisting of: a line of code, a block of code, a method, a class, and a package.3.The method of claim 1 wherein the data correlating the one or more test cases to respective portions of the code comprises a map that correlates each test case with the code exercised by the test case.4.The method of claim 1 further comprising: testing the code in accordance with one of the test cases; exercising a portion of the code with the test case used for the testing; and recording which portion of the code was exercised by the test case used for the testing.5.The method of claim 4 wherein exercising the portion of the code with the test case used for the testing comprises: calling one or more methods of the code.6.The method of claim 4 wherein recording which portion of the code was exercised by the test case used for the testing comprises: storing the portion of the code exercised by the test case used for testing as a data map in a non-transitory, computer readable medium, wherein the data correlating one or more test cases to respective portions of the code comprises the data map.7.The method of claim 1 further comprising: not testing the code using any test cases that do not correlate with the multiple portions of the code that were modified.8.The method of claim 1 wherein a test case correlates with the multiple portions of the code that were modified if the test case tests all or a proper subset of the multiple portions of the code that were modified.9.A data processing system comprising: a processor; and a memory, coupled to the processor, that includes code stored therein and executable by the processor to test the code after modification of multiple portions of the code, which modification of multiple classes of the code, and to transform the data processing system into a testing system for: accessing the code after modification of the multiple portions of the code, which includes modification of multiple classes of the code; determining which of the multiple portions of the code, including multiple classes, were modified; accessing data correlating one or more test cases to respective portions of the code, wherein each test case that is correlated to a portion of the code tests the correlated portion of code during a test of the code; identifying one or more correlated test cases, wherein the correlated test cases are the one or more test cases that correlate with the multiple portions of the code, including the multiple classes, that were modified; iterating through multiple test cases to determine which of the multiple test cases are prerequisites to the one or more identified correlated test cases; continue iterating through the multiple test cases to determine which of the multiple tests cases are prerequisites to the one or more determined prerequisite test cases; repeating the continue iterating element until all prerequisite test cases are determined; and testing the code using only the one or more correlated test cases and the one or more prerequisite test cases.10.The data processing system of claim 9 wherein each portion of the portions of code consist of one or more members of a group consisting of: a line of code, a block of code, a method, a class, and a package.11.The data processing system of claim 9 wherein the data correlating the one or more test cases to respective portions of the code comprises a map that correlates each test case with the code exercised by the test case.12.The data processing system of claim 9 wherein the code is further executable by the processor for: testing the code in accordance with one of the test cases; exercising a portion of the code with the test case used for the testing; and recording which portion of the code was exercised by the test case used for the testing.13.The data processing system of claim 12 wherein exercising the portion of the code with the test case used for the testing comprises: calling one or more methods of the code.14.The data processing system of claim 12 wherein recording which portion of the code was exercised by the test case used for the testing comprises: storing the portion of the code exercised by the test case used for testing as a data map in a non-transitory, computer readable medium, wherein the data correlating one or more test cases to respective portions of the code comprises the data map.15.The data processing system of claim 9 wherein the code is further executable by the processor for: not testing the code using any test cases that do not correlate with the multiple portions of code that were modified.16.The data processing system of claim 9 wherein a test case correlates with the multiple portions of the code that were modified if the test case tests all or a proper subset of the multiple portions of the code that were modified.17.A non-transitory computer readable medium comprising code stored therein and executable by a processor to test the code after modification of multiple portions of the code, which includes modification of multiple classes of the code, and to transform a data processing system into a testing system for: accessing the code after modification of the multiple portions of the code, which includes modification of multiple classes of the code; determining which of the multiple portions of the code, including multiple classes, were modified; accessing data correlating one or more test cases to respective portions of the code, wherein each test case that is correlated to a portion of the code tests the correlated portion of the code during a test of the code; identifying one or more correlated test cases, wherein the correlated test cases are the one or more test cases that correlate with the multiple portions of the code, including the multiple classes, that were modified; iterating through multiple test cases to determine which of the multiple test cases are prerequisites to the one or more identified correlated test cases; continue iterating through the multiple test cases to determine which of the multiple tests cases are prerequisites to the one or more determined prerequisite test cases; repeating the continue iterating element until all prerequisite test cases are determined; and testing the code using only the one or more correlated test cases and the one or more prerequisite test cases.18.The non-transitory, computer readable medium of claim 17 wherein each portion of the portions of code consist of one or more members of a group consisting of: a line of code, a block of code, a method, a class, and a package.19.The non-transitory, computer readable medium of claim 17 wherein the data correlating the one or more test cases to respective portions of the code comprises a map that correlates each test case with the code exercised by the test case.20.The non-transitory, computer readable medium of claim 17 wherein the code is further executable by the processor for: testing the code in accordance with one of the test cases; exercising a portion of the code with the test case used for the testing; and recording which portion of the code was exercised by the test case used for the testing.21.The non-transitory, computer readable medium of claim 17 wherein exercising the portion of the code with the test case used for the testing comprises: calling one or more non-transitory, computer readable mediums of the code.22.The non-transitory, computer readable medium of claim 21 wherein recording which portion of the code was exercised by the test case used for the testing comprises: storing the portion of the code exercised by the test case used for testing as a data map in a non-transitory, computer readable medium, wherein the data correlating one or more test cases to respective portions of the code comprises the data map.23.The non-transitory, computer readable medium of claim 17 wherein the code is further executable by the processor for: not testing the code using any test cases that do not correlate with the multiple portions of code that were modified.24.The non-transitory, computer readable medium of claim 17 wherein a test case correlates with the multiple portions of the code that were modified if the test case tests all or a proper subset of the multiple portions of the code that were modified.","Description":"BACKGROUND OF THE INVENTIONField of the InventionThe present invention relates in general to the field of electronics, and more specifically to computer software testing and selectively executing test cases to reduce overall test case execution.Description of the Related ArtTesters often test computer software using a suite of test cases. Test cases are also often referred to as test scripts. The test cases often include a set of conditions or variables, and the tester tests the computer software in accordance with the test cases. Generally, the test case provides a known input with an expected output, and the tester determines if the computer software passes or fails based on whether the computer software respectively produced the expected output or another output.Testers test computer software when certain conditions occur. An exemplary condition is when computer software is modified either through the addition of new code or the revision of existing code. Regression testing tests the computer software in accordance with test cases to determine whether the modified computer software produces the correct predetermined behavior despite the changes made to the code. Since computer software frequently change during the process of development for initial and new versions, regression testing also often occurs frequently. Any product that invests in exhaustive regression testing invariably has a very large automated regression test suite of test cases. The objective of this test suite is that it can be executed with every code modification to identify potential regressions, i.e. errors.FIG. 1 depicts computer software development and testing system 100, which performs exhaustive test case regression testing. A software developer utilizes computer 102 to develop code 104. From computer 102, the developer performs a code check-in 106 to check the code 104 into computer system 108. The code 104 is all or part of software 110. Computer system 108 includes a source control system 109 that assigns a new revision number to the software 110 to provide version control and stores each version of the software 110 in a file versioning repository memory 111 of the computer system 108. The source control system 109 sends CHECK_IN data to notify a regression testing system 111 of computer system 113 when code 104 is checked-in. The CHECK_IN data provides specific details associated with the code check-in. Exemplary CHECK_IN data includes:Identification of the user who checked in the code 104;The files of code 104 that were checked in;The check in time;The assigned revision number; andIdentification of the repository in which the code 104 was checked in.The source control system 109 is a software program executed by the computer system 108, and the regression testing system 111 is a software program executed by the computer system 113.The regression testing system 111 performs regression testing to determine whether the code 104 caused any functional or other errors in the software 110. Regression testing can involve one or more large test suites that typically have thousands of test cases and can take between 2 and 30 minutes each to run. Regression testing system and process 112 includes a test suite 114, and test suite 114 includes N test cases, where N is an integer representing the number test cases in test suite 114. The regression system and process 112 is incorporated as data and applications in computer system 108. Regression testing process 116 runs each of the N test cases in test suite 114. For large values of N, such as greater than 100, when each test case 1 through N runs serially in computer system 108, the regression test suite 114 may take in excess of 48 hours to run. Running regression test suite 114 serially can, thus, take a significant amount of time. Utilizing parallel processing, by adding one or more additional computer systems to computer system 108 to run all or a subset of the test cases in parallel, reduces regression testing time but can increase costs significantly. The results data 118 contains the results of the regression testing.Thus, conventional regression testing is costly either in terms of time, cost, or both. However, without regression testing, computer software can produce errors that may not be caught and/or understood until actual deployment.BRIEF DESCRIPTION OF THE DRAWINGSThe present invention may be better understood, and its numerous objects, features and advantages made apparent to those skilled in the art by referencing the accompanying drawings. The use of the same reference number throughout the several figures designates a like or similar element.FIG. 1 (labeled prior art) depicts a computer software development and testing system with exhaustive test case regression testing.FIG. 2 depicts a computer software development and testing system with selective test case regression testing.FIG. 3 depicts a test case-to-code correlation process.FIGS. 4A-4M (collectively referred to as FIG. 4) depict an exemplary, partial code coverage determination result.FIG. 5 depicts a selective test case regression testing process.FIG. 6 depicts a block diagram illustrating a network environment.FIG. 7 depicts an exemplary computer system.DETAILED DESCRIPTIONIn at least one embodiment, a system performs regression testing of software using selected test cases. In at least one embodiment, the system selects the test case for regression testing based on whether the test case correlates with modified code. In at least one embodiment, a test case correlates with the modified code if the test case tests all or a proper subset of the modified code. In at least one embodiment, if a test case does not test any of the modified code, then the test case is not used in the regression testing of the modified code.In at least one embodiment, the portions of code that correlate with each test case are identified, and data representing the test case-to-code correlation is stored. In at least one embodiment, after modification of one or more code portions of computer software, the system determines which of the one or more portions of code of the computer software were modified. The system then accesses the test case-to-code correlation data and identifies which of the one or more test cases correlate with the one or more portions of code that were modified. After the identification, the system tests the computer software using the one or more identified test cases and generates test result data.FIG. 2 depicts computer software development and testing system 200, which performs selective test case regression testing. The computer software development and testing system 200 includes a computer system 201, which may be any type of computer system such as a server. The computer system 201 includes a source control system 203 to manage changes in software 204. The source control system 203 can include any type of source code control application, such as Apache Subversion (SVN) from the Apache Software Foundation. Git from www.git-scm.com, Clearcase from International Business Machines of Armonk, N.Y., Integrity from PTC Integrity with offices in Chicago, Ill., Visual Source Safe by Microsoft Corp. of Redmond, Wash., and the Polytron Version Control System (PVCS) from Polytron Corp. from Serena Software, Inc. of San Mateo, Calif.From computer system 216, a developer performs a code check-in 218 to check the code 210 into computer system 201. The code 210 is all or part of software 204. The source control system 203 assigns a new revision number to the code 210 to provide version control and stores each version of the code 210 in a file versioning repository memory 211 of the computer system 201. The source control system 203 sends CHECK_IN data to notify a regression testing system 219 of computer system 202 when code 210 is checked-in. The CHECK_IN data provides specific details associated with the code check-in. Exemplary CHECK_IN data includes:Identification of the user who checked in the code 210;The files of code 210 that were checked in;The check in time;The assigned revision number; andIdentification of the repository in which the code 104 was checked in.The source control system 203 is a software program executed by the computer system 201, and, in at least one embodiment, the regression testing system 219 is a software program executed by the computer system 202. In at least one embodiment, the source control system 203 and the regression testing system 219 are software programs executed by the same computer system, such as computer system 201.The computer system 202 has access to test suite 206. Test suite 206 is stored in a non-transitory computer readable medium such as any type of memory device. The bracket 208 indicates that elements below the bracket 208 are accessible to and, in at least one embodiment, are part of the regression testing system 219.In at least one embodiment, the computer software development and testing system 200 performs selective test case regression testing by identifying and using test cases in test suite 206 that correlate with the one or more portions of checked-in modified code 210. In at least one embodiment, the computer system 202 generates the test case-to-code correlation data; however, any computer system that can test the software with the test suite 206 identify test-case-to-code correlation can generate the test case-to-code correlation data 212.FIG. 3 depicts a test case-to-code correlation process 300, which represents one process for generating the test case-to-code correlation data 212. Referring to FIGS. 2 and 3, operation 302 determines test case code coverage. In other words, operation 302 determines which code in software 204 is exercised by each of test cases 1-N. In at least one embodiment, the computer system 202 utilizes a code coverage application 214 to determine which code is exercised by a test case. Exemplary code coverage applications include EMMA. EMMA is an open source toolkit for measuring and reporting Java code coverage. In at least one embodiment, when the computer system 202 executes a test case against the software 204, the code coverage application 214 determines which code was exercised by the test case. The granularity of code coverage is a matter of design choice. In at least one embodiment, the code coverage application can identify exercised code at one or more levels. For example, for Java-based software, the code coverage application can identify exercised code at line, block, method, class, and/or package levels. The level of granularity for each test case 1-N is a matter of design choice. Thus, the granularity between the test cases 1-N can be the same or can vary between one of more test cases. In a Java programming language context, lines of code makes up a \u201cblock\u201d of code, and blocks of code make up a \u201cmethod\u201d. Multiple methods make up a \u201cclass\u201d, and multiple classes make up a \u201cpackage\u201d. Java is a programming language originally developed by Sun Microsystems of California, USA, which has merged with Oracle Corporation of California, USA.FIGS. 4A-4M, collectively referred to as FIG. 4, depict an exemplary, partial code coverage determination result by code coverage application 214. FIG. 4A represents an overview of code coverage by an exemplary ith test casei. As indicated by table 402, overall, test casei exercised 86% of the classes, 62% of the methods, 56% of the blocks, and 58% of the lines of an embodiment of software 204. Table 404 provides a more specific code coverage breakdown by package. For example, in the org.apache.velocity.app.tools package, there was no code coverage by test casei on a class, method, block, or line level. Thus, test casei does not correlate to the org.apache.velocity.app.tools package. However, for the package org.apache.velocity.util.introspection, there is 93% class coverage, 83% method coverage, 72% block coverage, and 81% line coverage.FIG. 4B depicts code coverage by test casei for classes in the package org.apache.velocity.util.introspection. The package org.apache.velocity.util.introspection has four classes identified in table 406, i.e. ClassMap, ClassMap$1, ClassMap$CacheMiss, and ClassMap#MethodInfo. Each class except ClassMap$1 has code coverage by test casei.FIGS. 4C-4M depict the code coverage on a method, block, and line level for the class ClassMap. An \u201cE\u201d next to a bracket indicates that the bracketed code was tested by test casei. An \u201cE\u2032\u201d next to a bracket indicates that at least part of the bracketed code was tested by test casei. A \u201cNE\u201d next to a bracket indicates that none of the bracketed code was tested by test casei. Lines with delineated between \u201c/**\u201d and \u201c*/\u201d indicated comments, which are not executed.Referring to FIG. 3, operation 304 of the test case-to-code correlation process 300 then stores the correlation between test casei and the exercised code indicated in FIG. 4 in the test case-to-code correlation data 212. The test case-to-code correlation process 300 repeats for all other test cases 1-N to generate a complete map of test case-to-code correlation data 212. In at least one embodiment, the test case-to-code correlation process 300 repeats for each new test case added to the test suite 206 and/or upon addition of a new test suite with one or more new test cases. As previously indicated, the granularity of the test-to-code correlation data 212 is a matter of design choice. For example, with regard to the package org.apache.velocity.util.introspection, the granularity can be to correlate at the method level so that if any of the 3 exercised methods ClassMap, ClassMap$CacheMiss, or ClassMap$MethodInfo are modified, then computer system 202 executes test casei. In at least one embodiment, the granularity of the test-to-code correlation data 212 is at the line level so that computer system 202 executes test casei only when lines of code identified with an E or E\u2032 are modified.FIG. 5 depicts a selective test case regression testing process 500. Referring to FIGS. 2 and 5, as previously described, a developer utilizes computer system 216 to modify code 210. In at least one embodiment, code 210 represents code that is part of software 204. The developer performs a code check-in 218. Computer system 216 can communicate with computer system 201 via any means including via a local or wide area network (such as the Internet). Computer system 216 can also be part of computer system 201.Once computer system 201 notifies computer system 202 that code 210 has been checked in, in operation 502, software 204 is ready for regression testing by the regression testing system 219. Checked code-test case analyzer 220 determines which code in code 210 was modified. In operation 504, the checked code-test case analyzer 220 accesses the test case-to-code correlation data 212, and, in operation 504 identifies which of the one or more test cases in test suite 206 correlate with the one or more portions of code that were modified. In at least one embodiment, operation 504 identifies which of the one or more test cases in test suite 206 correlate with the one or more portions of code that were modified by reviewing the test case-to-code correlation data 212 to identify each test case that tested the modified code. The granularity of the identification process of operation 506 is a matter of design choice. In at least one embodiment, operation 506 identifies test cases based on whether a class in code 210 was modified. Operation 506 can also identify test cases based upon a method, block, or line granularity if the test case-to-code correlation data 212 also supports the level of granularity. Additionally, the granularity of identification can be different for different test cases.In operation 508, test case selector 222 selects the M selected test cases 224, which were identified in operation 506, for regression testing software 504. \u201cM\u201d is an integer greater than or equal to 1 and less than of equal to N. In at least one embodiment, M is less than N so that the number of test cases 224 used by regression testing process 226 to test software 204 is less than the number of test cases in test suite 206. In operation 510, the computer system 202 performs the regression testing process 226 by testing the software 204 with the M test cases 224. In operation 512, computer system 202 generates the test results data 228. Computer system 202 provides the test results data 228 to another computer system, such as computer system 216, for display and/or storage, stores the test results data 228 in a memory (not shown) for access by one or more computer systems, or directly displays the test results data 228. Additionally, in at least one embodiment, when the test case selector 222 identifies a particular test case, the test case selector 222 iterates through the test cases to determine which test cases are prerequisites to the identified particular test case, and determines which test cases are prerequisites to the determined prerequisite test cases, and so on, so that all test cases and prerequisite test cases are selected. Additionally, in at least one embodiment, the test cases can be divided into subsets and used on different machines to optimize cost, speed, etc.FIG. 6 depicts a block diagram illustrating a network environment in which a computer software development and testing system 200 may be practiced. Network 602 (e.g. a private wide area network (WAN) or the Internet) includes a number of networked server computer systems 604(1)-(N) that are accessible by client computer systems 606(1)-(N), where N is the number of server computer systems connected to the network. Communication between client computer systems 606(1)-(N) and server computer systems 604(1)-(N) typically occurs over a network, such as a public switched telephone network over asynchronous digital subscriber line (ADSL) telephone lines or high-bandwidth trunks, for example communications channels providing T1 or OC3 service. Client computer systems 606(1)-(N) typically access server computer systems 604(1)-(N) through a service provider, such as an internet service provider (\u201cISP\u201d) by executing application specific software, commonly referred to as a browser, on one of client computer systems 606(1)-(N).Client computer systems 606(1)-(N) and/or server computer systems 604(1)-(N) may be, for example, computer systems of any appropriate design, including a mainframe, a mini-computer, a personal computer system including notebook computers, a wireless, mobile computing device (including personal digital assistants). These computer systems are typically information handling systems, which are designed to provide computing power to one or more users, either locally or remotely. Such a computer system may also include one or a plurality of input/output (\u201cI/O\u201d) devices coupled to the system processor to perform specialized functions. Mass storage devices such as hard disks, compact disk (\u201cCD\u201d) drives, digital versatile disk (\u201cDVD\u201d) drives, and magneto-optical drives may also be provided, either as an integrated or peripheral device. One such example computer system is shown in detail in FIG. 7.FIG. 7 depicts an exemplary computer system 700. Embodiments of the computer software development and testing system 200 can also be implemented purely in hardware using, for example, field programmable gate arrays or other configurable or hard-wired circuits. Embodiments of the computer software development and testing system 200 can be implemented by a computer system such as a general-purpose computer system 700 that is configured with software thereby transforming the general-purpose computer system into a specialized machine for performing the functions set forth in the software. Input user device(s) 710, such as a keyboard and/or mouse, are coupled to a bi-directional system bus 718. The input user device(s) 710 are for introducing user input to the computer system and communicating that user input to processor 713. The computer system of FIG. 7 generally also includes a video memory 714, non-transitory main memory 715 and non-transitory mass storage 709, all coupled to bi-directional system bus 718 along with input user device(s) 710 and processor 713. The non-transitory mass storage 709 may include both fixed and removable media, such as other available mass storage technology. Bus 718 may contain, for example, 32 address lines for addressing video memory 714 or main memory 715. The system bus 718 also includes, for example, an n-bit data bus for transferring DATA between and among the components, such as CPU 709, main memory 715, video memory 714 and mass storage 709, where \u201cn\u201d is, for example, 32 or 64. Alternatively, multiplex data/address lines may be used instead of separate data and address lines. Main memory 715 and mass storage 709 represent embodiments of non-transitory, computer readable media that store software that is executable by a processor.I/O device(s) 719 may provide connections to peripheral devices, such as a printer, and may also provide a direct connection to a remote server computer systems via a telephone link or to the Internet via an ISP. I/O device(s) 719 may also include a network interface device to provide a direct connection to a remote server computer systems via a direct network link to the Internet via a POP (point of presence). Such connection may be made using, for example, wireless techniques, including digital cellular telephone connection, Cellular Digital Packet Data (CDPD) connection, digital satellite data connection or the like. Examples of I/O devices include modems, sound and video devices, and specialized communication devices such as the aforementioned network interface.Computer programs and data are generally stored as instructions and data in mass storage 709 until loaded into main memory 715 for execution.The processor 713, in one embodiment, is a microprocessor manufactured by Motorola Inc. of Illinois, Intel Corporation of California, or Advanced Micro Devices of California. However, any other suitable single or multiple microprocessors or microcomputers may be utilized. Main memory 715 is comprised of dynamic random access memory (DRAM). Video memory 714 is a dual-ported video random access memory. One port of the video memory 714 is coupled to video amplifier 716. The video amplifier 716 is used to drive the display 717. Video amplifier 716 is well known in the art and may be implemented by any suitable means. This circuitry converts pixel DATA stored in video memory 714 to a raster signal suitable for use by display 717. Display 717 is a type of monitor suitable for displaying graphic images.The computer system described above is for purposes of example only. The computer software development and testing system 200 may be implemented in any type of computer system or programming or processing environment. It is contemplated that the computer software development and testing system 200 might be run on a stand-alone computer system, such as the one described above. The computer software development and testing system 200 might also be run from a server computer systems system that can be accessed by a plurality of client computer systems interconnected over an intranet network. Finally, the computer software development and testing system 200 may be run from a server computer system that is accessible to clients over the Internet.Embodiments of the computer software development and testing system 200 can also be implemented can be implemented purely in hardware using, for example, field programmable gate arrays or other configurable or hard-wired circuits.Thus, a system performs regression testing of software using selected test cases. In at least one embodiment, the system selects the test case for regression testing based on whether the test case correlates with modified code.Although embodiments have been described in detail, it should be understood that various changes, substitutions, and alterations can be made hereto without departing from the spirit and scope of the invention as defined by the appended claims.","Export Citation":"Click for automatic bibliographygeneration","Field of Search":"717/124","Filing Date":"03/14/2014","International Classes":"G06F11/36","Inventors":"Liemandt, Joseph A. (Austin, TX, US)Subramaniam, Rahul (Dubai, AE)Aboel-nil, Samy (Austin, TX, US)","Other References":"\u201cEMMA: A Free Java Code Coverage Tool\u201d; EMMA website (emma.sourceforge.net); Jan. 14, 2006 (Year: 2006).Gregor Schmid; \u201cQF-Test\u2014The Manual\u201d; Quality Software First (QSF) website (www.qfs.de); Oct. 2, 2012 (Year: 2012).\u201cDependencies between Test Cases and Suites\u201d; Common Test User's Guide, Chapter 12; Erlang.org website (full url in ref.); captured by the Wayback Machine Internet Archive (archive.org) on Feb. 17, 2013 (Year: 2013).International Search Report, PCT/US2014/030399, European Patent Office, dated Jul. 29, 2014, pp. 1-5.Written Opinion, PCT/US2014/030399, European Patent Office, dated Jul. 29, 2014, pp. 1-4.Communication pursuant to Article 94(3) dated Oct. 26, 2018, mailed in European Patent Application 14725823.0, pp. 1-7.Response to the communication pursuant to Rules 161(1) and 162 EPC dated Nov. 6, 2015, as filed with the European Patent Office on May 17, 2016 in European Patent Application 14725823.0, pp. 1-16.Response to Communication pursuant to Article 94(3) dated Oct. 26, 2018, as filed in European Patent Application 14725823.0 on May 3, 2019, pp. 1-18.","Parent Case Data":"CROSS-REFERENCE TO RELATED APPLICATIONThis application claims the benefit under 35 U.S.C. \u00a7 119(e) and 37 C.F.R. \u00a7 1.78 of U.S. Provisional Application No. 61/794,260, filed Mar. 15, 2013, which is incorporated by reference in its entirety.","Primary Examiner":"THATCHER, CLINT A","Publication Date":"08/13/2019","Title":"Test case reduction for code regression testing","US Patent References":"20130159774DYNAMIC REPRIORITIZATION OF TEST CASES DURING TEST EXECUTION2013-06-20Budnik714/338276123Adaptive regression test selection within testing environments2012-09-25Deng et al.717/12520110161936METHOD AND APPARATUS FOR REGRESSION TESTING SELECTION FOR A FRAMEWORK-BASED APPLICATION2011-06-30Huang et al.7614042System and method for selecting applicable tests in an automation testing system2009-11-03Hardy et al.717/12420090265693METHOD AND SYSTEM FOR TEST RUN PRIORITIZATION FOR SOFTWARE CODE TESTING IN AUTOMATED TEST EXECUTION2009-10-22Bakowski717/13120090094485METHOD FOR ENHANCING FUNCTIONALITY OF AN AUTOMATED TESTING TOOL2009-04-09Voruganti20080126867METHOD AND SYSTEM FOR SELECTIVE REGRESSION TESTING2008-05-29Pandarinathan et al.20050044533System and method for focused testing of software builds2005-02-24Nesbit et al.717/12420030204836Method and apparatus for prioritizing software tests2003-10-30Srivastava et al.717/1245673387System and method for selecting test units to be re-run in software regression testing1997-09-30Chen et al.714/38.15672387Process for the production of heat- and corrosion-resistant porous metal body1997-09-30Chin et al.","View Patent Images":"Download PDF 10380004"},"United States Patent 11487647":{"Abstract":"The systems and methods that determine tests that may be executed in parallel during regression testing of an analytics application are provided. Multiple tests that test functions of the analytics application are accessed from a test automation suite. For each test, data sources that provide data to the analytics application during the test are identified. The tests are aggregated into temporary groups according to the identified data sources. The test groups are generated from the temporary groups such that each test group comprises tests that are associated with non-overlapping data sources. The regression testing is performed on the application by executing the test groups in parallel.","Application Number":"17/035234","Assignee":"PayPal, Inc. (San Jose, CA, US)","Attorney, Agent or Firm":"Haynes & Boone, LLP (70481) (Dallas, TX, US)","Claims":"What is claimed is:1.A system, comprising: a processor; and a non-transitory computer-readable medium have stored thereon instructions that are executable to cause the system to perform operations comprising: accessing a plurality of automated software tests, wherein the plurality of automated software tests are configured to test one or more functions of an application; analyzing the plurality of automated software tests to identify at least a first data source and a second data source that are used to respectively perform at least first and second automated software tests of the plurality of automated software tests; generating test groups including a first test group comprising the first automated software test and a second test group comprising the second automated software test, wherein the generating is based on an aggregation of automated software tests according to data sources used to perform those automated software tests, and wherein each test group comprises one or more tests associated with non-overlapping data sources; and performing parallel execution of the test groups, including the first and second test groups, on the application.2.The system of claim 1, wherein the first data source comprises a first database accessible via a network, and wherein the second data source comprises a second database accessible via the network.3.The system of claim 1, wherein the operations further comprise: generating a test group automation suite for a particular test group from the test groups.4.The system of claim 1, wherein the operations further comprise: determining a maximum execution time of the test groups as a maximum execution time of a longest executing test group.5.The system of claim 1, wherein the operations further comprise: parsing each of the plurality of automated software tests to determine one or more respective data sources required for that automated software tests.6.The system of claim 1, wherein the first test group requires data from at least a third data source to be performed and wherein the second test group requires data from at least a fourth data source to be performed.7.The system of claim 1, wherein the operations further comprise: performing sequential execution of tests within at least one of the first test group or the second test group.8.The system of claim 1, wherein the operations further comprise: aggregating into a first temporary group the first automated software test; aggregating into a second temporary group the second automated software test; and generating a particular test group from the first temporary group and the second temporary group.9.A method, comprising: accessing, by a computer system, a plurality of automated software tests, wherein the plurality of automated software tests are configured to test one or more functions of an application; analyzing, by the computer system, the plurality of automated software tests to identify at least a first data source and a second data source that are used to respectively perform at least first and second automated software tests of the plurality of automated software tests; the computer system generating test groups including a first test group comprising the first automated software test and a second test group comprising the second automated software test, wherein the generating is based on an aggregation of automated software tests according to data sources used to perform those automated software tests, and wherein each test group comprises one or more tests associated with non-overlapping data sources; and the computer system performing parallel execution of the test groups, including the first and second test groups, on the application.10.The method of claim 9, wherein the first automated software test is configured to activate a service in the application that modifies data in the first data source.11.The method of claim 10, wherein modifying one or more values of the data determines behavior of the service in the application.12.The method of claim 9, wherein the first data source comprises a first database accessible via a network, and wherein the second data source comprises a second database accessible via the network.13.The method of claim 12, wherein the first database is hosted on a first computing device, and wherein the second database is hosted on a separate, second computing device.14.The method of claim 9, wherein a particular automated software test in the first group and a particular automated software test in the second group both use data from least one particular data source other than the first and second data sources.15.The method of claim 9, wherein the application is an analytics application.16.The method of claim 9, wherein the application is a payments application configured to allow electronic transfer of monetary amounts between different users of the application.17.A non-transitory computer-readable medium having stored thereon instructions that are executable by a computer system to cause the computer system to perform operations comprising: accessing a plurality of automated software tests, wherein the plurality of automated software tests are configured to test one or more functions of an application; analyzing the plurality of automated software tests to identify at least a first data source and a second data source that are used to respectively perform at least first and second automated software tests of the plurality of automated software tests; generating test groups including a first test group comprising the first automated software test and a second test group comprising the second automated software test, wherein the generating is based on an aggregation of automated software tests according to data sources used to perform those automated software tests, and wherein each test group comprises one or more tests associated with non-overlapping data sources; performing parallel execution of the test groups, including the first and second test groups, on the application; and recording results of the execution of the test groups.18.The non-transitory computer-readable medium of claim 17, wherein the first test group requires data from at least a third data source to be performed and wherein the second test group requires data from at least a fourth data source to be performed.19.The non-transitory computer-readable medium of claim 17, wherein the operations further comprise: performing sequential execution of tests within at least one of the first test group or the second test group.20.The non-transitory computer-readable medium of claim 17, wherein the operations further comprise: aggregating into a first temporary group the first automated software test; aggregating into a second temporary group the second automated software test; and generating a particular test group from the first temporary group and the second temporary group.","Description":"TECHNICAL FIELDThe disclosure generally relates to testing applications, and more specifically to optimizing regression testing of analytics applicationsBACKGROUNDAutomation tools perform thousands and thousands of tests on applications before the applications are rolled out into a real-world and utilized by other applications, servers, client devices and/or users. When testing analytics applications, automation tools use different data sources, such as database tables, static and dynamic files, live data feeds, etc., that are injected with data. The data may have particular values that trigger functionality being tested in the analytics application. The automation tools then validate the output data from the tests against the benchmark data that includes the expected results.The thousands of tests that test an application are stored in a test automation suite. As the application evolves and develops, more features and services are added to the application. To test the new features and services, new tests are created and integrated into the test automation suite. This causes the size of the test automation suite to grow and include more and more tests.Typically, before the application is rolled out into a real-world, automation tools perform regression testing on the application. During regression testing, most or all tests in the test automation suite are executed against the application, and the output data is validated against the expected test results. Because there are thousands of tests in the test automation suite, regression testing is a time consuming process which may take several hours. Further, when one or more tests during the regression testing fail, the errors in the application are fixed. After the fix, the automation tools re-execute regression tests in the test automation suite against the application to ensure application stability. This process may be performed multiple times until the application passes most or all tests in the test automation suite.Regression testing takes several hours for numerous reasons. First, there may be thousands of tests in the test automation suite that are executed against the application. Second, these tests are performed sequentially which causes the total execution time to be the sum of the execution times of all executed tests. Tests are performed sequentially because multiple tests may depend on data from the same data sources, and parallel execution of these tests may cause the tests to overwrite data in the one or more data sources. This in turn, may cause subsequent tests to fail because the application may execute subsequent tests using data in the data sources that has been overwritten by other tests.An alternative approach to reduce time required for regression testing is to create multiple copies of the testing environment. In this way, tests that access the same data sources may execute in parallel, but in different testing environments and not overwrite data stored in the data sources. But this solution is also expensive. First, the testing environment administrator needs to configure and maintain multiple testing environments. Second, the multiple testing environments require additional computing hardware and software to function and conduct the tests. Moreover, this solution may not be scalable as the test automation suite grows, and more and more tests are added into the test automation suite.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 is a block diagram of a system environment where embodiments can be implemented.FIG. 2 is a block diagram of a testing environment, according to an embodiment.FIG. 3 is a block diagram of a test separator, according to an embodiment.FIG. 4 is a block diagram of a group analyzer, according to an embodiment.FIG. 5 is a block diagram of a test processor performing parallel execution of test groups, according to an embodiment.FIG. 6 is a flowchart of a method for generating tests that can execute in parallel, according to an embodiment.FIG. 7 is a block diagram of a computer system suitable for implementing one or more components in FIGS. 1-5, according to an embodiment.Embodiments of the disclosure and their advantages are best understood by referring to the detailed description that follows. It should be appreciated that like reference numerals are used to identify like elements illustrated in one or more of the figures, wherein showings therein are for purposes of illustrating embodiments of the disclosure and not for purposes of limiting the same.DETAILED DESCRIPTIONThe detailed description set forth below, in connection with the appended drawings, is intended as a description of various configurations and is not intended to represent the only configurations in which the concepts described herein may be practiced. The detailed description includes specific details for the purpose of providing a thorough understanding of the various concepts. However, it will be apparent to those skilled in the art that these concepts may be practiced without these specific details. In some instances, well-known structures and components are shown in block diagram form in order to avoid obscuring such concepts.The disclosure provides systems, methods, and computer program products that determine regression tests that may be executed in parallel when testing an analytics application and thus reduce time for testing the application. The tests that test the application are stored in a test automation suite. As the application evolves, additional tests are incorporated into the test automation suite, and the test automation suite grows to include thousands of tests. During regression testing, the application needs to execute and validate most or all tests in the test automation suite before the application is released into a real-world environment. Further, regression testing may be performed multiple times when one or more tests fail. In this case, the function or service that caused the application to fail is fixed, and the regression testing is performed from the beginning. This process may be repeated until the application no longer fails one or more tests.Each test in the test automation suite tests a particular function, service, etc., of the application, causes the application to process data, and compares the output of the function, service, etc., against benchmark data. The tests cause the application to receive and process data from multiple data sources. When multiple tests request the same data from the same data source, one of these tests may inadvertently fail not because of an error in the application, but because another test had already modified the value of the data and caused the application to behave in an unexpected way.To prevent the inadvertent failure of the test, the testing environment that regression tests the application executes some of the tests in parallel and other tests in sequence. To determine the tests that can be executed in parallel, the data sources that are associated with each test are identified. The data sources may be identified by examining syntax of each test and identifying regular expressions or annotations in the test. The tests that have common data sources are aggregated into temporary groups.From the temporary groups, test groups are generated. Each test group includes tests from one or more temporary groups, such that data sources that are associated with the tests in each test group do not overlap with other test groups. In this way, the data sources used by tests in each test group are mutually exclusive from the data sources used by the tests in the other test groups.Once the test groups are generated, a test group automation suite is created for each test group. The testing environment then optimizes regression testing by executing tests in the test group automation suite in parallel with tests from other test group automation suites. The test within the test group automation suite may be executed sequentially. As a result, tests that are associated with different data sources can be executed in parallel within the testing environment. This reduces the amount of time that is required to regression test an application, and avoids the expense of having multiple testing environments.FIG. 1 is an exemplary system 100 where embodiments can be implemented. System 100 includes a network 102. Network 102 may be implemented as a single network or a combination of multiple networks. For example, in various embodiments, network 102 may include the Internet or one or more intranets, landline networks, wireless networks, and/or other appropriate types of networks. Network 102 may be a small scale communication network, such as a private or local area network, or a larger scale network, such as a wide area network or the Internet, accessible by the various components of system 100.Various components that are accessible to network 102 may be computing devices 104 and servers 106. Computing devices 104 may be portable and non-portable electronic devices under a control of a user and configured to transmit, receive, and manipulate data from servers 106 over network 102. Example computing devices 104 include desktop computers, laptop computers, tablets, smartphones, wearable computing devices, eyeglasses that incorporate computing devices, implantable computing devices, etc.Computing devices 104 may include one or more applications 108. Applications 108 may be pre-installed on the computing devices 104, installed on the computing devices 104 using portable memory storage devices, such as a compact disk or a thumb-drive, or be downloaded to the computing devices 104 from one or more servers 106. Applications 108 may be executed on the computing devices 104 and receive instructions and data from a user, from server 106, and communicate data to server 106.Example applications 108 installed on computing devices 104 may be analytics applications. Analytics applications perform business logic, provide services, and measure and improve performance of services and functions of other applications that execute on computing devices 104 based on current and historical data. In an embodiment, applications 108 may also be included as components of various services applications that are configured to transfer money world-wide, receive payments for goods and services, manage money spending, etc., which may be under an ownership or control of a payment service provider, such as PAYPAL\u00ae, Inc. of San Jose, Calif., USA, a telephonic service provider, a social networking service provider, and/or other service providers. In another embodiment, applications 108 may also be included as components of security applications for implementing client-side security features, programmatic client applications for interfacing with appropriate application programming interfaces (APIs) over network 102, communication applications, such as email, texting, voice, and instant messaging applications that allow a user to send and receive emails, calls, texts, and other notifications through network 102. In yet another embodiment, applications 108 may be included in financial applications, such as banking, online payments, money transfer, or other applications, location detection applications, such as a mapping, compass, and/or global positioning system (GPS) application. Further, applications 108 may be included in social networking applications and/or merchant applications device interfaces and other display modules that may receive input and/or output information, software programs, executable by a processor, including a graphical user interface (GUI) configured to provide an interface to the user, etc.Computing devices 104 may further include a database 110 stored in a transitory and/or non-transitory memory of computing devices 104. The database 110 may store data and be utilized during execution of various modules of computing devices 104. Database 110 may also serve as a data source (described below) that provides data to applications 108. Example data stored in database 110 may include data that is provided, processed and manipulated by applications 108, and may include IDs such as data source IDs, IDs associated with hardware of computing devices 104, or other appropriate IDs, such as IDs used for payment/user/device authentication or identification.Computing devices 104 may also include at least one communication module 112 adapted to communicate with server 106 over network 102. In various embodiments, communication module 112 may include a DSL (e.g., Digital Subscriber Line) modem, a PSTN (Public Switched Telephone Network) modem, an Ethernet device, a broadband device, a satellite device and/or various other types of wired and/or wireless network communication devices including microwave, radio frequency, infrared, Bluetooth, and near field communication devices.As described above, server 106 is also connected to network 102. Server 106 may be an application executing on a computing device that provides services and data to applications 108 that execute on computing devices 104. Server 106 may also be maintained by a service provider, such as PAYPAL, a telephonic service provider, social networking service, and/or other service providers. Server 106 may be a cloud server, storage server, web server, or another type of server that is accessible over network 102, and that can receive, transmit, process, aggregate, etc., data on behalf of multiple computing devices 104.In an embodiment, server 106 also stores and executes applications 114. Applications 114 may be counterparts to applications 108 executing on computing devices 104 and may receive, process, and transmit data to applications 108. Thus, applications 114 may also be analytics applications that are incorporated into services application configured to transfer money world-wide, receive payments for goods and services, manage money spending, etc. In an embodiment, applications 114 may also be incorporated into security applications configured to implement client-side security features, programmatic client applications for interfacing with appropriate application programming interfaces (APIs) over network 102. In another embodiment, applications 114 may also be incorporated into communication applications that use analytics to perform email, texting, voice, and instant messaging functions that allow a user to send and receive emails, calls, texts, and other notifications through network 102. In yet another embodiment, applications 114 may be incorporated into financial applications, such as banking, online payments, money transfer, or other applications. In yet another embodiment, applications 114 may be incorporated into location detection applications, such as a mapping, compass, and/or GPS applications. In yet another embodiment, applications 114 may also be incorporated into social networking applications and/or merchant applications.In an embodiment, server 106 also includes a communication module 116. Communication module 116 is adapted to communicate with network 102, and transmit data to communication device 104. For example, communication module 116 may be adapted to transmit and receive data from applications 114 to applications 108, and vice versa.In an embodiment, system 100 includes one or more data sources 118. Data sources 118 store and/or broadcast data over network 102 or directly to server 106. Data sources 118 may be under control of server 106, or be third-party data sources that transmit data or make data accessible to applications 114 that execute on server 106. Example data sources 118 may include databases, data feeds, file storage systems, static and dynamic files, memory caches, etc. Additionally, data sources 118 may also be incorporated into computing devices 104, such as database 110, and may store a subset of data on computing devices 104 that is also available to servers 106.In an embodiment, prior to applications 108 and/or applications 114, or components, sub-components, or new versions thereof being installed on computing devices 104 and/or servers 106, applications 108 and/or applications 114 are installed and tested in a testing environment. A testing environment may include computing devices 104, servers 106, data sources 118 or any combination, sub-combination, or emulators, thereof. Further, the testing environment may be connected to network 102, or be a standalone environment. Also data in the testing environment may be injected or preloaded into data sources 118, so that the data can activate and validate specific services or functions of applications 108 and/or applications 114.FIG. 2 is a block diagram of a testing environment 200, according to an embodiment. As described above, testing environment 200 may be implemented using one or more devices described in FIG. 1, which are collectively referred to as a testing device 201. Testing device 201 may also include some or all components described in detail in FIG. 7.In an embodiment, testing environment 200 tests an exemplary application 202. Application 202 may be a test version of one of applications 108, 114, or a combination thereof, before the application is released into system 100. In an embodiment, application 202 may be an analytics application. As described above, analytics applications may be data value dependent applications, such that specific values of data may activate certain functions and services in application 202.In an embodiment, application 202 may be loaded into memory of testing device 201. Once loaded, application 202 may be executed and tested on testing device 201, before application 202 is released into system 100.To test application 202, testing environment 200 includes a test automation suite 204. The test automation suite 204 may be stored in a memory storage, such as one of memory storages described in detail in FIG. 7. Further, the memory storage may be included in or communicatively coupled to the testing device 201. In an embodiment, test automation suite 204 includes hundreds or thousands of tests 206 that may be conducted on application 202. One or more tests 206 may have different test cases that test a particular portion, code, service, function, module, etc., of application 202 and ensure that application 202 behaves as expected when loaded and executed by users, computing devices 104, servers 106, etc. Example tests 206 may cause application 202 to receive data from one or more data sources 118. The data and/or value of the data may trigger different services, functions, etc., in the application 202 that process the data. Tests 206 then parse and validate the data output generated by the different services, functions, etc., of application 202 and compare the data output against benchmark or expected data. Validation of the data output may identify faults, errors, defects, etc., in application 202 that may be rectified before application 202 is installed in system 100. In an embodiment, testing device 201 executes and validates most, all, or a percentage of tests 206 in test automation suite 202 against application 202 before application 202 may be installed in system 100.As discussed above, tests 206 may test how application 202 receives and processes data, such as data from one or more data source(s) 118. Example data sources 118 shown in FIG. 2 are data sources 118A-G, and may include data stored in database systems, files systems, static files, dynamic files, memory caches, etc. Also, the services and functions of application 202 that are activated during the one or more tests 206 may depend on a value of data, type of data, etc. Because, tests 206 may depend on the value and type of data from data sources 118A-G, testing device 201 may also be configured to receive data from data sources 118A-G, inject data required for tests 206 into data sources 118A-G, or emulate data that is received from one or more data sources 118A-G, such that the data triggers services and functions that are tested by tests 206. Further, because one or more tests 206 depend on the value of data, testing device 201 may conduct tests 206 that receive data from the same data source 118, such as data source 118A in a specified order. The order ensures that the value of the data remains the same or is modified in a specified order when multiple tests 206 cause application 202 to read and write data from data source 118A. In this way, tests 206 may not fail when application 202 works as expected, even though the tests were conducted out of order.In an embodiment, to optimize tests 206 conducted on application 202, testing device 201 includes a test separator 208 and a group analyzer 210. Test separator 208 and group analyzer 210 may be hardware or software modules, or combinations thereof, that optimize the amount of time testing device 201 executes tests 206 from the test automation suite 204 on application 206. To optimize the amount of time application 202 runs tests 206, test separator 208 and group optimizer 210 separate tests 206 into test groups according to data sources 118A-G that are used in each test 206. In an embodiment, a subset of tests 206 in each test group receives data from a non-overlapping subset of data sources 118A-G that are specific to the test group. In this way, tests 206 are separated so that tests 206 from different test groups do not modify data from the same data source, and do not overwrite the values of the data which may cause one or more tests 206 to unintentionally fail.In an embodiment, test separator 208 separates tests 206 into temporary groups according to data sources 118A-G. One way to separate tests 206 into temporary groups is to identify data sources 118A-G that are associated with each test in tests 206. Test separator 208 then aggregates tests 206 that are associated with the same one or more data sources 118A-G into a temporary group. To identify data sources 118A-G associated with each test in tests 206, test separator 208 may parse the syntax of tests 206 and identify regular expressions or annotations in each test 206 that are associated with or identify a particular data source 118. In another example, test separator 208 may also identify function calls that request data from one or more data sources 118. In yet another example, test separator 208 may parse the configuration file associated with tests 206 and use the configuration file to identify data sources 118 used by each test. Further, a person of ordinary skill in the art will appreciate that the above examples that identify data sources 118 associated with each test are not limiting and that test separator 208 may use other methodologies to identify data sources 118 that are associated with each test.FIG. 3 is a block diagram 300 of a test separator 208, according to an embodiment. As discussed with reference to FIG. 2, test separator 208 separates tests 206 into temporary groups. As illustrated in FIG. 3, test separator 208 receives exemplary tests 206A-N and separates tests 206A-N into six exemplary temporary groups, such as temporary groups 302A, 302B, 302AB, 302BCD, 302FG, and 302E. To generate temporary groups 302A, 302B, 302AB, 302BCD, 302FG, and 302E, test separator 208 parses tests 206A-N and determines that data source 118A is associated with test 206A, and places test 206A into temporary group 302A. Test separator 208 also determines that data source 118B is associated with test 206B and places test 206B into temporary group 302B. Next, test separator 208 determines that data sources 118A and 118B are associated with test 206C, and place test 206C into temporary group 302AB. Test separator 208 also parses test 206D and determines that data sources 118B, 118C, and 118D are associated with test 206D. Test separator 208 then places test 206D into temporary group 302BCD. Next, test separator 208 parses test 206E and determines that data sources 118F and 118G are associated with test 206E, and places test 206E into temporary group 302FG. Additionally, test separator 208 parses test N and determines that data source 118E is associated with test 206N. Test separator 208 then places test 206N into temporary group 302E.Going back to FIG. 2, once test separator 208 determines temporary groups 302, group analyzer 210 generates test groups from temporary groups 210. In an embodiment, group analyzer 210 aggregates one or more temporary groups 302 into a test group such that each test group includes tests 206 that utilize data from non-overlapping data sources 118. In other words, temporary groups 302 that include tests 206 that access the same data sources 118 are aggregated into a single test group. In this way, testing device 201 can execute different test groups in parallel without risking that tests 206 in different test groups may cause application 202 to overwrite data in one or more data sources 118.FIG. 4 is a block diagram 400 of a group analyzer 210, according to an embodiment. As described above, group analyzer 210 aggregates temporary groups 302 into test groups. As illustrated in FIG. 4, group analyzer 210 receives temporary groups 302A, 302B, 302AB, 302BCD, 302FG, and 302E that were generated by test separator 208 in FIG. 3. Group analyzer 210 then generates test groups 402, such as 402ABCD, 402FG, and 402G from the temporary groups 302A, 302B, 302AB, 302BCD, 302FG, and 302E.In an embodiment, group analyzer 210 generates test groups 402 such that each one of data sources 118A-G is associated with a single test group 402. Further, group analyzer 210 aggregates temporary groups 302 that include tests 206 that are associated with overlapping data sources 118 into a single test group 402. For example, group analyzer 210 aggregates temporary groups 302A, 302B, and 302AB into a single test group ABCD because temporary group 302AB includes test 206C that is associated with data sources 118A and 118B. Group analyzer 210 also adds temporary group 302BCD into test group ABCD because test 206D in temporary group 302BCD utilizes data from data source 118B.In an embodiment, group analyzer 210 also generates test group 402FG from temporary group 302FG. As illustrated in FIG. 4, the group analyzer 210 does not add additional temporary groups 302 into test group 402G because the other temporary groups 302 do not include tests 206 that are associated with either data source 118F or data source 118G. Similarly, group analyzer 210 generates test group 402E from temporary group 302E, and does not add additional temporary groups 302 into test group 402E because other tests 206 are not associated with data source 118E.Going back to FIG. 2, in an embodiment, once group analyzer 210 generates the test groups 402, group analyzer 210 may also generate test group automation suites 218. In an embodiment, there may be one test group automation suite 218 per test group 402. The test group automation suite 218 may then include tests 206 that are included in the test group 402. For example, tests 206A, 206B, 206C, and 206D from test group 402ABCD illustrated in FIG. 4 may be included in a single test group automation suite 218. In another embodiment, there may be multiple test groups 402 in a single test group automation suite 218 as long as the test groups in the test group automation suite 218 do not read and write data from the same data sources 118. For example, tests 206E and 206N from test groups 402FG and 402E illustrated in FIG. 4 may be included in a single test group automation suite 218.In an embodiment, testing environment 200 also includes a test processor 212. Test processor 212 may be included in or coupled to testing device 101. Test processor 212 may also execute tests 206 in the test automation suite 204 on application 202 and generate test results 216. The test results 216 may include output data from multiple tests 206 that test processor 212 has compared and verified against the expected results or benchmark data. In a further embodiment, test processor 212 may optimize the execution of tests 206 by executing tests 206 in test group automation suites 218 in parallel with each other. Such parallel execution may be possible because tests 206 in different test group automation suites 218 may execute independently of each other as these tests 206 utilize data from different data sources 118. In this way, tests 206 in different test group automation suites 218 do not overwrite data in the same data source 118, which may cause tests 206 to fail due to corrupted data and not errors in application 202.FIG. 5 is a block diagram 500 of a test processor executing test group automation suites in parallel, according to an embodiment. As illustrated in FIG. 5, test processor 212 executes test group automation suites 218, such as test group automation suites 218A-C, in parallel with each other. Test group automation suites 218A-C include test groups 402, such that test group automation suite 218A includes test group 402ABCD, test group automation suite 218B includes test group 402FG, and test group automation suite 218C includes test group 402E. As discussed above, test group 402ABCD includes tests 206A, 206B, 206C, and 206D, test group 402FG includes test 206E, and test group 402E includes test 206N.In an embodiment, test processor 212 executes tests 206A-N in test groups 402ABCD, 402FG, and 402E in parallel with each other. In this case, test processor 212 executes tests 206A, 206B, 206C, and 206D from test group 402ABCD sequentially because tests 206A, 206B, 206C, and 206D receive and process data from common data sources 118A-D. However, test processor 212 executes test 206E that receives and processes data from data sources 118F and 118G in parallel with tests 206A, 206B, 206C, and 206D. Similarly, test processor 212 executes test 206N that receives and processes data from data source 118E in parallel with tests 206A, 206B, 206C, 206D, and 206E.In an embodiment, because test group automation suites 218A-C execute in parallel, test processor 212 may determine the maximum execution time for tests 206A-N as the maximum execution time of tests in test group 402ABCD, tests in test group 402FG or tests in test group 402E. In other words, the maximum execution time of tests 206A-N is the execution time of the longest executing test group.In a further embodiment, as tests 206A, 206B, 206C, 206D, 206E and 206N execute, test processor 212 generates test results 216. Test results 216 include tests results of each one of tests 206A, 206B, 206C, 206D, 206E and 206N, which may include data output from the tests as compared against expected results or benchmark data. Further, if test results 216 indicate that one or more of tests 206A, 206B, 206C, 206D, 206E or 206N fail, test processor 212 may re-execute tests 206A, 206B, 206C, 206D, 206E and 206N in parallel according to test groups 402ABCD, 402FG, and 402E.FIG. 6 is a flowchart of a method 600 for determining tests that can execute in parallel, according to an embodiment. Method 600 may be performed using hardware and/or software components described in FIGS. 1-5. Note that one or more of the operations may be deleted, combined, or performed in a different order as appropriate. Further, additional operations may be performed at various stages of the method.At operation 602, tests in the test automation suite are accessed. For example, testing device 201 accesses tests 206 in the test automation suite 204 that are used in regression testing of application 202. As described above, application 202 may be an analytics application that may be tested with value dependent data, and each test 206 may cause a service, function, etc., of application 202 to receive, process, and modify data stored in data sources 118. As also described above, tests 206 in the test automation suite 204 may be stored within testing device 201 or be stored in another memory storage that is coupled to the testing device 201.At operation 604, data sources for each test are identified. For example, for each test in tests 206, test separator 208 identifies data sources 118 that are associated with the test. In an embodiment, test separator 208 may examine syntax of each test and identify regular expressions or annotations in the test that indicate that the test uses one or more data sources 118.At operation 606, tests are aggregated into temporary groups. For example, test separator 208 aggregates tests 206 into temporary groups 302 according to the data sources 118 identified for each test in operation 604. In an embodiment, tests 206 that have the same data sources 118 are aggregated into the same temporary group 302.At operation 608, test groups are generated. For example, group analyzer 210 generates test groups 402 from the temporary groups 302, such that temporary groups 302 that include tests with overlapping data sources 118 are in the same test group. In this way, each data source 118 may be associated with one or more tests 206 in a single test group of test groups 402.At operation 610, test group automation suites are generated. For example, group analyzer 210 generates test group automation suites 218. In an embodiment, group analyzer 210 generates a test group automation suite for each test group in test groups 402.At operation 612, test group automation suites are executed. For example, test processor 212 tests application 202 using tests 206. In an embodiment, test processor 212 executes tests 206 in different test group automation suites 218 in parallel with each other. In this way, tests 206 from different test group automation suites 218 may execute in parallel without modifying data stored in data sources 118 which may cause subsequent tests 206 to fail.Referring now to FIG. 7 an embodiment of a computer system 700 suitable for implementing, the systems and methods described in FIGS. 1-6 is illustrated.In accordance with various embodiments of the disclosure, computer system 700, such as a computer and/or a server, includes a bus 702 or other communication mechanism for communicating information, which interconnects subsystems and components, such as a processing component 704 (e.g., processor, micro-controller, digital signal processor (DSP), graphics processing unit (GPU), etc.), a system memory component 706 (e.g., RAM), a static storage component 708 (e.g., ROM), a disk drive component 710 (e.g., magnetic or optical), a network interface component 712 (e.g., modem or Ethernet card), a display component 714 (e.g., CRT or LCD), an input component 718 (e.g., keyboard, keypad, or virtual keyboard), a cursor control component 720 (e.g., mouse, pointer, or trackball), a location determination component 722 (e.g., a Global Positioning System (GPS) device as illustrated, a cell tower triangulation device, and/or a variety of other location determination devices known in the art), and/or a camera component 723. In one implementation, the disk drive component 710 may comprise a database having one or more disk drive components.In accordance with embodiments of the disclosure, the computer system 700 performs specific operations by the processor 704 executing one or more sequences of instructions contained in the memory component 706, such as described herein with respect to the mobile communications devices, mobile devices, and/or servers. Such instructions may be read into the system memory component 706 from another computer readable medium, such as the static storage component 708 or the disk drive component 710. In other embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the disclosure.Logic may be encoded in a computer readable medium, which may refer to any medium that participates in providing instructions to the processor 704 for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. In one embodiment, the computer readable medium is non-transitory. In various implementations, non-volatile media includes optical or magnetic disks, such as the disk drive component 710, volatile media includes dynamic memory, such as the system memory component 706, and transmission media includes coaxial cables, copper wire, and fiber optics, including wires that comprise the bus 702. In one example, transmission media may take the form of acoustic or light waves, such as those generated during radio wave and infrared data communications.Some common forms of computer readable media includes, for example, floppy disk, flexible disk, hard disk, magnetic tape, any other magnetic medium, CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, RAM, PROM, EPROM, FLASH-EPROM, any other memory chip or cartridge, carrier wave, or any other medium from which a computer is adapted to read. In one embodiment, the computer readable media is non-transitory.In various embodiments of the disclosure, execution of instruction sequences to practice the disclosure may be performed by the computer system 700. In various other embodiments of the disclosure, a plurality of the computer systems 700 coupled by a communication link 724 to the network 102 (e.g., such as a LAN, WLAN, PTSN, and/or various other wired or wireless networks, including telecommunications, mobile, and cellular phone networks) may perform instruction sequences to practice the disclosure in coordination with one another.The computer system 700 may transmit and receive messages, data, information and instructions, including one or more programs (i.e., application code) through the communication link 724 and the network interface component 712. The network interface component 712 may include an antenna, either separate or integrated, to enable transmission and reception via the communication link 724. Received program code may be executed by processor 704 as received and/or stored in disk drive component 710 or some other non-volatile storage component for execution.Where applicable, various embodiments provided by the disclosure may be implemented using hardware, software, or combinations of hardware and software. Also, where applicable, the various hardware components and/or software components set forth herein may be combined into composite components comprising software, hardware, and/or both without departing from the scope of the disclosure. Where applicable, the various hardware components and/or software components set forth herein may be separated into sub-components comprising software, hardware, or both without departing from the scope of the disclosure. In addition, where applicable, it is contemplated that software components may be implemented as hardware components and vice-versa.Software, in accordance with the disclosure, such as program code and/or data, may be stored on one or more computer readable mediums. It is also contemplated that software identified herein may be implemented using one or more general purpose or specific purpose computers and/or computer systems, networked and/or otherwise. Where applicable, the ordering of various steps described herein may be changed, combined into composite steps, and/or separated into sub-steps to provide features described herein.The foregoing disclosure is not intended to limit the disclosure to the precise forms or particular fields of use disclosed. As such, it is contemplated that various alternate embodiments and/or modifications to the disclosure, whether explicitly described or implied herein, are possible in light of the disclosure. Having thus described embodiments of the disclosure, persons of ordinary skill in the art will recognize that changes may be made in form and detail without departing from the scope of the disclosure. Thus, the disclosure is limited only by the claims.","Export Citation":"Click for automatic bibliographygeneration","Field of Search":"717/124","Filing Date":"09/28/2020","International Classes":"G06F11/36; G06F8/71","Inventors":"Koplovich, Eyal (Kfar Haroe, IL)Lifschitz, Lucia (Tel Aviv, IL)Emanueli, Amir (Givatayim, IL)","Parent Case Data":"CROSS-REFERENCE TO RELATED APPLICATIONSThis application is a continuation of U.S. patent application Ser. No. 15/194,285, filed Jun. 27, 2016, and entitled \u201cTest Execution Optimizer For Test Automation,\u201d the entire disclosure of which is incorporated herein by reference in its entirety.","Primary Examiner":"HUDA, MOHAMMED NURUL","Publication Date":"11/01/2022","Title":"Test execution optimizer for test automation","US Patent References":"20130152047SYSTEM FOR DISTRIBUTED SOFTWARE QUALITY IMPROVEMENT2013-06-13Moorthi et al.717/12420110296384Mechanism for Performing Dynamic Software Testing Based on Grouping of Tests Using Test List Entity2011-12-01Pasternak717/1247099791System and method for linking and loading compiled pattern data2006-08-29Fritzsche717/162","View Patent Images":"Download PDF 11487647"},"United States Patent 8185782":{"Abstract":"A test device for a hierarchical test architecture is disclosed. The architecture includes cores for plural test layers, a top-level data register, and a top-level test controller. Cores for each test layer are hierarchical test circuits. The top-level test controller retrieves plural control signals, controls the top-level data register based on first type control signals in the control signals, and controls each core based on second type control signals in the control signals.","Application Number":"12/324795","Assignee":"Industrial Technology Research Institute (Hsinchu, TW)","Attorney, Agent or Firm":"QUINTERO LAW OFFICE, PC (Venice, CA, US)","Claims":"What is claimed is:1.A test device for controlling a hierarchical test architecture, comprising: a top test level, comprising: a top level data register; and a top level test controller, obtaining a plurality of test control signals and generating a plurality of control signals, wherein the control signals comprise a first set of control signals and a second set of control signals, and controlling the top level data register using the first set of control signals; and a next test level, composed of one or more cores having a test wrapper, wherein the core is controlled by the top level test controller using the second set of control signals, an instruction decoder, an instruction register, a multiplexer and a state register, wherein the instruction register receives the data from a test data input signal and stores the data from the test data input signal as a test instruction, the instruction decoder is connected to output ports of the instruction register for receiving the test instruction, and the multiplexer selects a register connected to the standard test output port of the controller based on the test instruction and the value of the state register.2.The test device as claimed in claim 1, wherein the test control signals are composed of a test mode select signal and a test clock signal.3.The test device as claimed in claim 1, wherein the first set of control signals is generated by the top level test controller for controlling the control signals of the data register.4.The test device as claimed in claim 1, wherein the second set of control signal comprises the test control signals and a set of wrapper serial control signals, wherein the set of wrapper serial control signals is generated by the top level test controller and is in compliance with the IEEE 1500 standard serial test control signal.5.The test device as claimed in claim 1, wherein the core of the next test level is the hierarchical test circuit or the core is wrapped in compliance with the IEEE 1149.1 or 1500 standard test wrapper.6.The test device as claimed in claim 5, wherein the control signals connected to the core are the test mode select signal and the test clock signal of the second set of control signals when the core connected to the control signals are wrapped in compliance with the IEEE 1149.1 standard test wrapper.7.The test device as claimed in claim 5, wherein the control signals are the wrapper control signal of the second set of control signals when the core connected to the control signals are wrapped in compliance with the IEEE 1500 standard test wrapper.8.The test device as claimed in claim 5, wherein if there is a hierarchical test circuit in the core, one or more cores can be added to the hierarchical test circuit as the cores of the next test level of the hierarchical test circuit.9.The test device as claimed in claim 5, wherein the cores of the next test level comprises one or more hierarchical test circuits.10.The test device as claimed in claim 5, wherein if there are no hierarchical test circuits in the next test level, the next test level does not comprise any further next test level.11.The test device as claimed in claim 5, wherein the hierarchical test circuit comprises: a test level, composed of a hierarchical test controller and a data register; and a next test level, composed of one or more cores.12.The test device as claimed in claim 11, wherein the hierarchical test controller obtains a plurality of test control signals and generates a plurality of control signals by using the test control signals, wherein the control signals comprise a first set of control signals and a second set of control signals, and controls the data register using the first set of control signals; and a next test level, composed of one or more cores having a test wrapper, wherein the cores are controlled by the hierarchical test controller using the second set of control signals.13.The test device as claimed in claim 12, wherein the test control signals are composed of a test mode select signal and a test clock signal.14.The test device as claimed in claim 12, wherein the first set of control signals is generated by the hierarchical test controller for controlling the control signals of the data register.15.The test device as claimed in claim 12, wherein the second set of control signals comprises the test control signals and a set of wrapper serial control signals, wherein the set of wrapper serial control signals is generated by the hierarchical test controller and wrapped in compliance with the IEEE 1500 standard serial test control signal.16.The test device as claimed in claim 1, wherein the top level data register is composed of a boundary-scan register, a bypass register and an optional user-defined data register.17.The test device as claimed in claim 1, wherein the number of the cores is not a fixed number.18.The test device as claimed in claim 1, wherein if there is a next test level in a test level, at least one of the cores has a hierarchical structure, and other cores are in compliance with IEEE 1149.1 or IEEE 1500 test standard.19.The test device as claimed in claim 1, wherein if there is only one core in the next test level, the core is a hierarchical test circuit.20.The test device as claimed in claim 1, wherein the top test level comprises a hierarchical test controller, and each test level of the next and further test levels comprise one or more cores in compliance with the IEEE 1149.1, IEEE 1500 or have a hierarchical test structure.21.The test device as claimed in claim 20, wherein the control signals further comprise a control signal for controlling the operation of the test wrapper of the next test level, and a control signal for controlling whether the instruction register of the next level should operate or not.22.The test device as claimed in claim 21, wherein the control signal for controlling whether the instruction registers of cores of the next level should operate or not controls the instruction register of the level and the instruction registers of cores of the next level, and the instruction register of the level can receive a test instruction when the control signal is disabled, and the instruction register of the level can not receive the test instruction and the instruction registers of the cores of the next level can receive the test instruction, when the control signal is enabled.23.The test device as claimed in claim 21, wherein the control signal for controlling whether the instruction registers of cores of the next level should operate or not and a Clock-IR signal of the level are connected to two inputs of an OR gate, and an output port of the OR gate is connected to the clock signal of the instruction register of the level.24.The test device as claimed in claim 21, wherein the control signal for controlling whether the instruction registers of cores of the next level should operate or not is first connected to an input of an inverter, the output of the inverter and the Shift-IR signal of the level are connected to two inputs of an AND gate, and the output port of the AND gate is connected to the shift enable signal of the instruction register of the level.25.The test device as claimed in claim 20, wherein the control signal for controlling the operation of the test wrapper of the next test level controls all instruction registers and all data register of all cores of the next level, one or more instruction registers and data registers of the next level can not receive the test instruction and receive or output the test data when the control signal is disabled, and the instruction registers and the data registers of the cores of the next level can receive the test instruction and receive or output the test data when the control signal is enabled.26.The test device as claimed in claim 1, wherein the register is the instruction register or data register.27.The test device as claimed in claim 1, wherein the value of the state register is copied to a current state register when the test clock signal falls within the falling edge.28.The test device as claimed in claim 1, wherein the test controller is composed of a standard test access port finite state machine, a plurality of control signal registers and a plurality of control signals, the hierarchical test controller receives a plurality of signals from the outer test access port and generates a plurality of corresponding test states, and enables or disables the test control signals based on the test state and the instruction value stored in the instruction register.29.The test device as claimed in claim 20, wherein all of the state registers within the test controllers having the test access finite state machine are set with the same values.30.The test device as claimed in claim 27, wherein when the test clock signal changes to a rising edge, if the current state register is in a select-instruction register-scan state, a control signal of the test controller of the level for controlling whether the instruction registers of cores of the next level should operate or not is enabled, and the test mode select signal is 0, which indicates that the instruction registers of cores of the next test level are ready for receiving the next test instructions, and each control signal for controlling the operation of the test wrapper of the next test level of each level are enabled.31.The test device as claimed in claim 27, wherein when the next test clock signal changes to a rising edge, if the current state register is in a select-instruction register-scan state, a control signal of the test controller of the level for controlling whether the instruction registers of cores of the next level should operate or not is disabled, and the test mode select signal is 0, which indicates that the test controller of the level is ready for receiving the next test instruction, and each control signal for controlling whether the test wrapper of the next test level should operate or not are disabled.32.The test device as claimed in claim 27, wherein when the next test clock signal changes to a rising edge, if the current state register is in a select-data register-scan state, the instruction value of an instruction register of the test controller of the level is a hierarchical instruction and the test mode select signal is 1, which indicates that the instruction registers of the cores of the next level is ready for receiving test instructions, and a control signal of the test controller of the level for controlling whether the instruction registers of the cores of the next level should operate or not is enabled, and the instruction register of the test controller of the level is disabled, wherein the test instruction value stored in the instruction register remains.33.The test device as claimed in claim 27, wherein when the next test clock signal changes to a rising edge, if the current state register is in a select-data register-scan state, the instruction value of an instruction register of the test controller of the level is a hierarchical instruction, a control signal of the hierarchical test controller for controlling whether the instruction registers of the cores of the next level should operate or not is enabled, and the test mode select signal is 0, which indicates that the cores of the next level is ready for testing, and a control signal of the test controller of the level for controlling whether the instruction registers of the cores of the next level should operate or not is disabled, and the data registers of cores of the next level are enabled for receiving the test data.34.A test device for controlling a hierarchical test architecture, comprising: a plurality of test groups connected in parallel, wherein each test group comprises one or more cores; and a hierarchical test controller, inputting a plurality of test control signals into the test groups respectively, wherein each control signal corresponds to a test group respectively for testing the cores of each test group and controlling test outputs of the test groups, wherein a multiplexer is set by the test controller, by using different group test instructions for selecting different test groups, or setting a test group by a test group identifier in an identifier register.35.The test device as claimed in claim 34, wherein the test controller sets that the test data of the multiplexer is output through the test group when the test group identifier in the identifier register is similar to a test group identifier of a test group.36.The test device as claimed in claim 34, wherein each group test instruction corresponds to a test group, and the test controller set that the test data of the multiplexer is output, is output by the test group when the instruction register of the test controller is the group test instruction corresponding to the test group.37.The test device as claimed in claim 34, wherein only one group can be tested per testing, but a plurality of cores in the one group can be tested in parallel.38.The test device as claimed in claim 34, wherein each test flow executed by the cores can test one or more cores under test within the same test group.39.The test device as claimed in claim 34, wherein if any core within each test group is wrapped with the IEEE 1149.1 standard wrapper, then the test mode select signal and the test clock signal thereof are connected to the test mode select signal and the test clock signal corresponding to the outer test access port.40.The test device as claimed in claim 34, wherein if any core within each test group is wrapped with the IEEE 1500 standard wrapper, then the standard test control signal of the core is connected to the IEEE 1500 standard test control signal provided by the hierarchical test controller.41.The test device as claimed in claim 34, wherein if any core within each test group is wrapped with the IEEE 1500 standard wrapper, then the standard test control signal of the core is connected to the IEEE 1500 standard test control signal provided by the hierarchical test controller to the test group.","Description":"BACKGROUND OF THE INVENTION1. Field of the InventionThe invention relates to a System-on-a-Chip (SoC) test architecture, and more particularly to a test device for a hierarchical test architecture.2. Description of the Related ArtSystem-on-a-Chip (SoC) devices are widely used today. With combining more and more different functions (cores) from different sources, the fault coverage of a core-based SoC device has been decreased dramatically. In order to reduce the test complexity of a SoC device, and for the purpose of test reuse, the IEEE (Institute of Electrical and Electrical and Electronic Engineers) has defined IEEE 1500 test standard, the test standard for core-based design.FIG. 1 is showing the test wrapper defined by IEEE 1500.Conforming to IEEE 1500 standard, a test wrapper 120 is wrapped around a core 110. The test wrapper 120 includes an N-bit wrapper instruction register (WIR) (not shown) for storing a test instruction, a 1-bit wrapper bypass register (WBY) (not shown), a wrapper boundary register (WBR) 130 for storing test data, a serial interface layer 140 and a set of standard wrapper serial control (WSC), wherein WIR and WBY are included in the serial interface layer 140. In addition, the test circuit can access data registers (DR) inside the core for testing the core. This type of data register is called a core data register (CDR).In core-based design, another test standard, the IEEE 1149.1 standard can also be used, as shown in FIG. 2. The IEEE 1149.1 standard is designated for testing, and debugging a chip that is mounted on a printed-circuit board (PCB) and also for testing the interconnections between the chips that are mounted on the same PCB. Conforming to the IEEE 1149.1 standard, a core 210, a set of test access port (TAP) test signals (composed of TDI, TDO, TMS, TCK and optional TRST), a boundary-scan register (BSR, composed of serial linked boundary scan cells) 225 connected to input/output (I/O) ports 220 and an inner core 210, a user-defined data register (UDR) 230, an N-bit instruction register (IR) 240, a 1-bit bypass register 250, a TAP controller 260 and a multiplexer 270. The TAP controller 260 is composed of a finite state machine (FSM), a 4-bit state register and control circuits. FIG. 3 is a state diagram showing the FSM in the TAP controller 260, wherein all indicated states values are stored in the state register as the states of the state machine.For the IEEE 1149.1 standard, data registers and corresponding test instructions other than the standard mandatory and optional instructions can be defined. By using the TAP controller, users can control testing processes and testing data path of an integrated circuit (IC). In addition to PCB testing, the IEEE 1149.1 standard can also be used to test and debug the inner cores of a SoC.In addition, a core that is wrapped in a test wrapper conforming to the IEEE 1149.1 or IEEE 1500 standard may contain the other cores that are also wrapped in a test wrapper conforming to the IEEE 1149.1 or IEEE 1500 standard, the kind of test architecture may also be referred to as a hierarchical test architecture. In order to integrate the cores that are wrapped in the test wrappers conforming to the IEEE 1149.1 standard or IEEE 1500 standard and control the hierarchical test architecture, the present invention provides a test device and a method for a hierarchical test architecture.BRIEF SUMMARY OF THE INVENTIONA test device for controlling a hierarchical test architecture is provided, comprising: a top level test circuit, comprising: a top level data register; and a top level test controller, obtaining a plurality of test control signals and generating a plurality of control signals, wherein the control signals comprise a first set of control signals and a second set of control signals, and control the top level data register using the first set of control signals; and a next test level, composed of one or more cores having a test wrapper, wherein the core is controlled by the top level test controller using the second set of control signals.A detailed description is given in the following embodiments with reference to the accompanying drawings.BRIEF DESCRIPTION OF THE DRAWINGSThe invention can be more fully understood by reading the subsequent detailed description and examples with references made to the accompanying drawings, wherein:FIG. 1 is a schematic view showing the architecture of an IEEE 1500 standard test wrapper.FIG. 2 is a schematic view showing the architecture of an IEEE 1149.1 standard test access port and boundary scan.FIG. 3 is a state diagram showing a finite state machine within a TAP controller of the related art.FIG. 4A is a schematic view of a test device of a hierarchical test architecture of an embodiment of the present invention.FIG. 4B is a schematic view for explaining control signal connections in the test architecture of the embodiment of the present invention.FIG. 4C is a schematic view of the test device of the hierarchical test architecture of another embodiment of the present invention.FIG. 4D is a schematic view for explaining control signal connections in the test architecture of FIG. 4C during the operation flow of the instruction registers of the present invention.FIG. 4E is a schematic view for explaining control signal connections in the test architecture of FIG. 4C during the operation flow of the data registers of the present invention.FIG. 5 is a state diagram showing a finite state machine and changing of the control signals within a TAP controller of the hierarchical test controller of the embodiment of the present invention.FIG. 6A\u02dc6C is a timing diagram of signals in the hierarchical test controller of the embodiment of the present invention.FIG. 7 is a flowchart for explaining the test method for the hierarchical test architecture of the embodiment of the present invention.FIG. 8A is a schematic view showing a SoC mixed test architecture of the exemplary embodiment of the present invention.FIG. 8B is a schematic view showing a SoC mixed test architecture of another exemplary embodiment of the present invention.FIG. 9A is a schematic view of the IEEE 1149.1 standard instruction register controller.FIG. 9B is a schematic view of the instruction register controller of the embodiment of the present invention.FIG. 9C is a schematic view of the instruction register controller of another embodiment of the present invention.FIG. 10 is a schematic view showing the architecture of the IEEE 1149.1 standard TAP controller.FIG. 11 is a schematic view showing the architecture of the controller of the hierarchical test architecture of the embodiment of the present invention.DETAILED DESCRIPTION OF THE INVENTIONSeveral exemplary embodiments of the invention are described with reference to FIGS. 4 through 11. It is to be understood that the following disclosure provides various different embodiments as examples for implementing different features of the invention. Specific examples of components and arrangements are described in the following to simplify the present disclosure. These are, of course, merely examples and are not intended to be limiting. In addition, the present disclosure may repeat reference numerals and/or letters in the various examples. This repetition is for the purpose of simplicity and clarity and does not in itself dictate a relationship between the various described embodiments and/or configurations.The invention discloses a test device and method for a hierarchical test architecture.A test controller of the present invention can control the test wrapper of a System-on-a-Chip in compliance with the IEEE standard 1149.1 and 1500. The test controller contains a test access port (TAP) finite state machine (FSM) in compliance with the IEEE 1149.1 standard for controlling test processes within all ICs, and adds new control signals, hierarchical test instructions and new test processes to the test controller in order to be compatible with the IEEE 1500 standard test processes without changing the standard finite state machine. In addition, a hierarchical testing function is provided.The test controller in the test device receives the TAP test signals in compliance with the IEEE 1149.1 standard provided by the outer portion of the chip, and generates test control signals for controlling level 0 data registers. The TAP test signals comprise a test data in (TDI) signal, a test data out (TDO) signal and the test control signals. The test control signals comprise a test mode select (TMS) signal, a test clock (TCK) signal and an optional test reset (TRST) signal.The test controller can also generate test control signals in compliance with the IEEE 1500 standard for wrapper serial control signals. The wrapper serial control signals comprise a wrapper clock (WRCK) signal, a wrapper reset (WRSTN) signal, a shift wrapper register (ShiftWR) signal, a capture wrapper register (CaptureWR) signal, an update wrapper register (UpdateWR) signal, a select wrapper instruction register (SelectWIR) signal and so on. The test controller contains a TAP controller in compliance with the IEEE 1149.1 standard for controlling the test process and test data path, and a hierarchical core test instructions (ex. Core_Test) and a control signal register are also added to the test controller.FIG. 4A is a schematic view showing the architecture of the test device of the hierarchical test architecture mixed with the IEEE standard 1149.1 and 1500 of an embodiment of the present invention. The test device can control the test wrapper in compliance with the IEEE 1149.1 standard and IEEE 1500 at the same time.The test device is composed of at least one core (410-1 . . . 410-N), a level 0 test controller 420 and a level 0 data register 430. The core of the level 1 test layer can be a hierarchical test circuit or the core wrapped with a test wrapper in compliance with the IEEE standard 1149.1 or 1500. If the core is a hierarchical test circuit, such as the first core of the level 1 in FIG. 4A (in which the level 1 data register (indicated as L1DR) 413 is used to record the test data of the level, and the level 1 test controller 415 is used to control test processes), then one or more cores of the level 2 test layer can be added to the core (1.1..1.N1, indicated as L2C). As shown in FIG. 4A, when one of the cores in the core of the level 2 test layer is a hierarchical test circuit (such as the core 1.1), then in the level 2 test layer, the level 2 test controller (L2TC) is used to control the test processes, and the level 2 data register (L2DR) is used to record the test data (Similar to level 1 test architecture). Meanwhile, the one or more test levels of the level 3 test layer (indicated as L3C) can be added to the core. In the level 3 test layer, if the core is the hierarchical test circuit, then the core further comprises one or more cores of the level 4 test layer (indicated as L4C). Similarly, when the core of any level is a hierarchical test circuit, then one or more cores of next level test layer are added to the core until no more cores of the level is a hierarchical test circuit.When one test layer is composed of multiple cores, then all of the cores are connected in series. Specifically, for the test layer, each test data output of the core is connected to the test data input of the next core other than the first and the last core. The test data input of the first core is connected to the wrapper serial input (WSI) port of a previous level test controller, and the test data output of the last core is connected to a wrapped serial output (WSO) port of a previous level test controller.The level 0 data registers comprises at least a boundary-scan register and a bypass register, and one or more user-defined registers can be added as required. The level 0 test controller receives the test control signals, TMS, TCK, and optional TRST, and receives test data from the level 0 TDI port to the instruction register of the level 0 controller or the level 0 data register. By receiving the test control signals from the level 0 input ports of TMS, TCK, and optional TRST, and the state value of the TAP state register, the test controller can generate two sets of test control signals, wherein the first set of test signals comprises Clock-DR, Shift-DR, Capture-DR, Update-DR and so on to control the level 0 data register and the level 0 test processes, called CS1. The second set of test signals are WSC test control signals for controlling a test wrapper in compliance with IEEE 1500 standard, wherein the signals combined with the control signals such as TMS, TCK are referred to as a CS2 for controlling each test processes of the core of the next level test layer. When the cores are wrapped with the wrapper in compliance with the IEEE 1149.1 standard, the control signal TMS and TCK are directly connected to the input port of the TMS and TCK in level 0. When the core is wrapped with the wrapper in compliance with the IEEE 1500 standard, the control signals are WSC. Whether the test data output port (TDO) is connected to the test data output (WSO) of the core or the test data output of level 0 data registers are determined by the instruction which is stored in the instruction registers and decoded by the instruction decoder. The instruction decoder determines which data register will output the test data or output the test data from the WSO connected to the core based on the instruction code.Note that when the level 0 test layer only has one core, the core needs to have the hierarchical test architecture of the embodiment of the present invention. Each level of the test layer which is similar to the level 0 test architecture may comprise multiple cores of the next level (i.e. tree architecture) other than the final level test layer having a core which is the wrapper in compliance with the IEEE standard 1149.1 or 1500.In the hierarchical test architecture shown in FIG. 4A, the number of cores is not a fixed number and the number of the test layers is also not a fixed number.In each test layer, if the next level test layer exists, then at least one of the cores must be the hierarchical architecture and all the other cores can be the cores in compliance with the IEEE standard 1149.1 or 1500. If there is no any core that contains a hierarchical architecture, then it is called the last level test layer.When the level 0 only has one core, the core of the level 0 must contain a hierarchical architecture and test controller. When the level 0 has only one core without a hierarchical test architecture, a standard test architecture in compliance with the IEEE standard 1149.1 can be used as the test architecture of the level 0. Therefore, the hierarchical test architecture needs to have at least two test layers (level 0 and level 1), wherein the level 1 needs to have at least two cores or only one core but with the hierarchical test architecture.Only the level 0 needs to have a hierarchical test controller, the core of the level 1 and the layer after the level 1 may comprise the core in compliance with the IEEE 1149.1 standard, IEEE 1500 standard or the hierarchical test architecture. In addition, each layer can be composed of one or a multiple (not a fixed number) number of cores.FIG. 4B is a schematic view describing the connection of the control signals in the test architecture of the embodiment of the present invention.The test architecture is composed of a level 0 hierarchical test controller, level 0 data registers and a level 1 test layer. The level 0 hierarchical test controller is composed of an instruction register, an instruction decoder, a control signal register, a data register, control signals and a test access port finite state machine 443. The level 0 data register comprises a boundary-scan register (BSR) 444, a bypass register 445 and one or more optional user-defined registers 446.The level 1 test layer is composed of an IEEE 1500 standard wrapper of the first core of the level 1 441 and IEEE 1149.1 standard wrapper of the second core of the level 1 442. The IEEE 1500 standard wrapper of the first core of the level 1 441 comprises a WBR, WBY, WIR, other data registers (not shown), and logic circuits for controlling the wrapper (not shown). The IEEE 1149.1 standard wrapper of the second core of the level 1 442 comprises a hierarchical test controller, a data register and the level 2 test layer. Similar to the level 0 hierarchical test controller, the level 1 hierarchical test controller is also composed of an instruction register, an instruction decoder, a control signal register, a data register, control signals and a test access port finite state machine. The data register comprise a bypass register and a boundary-scan register.The level 2 test layer is composed of core 2-1 and core 2-2. The core 2-1 comprises a WBR, WBY and WIR. The core 2-2 comprises a BSR, Bypass and the test access controller (that is an IEEE 1149.1 test controller not a hierarchical test controller). If one of the cores in the level 2 test layer is the hierarchical test architecture, then the number of test layers can be increased, but the architecture can be the same as the described hierarchical test architecture.The thin solid line indicates the output and input of intra test data, which is connected the WSI port of a hierarchical test controller to the WSI or TDI of the first core of the next level, the WSO or TDO of the last core of the next level to the WSO port of the hierarchical test controller, or the WSO or, TDO ports of a core to the WSI or TDI of the core that is next to the previous one. The thick solid line indicates that the test signals are directly connected to the I/O ports of the chip which comprises TDI, TDO, TMS, TCK, and the optional TRST (all TAP signals). The thin dashed-line indicates the test control signals of the inner cores which are WSC control signals, wherein each the hierarchical test controllers of the cores that have the hierarchical test architecture need to individually generate a set of WSC control signals to control the IEEE 1500 standard test wrappers of the cores of a next level. The thick dashed-line indicates the inner control signals generated by the test controller, comprising a Shift-DR, Capture-DR, Update-DR and other test control signals, to control the data registers of this level.Note that in FIG. 4C-4E, each core also comprises a WBR, WBY, WIR, CDR, BSR and so on, however, detailed descriptions are omitted for brevity.FIG. 4C is a schematic view showing the architecture of the test device of the hierarchical test architecture. A user-defined register and CDR are non-standard data registers defined by the user for storing the test data.FIG. 4D is a schematic view describing the connection of the control signals in the instruction register operation flow. The arrows stand for the test data flow. During the operation flow of the instruction register, the instructions from the outer TDI pass through the TDI of the test controllers of each level to the IRs/WIRs of the cores of the level that needs to be tested and is output through the outer TDO port. Note that during the operation flow of the instruction register, output data is meaningless.FIG. 4E is a schematic view describing the connection of the control signals in the data register operation flow. In the data register operation flow, the test data from the outer TDI passes through the TDI of the test controllers of each level to the BSR, BYPASS, UDR, WBR, WBY, or CDR of the cores that need to be tested, and is output through the outer TDO port. During the data register operation flow, the test data stored in the WBY or BYPASS register is meaningless and for bypassing the core.The hierarchical test wrapper of the embodiment is composed of the TAP controller in compliance with the IEEE 1149.1 standard, a set of standard TAP I/O ports, an N-bit instruction register, an instruction decoder, a 1-bit bypass register, and a boundary-scan register.The data inputs of the instruction register, the boundary-scan register and the bypass register in the wrapper are connected to the TDI port of the wrapper, wherein the outputs of the boundary-scan register and the bypass register are connected to the input of the instruction decoder, and the output of the instruction decoder is connected to the input of a multiplexer, wherein the other input of the multiplexer is connected to the output of the instruction register, and the output of the multiplexer is connected to the TDO port of the wrapper.The test controller is composed of a standard TAP finite state machine with 16 different states, a copy of the state register, a control signal (i.e. Wrapper-Enable) which can control the operation of the wrapper of the next level, a control signal (i.e. SelectWIR) which can control whether the instruction register should operate or not, some control signal for controlling the registers including the instruction register and the data registers, and some logic circuits for generating these control signals.The standard TAP finite state machine is composed of a 4-bit state register, which logic value stands for current state of the TAP finite state machine, and the total state number is 16 as shown in FIG. 3. The 16 states can be partitioned into three different categories. The first type of states is composed of test logic-reset and run-test/idle state, wherein the test logic-reset state is used to reset the test controller and the run-test/idle state is keeping the test controller idling. Under the states, all data registers (such as the bypass register, boundary-scan register, and user-defined register) will not operate. The second type is control of the data register, comprising seven states including a select-DR-scan, Capture-DR, Shift-IR, Update-DR and so on, which mainly controls when the test data of the outer TDI port is input to the data register or when the test data of data register is output to the outer TDO port. The described process is also called data register operation. The third type is control of the instruction register, comprising seven states of a select-IR-scan, Capture-IR, Shift-IR, Update-IR and so on, which mainly controls when the test data of the outer TDI port is input to the instruction register. The described process is also called instruction register operation.When the TCK inputs to the test controller, since not all of the states of the TAP finite state machine correspond to the data register or instruction register, that data register or instruction register need to receive the data only in some states. In the test controller, there are two clock signals Clock-DR and Clock-IR, respectively. When the TAP finite state machine enters the four states, Capture-DR/Shift-DR or Capture-IR/Shift-IR states, the test controller allows the data register or instruction register to capture and shift the test data. When the TAP finite state machine enters Update-DR or Update-IR states, the test controller allows the data register or instruction register to update the test data. When the TAP finite state machine in the test controller enters the two states, Capture-DR and Shift-DR, the Clock-DR signal will synchronous with the outer test clock (TCK) signal, otherwise the Clock-DR will maintain the logic 1. Similarly, when the TAP finite state machine enters the Capture-IR or Shift-IR states, the Clock-IR signal will synchronous with the test clock (TCK), otherwise the Clock-IR will maintain the logic 1.For signals in compliance with the IEEE 1500 standard, the CaptureWR signal in the test controller is obtained by performing a logic OR operation on the Capture-IR signal and the Capture-DR signal, the ShiftWR signal is obtained by performing a logic OR operation on the Shift-IR signal and Shift-DR signal, the UpdateWR signal is obtained by performing a logic OR operation on the Update-IR signal and Update-DR signal, and the WRCK signal is obtained by performing a logic AND operation on the Clock-DR signal and Clock-IR signal. In addition, a logic AND operation is performed on the ShiftWR, CaptureWR, and UpdateWR signals of the test controller and the Wrapper-Enable signal, and a logic OR operation is performed on the WRCK signal of the test controller and the inversion of the Wrapper-Enable signal before the signals are connected to each test wrapper in compliance with the IEEE 1500 standard. Therefore, the signals can work only when a test is being conducted on the wrapper, otherwise, the signals are held at 1 (WRCK) or 0 (ShiftWR, CaptureWR, UpdateWR). The signals Shift-DR, Shift-IR, ShiftWR, Capture-DR, CaptureWR each have a corresponding register which is triggered by a falling edge, and the corresponding register will be set to 1 when the TAP finite state machine enter the states. For example, when the finite state machine enters the Shift-DR state, the Shift-DR register will be set to 1 at the time the test clock (TCK) changes from 1 to 0.The TMS port is set to a logic value at the falling edge of TCK signal, wherein the TAP finite state machine within the test controller is set based on the value at the rising edge of the TCK signal. Therefore, the test controller can not compare the value of the state register (as the value is changing) and the logic value of the TMS at the same time at the rising edge of the TCK signal. In order to compare the value of the state value and the value of the TMS at the rising edge of the TCK signal, the value of the state register is copied to a 4-bit register (i.e. the CurrentState register) when the TCK is at the falling edge. The value of the state register and the value of the TMS can be compared by the test controller at the rising edge of the TCK signal to determine whether the control flags are to be enabled or disabled. After the comparison (after a half of test clock cycle), the register of the corresponding control flag will be set by the controller at the falling edge of the TCK signal when the control flag needs to be enabled or disabled.An instruction decoder is connected to the output port of the instruction register for receiving the instruction value of the instruction register and setting which data register connected to the standard test output port of the test controller by a multiplexer based on the received instruction. The WSO port is output to the TDO port optionally by the multiplexer when the received instruction is a hierarchical test instruction.The instruction register is composed of the instruction shift register and the instruction update register. Under normal operation of the instruction register, the TAP finite state machine is in a Shift-IR state, and the test instruction is entered from the outer TDI port to the instruction shift register in sequence. The value of the instruction shift register is stored to the instruction update register when the TAP finite state machine is in the Update-IR state. The flow described is the operation flow of the instruction register.Following is a description of the test flow when using a hierarchical test instruction. If the value of the instruction update register is the hierarchical test instruction, the instruction register will be disabled by the test controller by using the control signal (SelectWIR) to control the instruction register when the state register changes from the Select-DR-Scan state into the Select-IR-Scan state, and then the test instructions inputted by the TDI are received by the instruction register of the test wrapper of the next level. The value stored in the instruction register of the level is held unchanged until the end of this test when the instruction register is disabled. Disabling the instruction register is executed by one of the following operations. An OR logic operation on the SelectWIR signal and the Clock-IR signal is performed and the clock of the instruction shift register remains unchanged, or an NOT operation is first performed on the SelectWIR signal and then an AND operation with the Shift-IR signal is performed, and the test instructions inputted by TDI are not allowed to be received by the instruction register of this level, and allowed to be received by the instruction registers of the test wrappers of the next level.The SelectWIR signal is enabled when the value stored in the instruction register is a hierarchical test instruction and the state register is changed from the Select-DR-Scan state into the Select-IR-Scan state. The Wrapper-Enable signal is enabled when the value stored in the instruction register is a hierarchical test instruction, the SelectWIR signal is enabled, and the state register is changed from the Select-IR-Scan state into the Capture-IR state. The SelectWIR signal is disabled when the state register is changed from the Select-DR-Scan state into the Capture-DR state. The Wrapper-Enable signal is disabled when the SelectWIR signal is disabled, and the state register is changed from the Select-IR-Scan state into the Capture-IR state.For a real circuit, the method for detecting the state change from the Select-DR-Scan state into the Select-IR-Scan state assumes the value stored in the CurrentState register is the current state. When the controller detects that the value stored in the CurrentState register is at the Select-DR-Scan state at the rising edge of the test clock (TCK) and the TMS is 1, which indicates the rising edge of the test clock, the state of the state register of the controller is changed from the Select-DR-Scan state into the Select-IR-Scan state and held at the Select-IR-Scan state before the test clock cycle enters a next rising edge.The SelectWIR signal is enabled when the value stored in the instruction register is a hierarchical test instruction, and then the Wrapper-Enable signal is enabled when the state register is changed from the Select-IR-Scan state into the Capture-IR state. The SelectWIR signal is disabled when SelectWIR signal is enabled and the state register is changed from the Select-DR-Scan state into the Capture-DR state, and then the Wrapper-Enable signal is disabled when the state register is changed from the Select-IR-Scan state into the Capture-IR state and the value stored in the instruction register is still a hierarchical test instruction until the end of the next instruction register operation.Since the test controller of each level takes the Wrapper-Enable signal and the SelectWIR signal as the signal for enabling or disabling the data registers and the instruction registers of the next level when performing the hierarchical test. Therefore, the signals are enabled only when the instruction register of the hierarchical test controller of the level is set to a hierarchical test instruction. The signals of the hierarchical test controller of all levels are disabled at the end of the test, and the instruction register and the data register of all levels other than the highest level are disabled. Next, the instruction register of the highest level is enabled and ready to receive the next test instruction.The control signal for controlling the operation of the instruction register is connected to the SelectWIR control signal port of the wrapper and controls the instruction register of the wrapper when the wrapper is in compliance with the IEEE 1500 standard.In the hierarchical test structure of the embodiment of the invention, the Level 0 controller is assumed as the highest level, in the order of the level 1, Level 2, . . . , Level n, wherein the number of the levels is not limited. The test controllers of the cores of all the levels are all IEEE 1149.1 standard TAP controller, but the instructions and the registers are designed based on the test requirements of the core under test.In order to control the IEEE 1500 standard wrapper and the IEEE 1149.1 standard hierarchical test circuit, one OR gate of the clock signal of the control instruction register is added to the test controller. Whether new instructions can be inputted into the instruction register or not is controlled by the IEEE 1500 standard SelectWIR control signal. The Wrapper-Enable control signal is used to enable/disable the IEEE 1500 standard test wrapper and the IEEE 1149.1 standard hierarchical test circuit.In addition, for the IEEE 1500 standard, since whether the test instruction can be inputted into the instruction register of the core or not is controlled by the SelectWIR signal, whether the TAP test controller is in the data register operation flow or the instruction register operation flow can be distinguished by the SelectWIR signal for the IEEE 1500 standard test wrapper, as shown in FIG. 5.FIG. 6A\u02dc6C is a timing diagram of signals in the hierarchical test controller of the embodiment of the present invention. The timing diagrams shown in FIG. 6A-6C are continuous timing diagram, showing the timing diagram of a part of the control signals of the hierarchical test controller and IEEE 1500 standard wrapper serial control (WSC) signals.In FIG. 6A-6C, the value stored in the state register is changed at the rising edge of the test clock (TCK) by each TAP FSM (not shown), wherein each state indicates one test clock. Since the CurrentState register in FIG. 6A-6C indicates the state value copied at the falling edge of the test clock, the value in the CurrentState register is changed at the falling edge.In FIG. 6A, the Core_Test (i.e. the hierarchical test instruction) instruction starts inputted when the signal arrives at the dotted line (1)(where the state of TAP FSM is entering the Shift-IR state, and the internal ShiftWR signal of the hierarchical test controller of the top level is changed to 1, but the external ShiftWR port of the test controller remains 0 since the Wrapper-Enable signal is not enabled), it needs N0 test clock cycles to shift the Core_Test instruction into an N0-bit instruction register, and then the instruction register is updated to the Core_Test instruction when the signal arrives at the dotted line (2) (where the state of TAP FSM is entering the Update-IR state, and the internal UpdateWR signal of the test controller is changed to 1, the external UpdateWR port of the test controller remains 0 since the Wrapper-Enable signal is not enabled), the SelectWIR signal is enabled when the signal arrives at the dotted line (3) (where the CurrentState of the hierarchical test controller of the top level is changed from Select-DR-Scan to Select-IR-Scan), which indicates that the data path has changed to the instruction register by the core, and the Wrapper_Enable signal is disabled when the signal arrives at the dotted line (4) (where the CurrentState of the hierarchical test controller of the top level is changed from Select-IR-Scan to Capture-IR), which indicates that the next test data can be received by the cores of the next level as the test instructions of these cores. In FIG. 6B, the SelectWIR signal is disabled after the instruction input is finished (it needs N1 test clock cycles for shifting the test instructions into the cores of the next level wherein the total number of bits of the instruction registers of these cores is equal to N1), and the execution of the test instructions is started when the signal arrives at the dotted line (1), it needs M0 cycles to shift the test data in and out the data registers of these cores for the first set of test data, and it needs M1 cycles for the second set of test data and so on. In FIG. 6C, the Wrapper_Enable signal is disabled and the test is terminated when the signal arrives at the dotted line (1) (where the execution of all the test instructions is finished, and the TAP FSM is entering the instruction register operation flow). The next test flow is started and a new test instruction is inputted when the signal arrives at the dotted line (2).The two FSMs (TAP0 FSM and TAP1 FSM) in FIG. 6A show the concept that all FSMs in the hierarchical test architecture are in the same state. All TAP FSMs in FIG. 6B indicate all TAP FSMs (all FSMs are in the same state) in the hierarchical test structure. The thin dotted line indicates the timing to change the status of the control flag and the value of the TMS resulted from comparison by the controller, and the bold dotted line indicates the timing to change the status of the control flag and the value stored in the instruction register (having a half clock cycle difference there between).In FIG. 6A-6C, Nx_Cycles and Mx_Cycles are the clock periods when entering the Shift-IR and Shift-DR state. That is, the Shift-IR state is held for an N0 clock cycle when first entered for inputting instructions. Here, the N0 is the length of the instruction register (bit number) of the highest level (level 0), N1 is the total length of the instruction registers (bit number) of all cores in the level 1 and so on. When there are two test levels in N1, N2,1 and N2,2 will be present. An instruction input is completed before every testing in the hierarchical test of the invention, since the test instruction is entered before testing. Therefore, the total clock cycle needed for entering the instruction is N0+N1 (the clock cycles of Shift-IR state) plus the total clock cycles of the other states such as two times of Update-IR, two times of Select-DR-Scan, . . . two times of Capture-IR, when testing the level 1 core.The M0 and M1 indicate the number of test data needed to be inputted or outputted when testing the real cores. The testing is not limited to M0/M1, and the test data can be repeatedly inputted and outputted until the end of the test (that is M0, . . . , Mn and n>=0). In addition, it is possible that no data needs to be inputted. That is, the state is changed from Capture-DR state to Update-DR state directly without passing through Shift-DR state. Next, the new test instruction is inputted in the next instruction register operation flow and changed when the TAP FSM is at Update-IR state.The SelectWIR signal is set to 1 after entering a predetermined hierarchical core test instruction (ex. Core_Test). Therefore, the instruction register in the TAP controller is disabled until the end of the entire test flow and thereafter prepares for entering of new instructions. After the instruction register is disabled, the hierarchical instruction stored in the instruction register remains unchanged until the end of this test. Every hierarchical test flow is composed of two or more instruction register operation flows (two instruction register operation flows are needed in testing the level 1 and three instruction register operation flow are needed in testing the level 2, and so on) and 0-N times data register operation flow. Every test level other than the level 0 (chip level) is composed of one or more cores, and each core is a circuit under test (CUT) wrapped with the IEEE 1149.1 or 1500 standard test wrapper, where in the core of the two standards can be combined on the same test serial (as shown in FIG. 4B). Every core is connected in turn from the first core to the last core.The cores at the same level and connected to the same test controller are connected in serial and respective test instructions can be inputted in a same test flow. Therefore, the cores can be tested in parallel (i.e. in a same test flow). However, the cores connected to different controllers at the same level can not be tested in parallel.The state register (the value stored is shown in FIG. 3) in the TAP controller is controlled by the test program using the TMS signal, the value stored in the state register is changed from the Select-DR-Scan state, passing the Capture-DR state, Shift-DR state, Exit1-DR state, Pause-DR state or Exit2-DR state, into the Update-DR state, wherein the flow described is referred to as one data register operation flow. If the value stored in the state register is changed from the Select-IR-Scan state, Capture-IR state, Shift-IR state, Exit1-IR state, Pause-IR-Scan state or Exit2-IR state, into the Update-IR state, the flow is referred to as one instruction register operation flow. If the state register changes from the Select-DR-Scan state into Select-IR-Scan state, it indicates that the test flow has ended.When all instruction register operation flows are finished and the finite state machine of the test controller enters the data register operation flow, the state register is changed from the Select-DR-Scan state into the Capture-DR state. Therefore, the SelectWIR signal is disabled when the state register is in a Select-DR-Scan state and about to enter the Capture-DR state, which indicates that the test controllers or the test wrappers of the level that are tested have completed receiving the instructions and are ready for receiving the test data and executing real test tasks. Then, the test data received during all of the data register operation flows will not be inputted into the wrapper that is not being tested and only be inputted into the wrapper being tested.At the end of the test flow, the state register is changed from the Select-DR-Scan state into the Select-IR-Scan state. After entering the next test clock (TCK), if the state register is changed from the Select-IR-Scan state into the Capture-IR state, which indicates that the instruction register is ready for receiving the next test instruction, then the Wrapper-Enable signal is disabled. Specifically, the TAP controller finishes controlling the test wrapper of the next level and returns to control the level. The test flow described above is referred to as a hierarchical test operation, as shown in FIG. 7.After the test flow has started, the instruction register of the top level (S1) is set, which is called the instruction register operation flow (IR-Operation). Next, it is determined whether an input instruction is a top level hierarchical test instruction (S2). If the input instruction is not the top level hierarchical test instruction, then the test instruction (S3) is executed. If the input instruction is the top level hierarchical test instruction, then the instruction registers of the next level cores (S4) are set, which indicate that the instruction register operation flow (IR-Operation) can be repeatedly executed by multiple times (N times). Next, it is determined whether an input instruction is the hierarchical test instruction of one of the cores of the level (S5). If the input instruction is the hierarchical test instruction of the core of the level, then the operation flow returns to step S4 to set the instruction registers of the next level cores. If the input instruction is not the hierarchical test instruction of the core of the level, then the test instruction (S6) is executed, wherein this step is the data register operation flow (DR-Operation) step. When the test instruction is completed (step S3 and S6), then the test flow returns to the top level, and waits for the next test flow.Note that in the embodiment of the present invention, the instruction register operation flow needs to be operated N+1 times (from 0th level to Nth level) before testing the cores of the level N. Additionally, the test flow always directly returns to the top level controller after completing the test flow of any tested level. Furthermore, all the finite state machines in all of the TAP controllers of the present invention have to stay at the same state.FIG. 8A is a schematic view showing a SoC mixed test architecture of the exemplary embodiment of the present invention. In this architecture, multiple test groups (TG-1\u02dcTG-N) are connected together, wherein each test group comprises multiple cores (such as Core 1,1 , Core 1,2, . . . Core 1,M1 -1, Core 1,M1, Core 2,1, Core 2,2, . . . Core 2,M2-1, Core 2,M2 , . . . , Core N,1, Core N,2, . . . Core N,MN\u22121, Core N,MN). The test input signals (WSI1\u02dcN) of each test group is directly fanned-out to the wrapper of the first core of each test group by the test controller 810, and the test output signal (WSO) is connected to the test input signal (WSI) of the next wrapper in turn. Meanwhile, the test output signal of the last wrapper is connected to the multiplexer 820 for setting one of the test output signals of the test groups as its output. The test control signals TMS and TCK are connected from the top level test controller to each same signal input port of the core with the IEEE 1149.1 standard wrapper directly by means of a fan-out. There are two connections methods, if the test group comprises the cores wrapped with the IEEE 1500 standard wrapper, and they are as follows. One method is that the test controller only provides one set of the standard test control signals (WSC) which are connected to all cores wrapped with the IEEE 1500 standard wrapper. Another method is that the corresponding set of WSC standard test control signals (WSC1-N) of each test group are connected to the same input port of the cores. The cores of the same test group are connected to the same set of WSC test control signals. The cores of different test groups are connected to different set of WSC test control signals.The multiplexer is set by the test controller. There are two ways for setting the multiplexer, one is to select different groups by using different instructions, and the other is to setting by a test group identity (ID) register. In method one, if the test instruction stored in the instruction register is the group test instruction of a group of test groups, the output of the multiplexer is set to be the test output of the test group by the test controller. In method two, every test group has only one GroupID. If the value of the test group ID register is equivalent to the GroupID of a group of test groups, the test controller sets the output signal of the multiplexer to be outputted by the test group (i.e. set the logic value of the select lines of the multiplexer equivalent to the value of the test group ID register). Only one group can be tested by the test architecture of the test controller in FIG. 8, but multiple cores in the same test group can be tested in parallel.Previously, for hierarchical reset circuits, after five 1's are inputted in a row to the test mode select (TMS) signal, the TAP controller enters a Test-Logic-Reset state, resets all control signal registers, and sets all instruction registers as Bypass instructions (the core wrapped with the IEEE 1149.1 wrapper) or WS_BYSS (the core wrapped with the IEEE 1500 wrapper). In the embodiment of the invention, when five 1's are received by TMS input of the test controller of the top level (level 0) in a row, if the instructions of the instruction register are hierarchical core test instructions (ex. Core_Test), then the TAP controller enters the Test-Logic-Reset state, but the control signal register is not reset by the test controller of the level and the WRSTN signal is set to 0 (the WRSTN signal is an active-low signal). Thus, the test controller only resets the next level test controller and sets the instruction register of all test wrappers controlled by the test controller as the Bypass instruction, and does not reset all control signal registers, all data registers and all instruction registers of the test controller and the test controller of a previous level.FIG. 8B is a schematic view showing a SoC mixed test architecture of another exemplary embodiment of the present invention. The main difference between the hierarchical test architecture of FIG. 8B and FIG. 8A is that the group under test is determined by a GroupID register 830.The following is detailed description of the control flow of the instruction register in test controller of the hierarchical test architecture.FIG. 9A is a schematic view of the architecture of the instruction register.The architecture comprises a TAP controller 910, an IR_Shift register 920, an IR_Update register 930, an IR decoder 940 and multiplexers 950 and 960. The multiplexer 950 is a Select_DR multiplexer, and the multiplexer 960 is a Select DR/IR multiplexer. The TAP controller 910 or the external input instruction is in turn transferred to IR_Shift register 920, IR_Update register 930 and IR decoder 940. The WSO, BSR, Bypass, UDR and TDI are external input/output signals, wherein the TDI is from the TDI signal of most external levels, the BSR/Bypass/UDR are outputs of the data registers and the WSO is the serial output signal of the next level. One of the output signals of the data registers and the next level is selected as the output of the multiplexer 950 by the IR decoder 940. One of the output signals of the multiplexer 950 and the IR_Shift register 920 is selected to output to a TDO output register by the multiplexer 960. The output of the TDO register is connected to most external TDO signals.The instruction register is composed of two parts, comprising an IR_Shift register 920 and an IR_Update register 930. The IR_Shift register 920 is controlled by the Shift_IR, wherein the Clock_IR is the clock signal for storing the instruction values from the TDI. Herein, the instruction values are only temporary values, and do not have any other functions. The IR_Shift register 920 hold an original value when the state register is not Shift-IR, and the test data from TDI can be shifted into the IR_Shift register 920 as the test instruction when the Shift-IR signal is equal to 1 (i.e. the state register is changed to Shift-IR. When the state register is changed to the Update_IR state (i.e. Update-IR signal is equal to 1), the instruction stored in the IR_Shift register 920 is updated to the IR_Update register 930.The IR decoder 940 controls one of the outputs of the data registers connected to the input (i.e. DR-Output) of the multiplexer 960 by controlled the multiplexer 950. The TAP controller 910 controls the output of the multiplexer 960. The output of the multiplexer 960 is the DR-Output when the state register is the data register operation flow, and the output of the multiplexer 960 is the IR-Output when the state register is the instruction register operation flow.FIG. 9B is a schematic view of the instruction register of one embodiment of the present invention.The structure in FIG. 9B comprises a TAP controller 910, an IR_Shift register 920, an IR_Update register 930, an IR decoder 940, multiplexers 950 and 960 and an OR gate 970. The clock signal of the IR_Shift register 920 is connected to the output of the OR gate 970. When the SelectWIR signal is 1, the clock signal of the IR_Shift register 920 is equal to 1 and the value stored in the IR_Shift register 920 is not changed. When the SelectWIR signal is 0, the output of the OR gate 970 is equal to Clock-IR signal, and the test data from TDI can be shifted into the IR_Shift register 920 as the test instruction.FIG. 9C is a schematic view of the instruction register of another embodiment of the present invention.The structure in FIG. 9C comprises a TAP controller 910, an IR_Shift register 920, an IR_Update register 930, an IR decoder 940, multiplexers 950 and 960, an AND gate 980 and an inverter 990.The shift enable signal of the IR_Shift register 920 is connected to the output of the AND gate 980, and when the shift enable signal of the IR_Shift register 920 is set to 1, the test data from TDI can be shifted into the IR_Shift register 920 at the rising edge of the Clock-IR. When the SelectWIR signal is 1, the output of the inverter 990 is set to 0. Thus, the output of the AND gate 980 is set to 0, the IR_Shift register 920 can not receive the test instruction from TDI, and the value of the IR_Shift register 920 remains the same.FIG. 10 is a schematic view showing the architecture of a traditional TAP controller comprising a TAP finite state machine 1010 and an instruction/data register control unit 1020.The TAP finite state machine 1010 is composed of the state register of 16 states (4-bit wide) and some logic circuits for decision-making. New state values are generated based on the TMS value and the current state at the rising edge of the TCK (as shown in FIG. 5). The arrows in the figure indicate transmitting a 4-bit state value to the next logic circuit block.The instruction/data register control unit 1020 (composed of some inverters and logic gates) generates the signals (such as Clock-DR, Shift-DR, Capture-DR, Update-DR etc (i.e. CS1 described above) for controlling the data register based on the state value, the signals (such as Clock-IR, Shift-IR, Update-IR etc.) for controlling the instruction register, and the control signals added by the user according to requirements (not shown).FIG. 11 is a schematic view showing the architecture of the TAP controller of the embodiment of the present invention comprising a TAP finite state machine 1110, an instruction/data register control unit 1120, a current state register 1130, a hierarchical test controller 1140 and a wrapper control unit 1150.The TMS, TCK, Clock-DR and WSC are the input/output signal of the TAP controller, wherein the TMS/TCK are the signals come from the most external TMS/TCK port and the Instruction is the instruction value (which is equivalent to the instruction value outputted to the IR decoder) from the instruction update register (IR_Update register). The WSC is the control signal for controlling the next level testing. The Clock-DR, Shift-DR, Capture-DR and Update-DR are signals for controlling the data register and the Clock-IR, Shift-IR and Update-IR are signals for controlling the instruction register.The TAP finite state machine 1110 within the TAP controller is composed of the state register of 16 states (4-bit width) and some logic circuits for making decisions. The arrows in the figure indicate transmitting the 4-bit state value to the next logic block. The instruction/data register control unit 1120 composed of some inverters and logic gates generates the control signals (comprising Clock-DR, Shift-DR, Capture-DR, Update-DR etc. (the CS1 described above) of the data register and the control signals (Clock-IR, Shift-IR, Update-IR etc. for controlling the instruction register) of the instruction register based on the state value.The hierarchical test control unit 1140 sets the values of the two control signals of the Wrapper-Enable and SelectWIR based on the values of the current state register 1130 and TMS. The Shift-IR and Shift-DR signals are connected to the inputs of the OR gate inside the wrapper control unit 1150, and the output is the ShiftWR signal (same generating method as the UpdateWR and the CaptureWR) of the WSC. The only exception is that the Clock-IR and the Clock-DR perform the AND operation and generate the WRCK, wherein all signals perform logic operations with the Wrapper-Enable before output. All WSCs will be enabled when the Wrapper-Enable is enabled, and the WRCK is changed according to the Clock-DR and the Clock-IR. The SelectWIR is outputted directly without any operation. The WSI is outputted by the TDI directly, and the output of the WSO is determined by the IR decoder as described previously.To conclude, the test controller in the test device of the controllable hierarchical test architecture of the embodiment can be shared by the IEEE 1149.1 and the IEEE 1500 standard cores for achieving hierarchical testing. The test controller can select whether to change the test level or not based on the instructions stored in the instruction register by using the test controller of the embodiment of the invention when the TAP finite state machine enters the Select-DR-Scan state.In addition, the test controller of the embodiment allows all TAP finite state machines to remain in the same state (ex. all TAP finite state machines enter the Update-IR state at same TCK cycle), wherein the only difference is that the TMS signal and the TDI signal can only change the instruction registers of the IEEE 1149.1 or 1500 standard test wrappers which are under test. Therefore, no extra TAP linking module (TLM) is needed for selecting the test controller, and only one logic gate is needed to control the clock signal if the instruction register for determining whether the instruction register should input new instructions or maintain original instructions.While the invention has been described by way of example and in terms of the embodiments, it is to be understood that the invention is not limited to the disclosed embodiments. To the contrary, it is intended to cover various modifications and similar arrangements (as would be apparent to those skilled in the art). Therefore, the scope of the appended claims should be accorded the broadest interpretation so as to encompass all such modifications and similar arrangements.","Export Citation":"Click for automatic bibliographygeneration","Field of Search":"714/10-13, 714/25-38, 714/42-44, 714/48-50, 714/726-733","Filing Date":"11/26/2008","International Classes":"G06F11/00","Inventors":"Luo, Kun-lun (Hsinchu, TW)","Other References":"Kuen-Jong Lee et al., \u201cA Hierarchical Test Control Architecture for Core Based Design\u201d, pp. 248-253, 2000 IEEE, US.Jin-Fu Li et al., \u201cA Hierarchical Test Scheme for System-on-Chip designs\u201d, Proceedings of the 2002 Design, Automation and Test in Europe Conference and Exhibition, 5 pages, 2002 IEEE, France.Jaehoon Song et al., \u201cA Simple Wrapped Core Linking Module for SoC Test Access\u201d, Proceedings of the 11th Asian Test Symposium, 6 pages, 2002 IEEE, US.\u201cIEEE Standard Test Access Port and Boundary-Scan Architecture,\u201d The Institute of Electrical and Electronics Enginners, Inc. Jul. 2001, 200 pages, IEEE, US.\u201cIEEE Standard Testability Method for Embedded Core-based Integrated Circuits,\u201d The institute of Electrical and Electronics Enginners, Inc. Aug. 2005, 127 pages, IEEE, US.Jin-Fu Li et al., \u201cA Hierarchical Test Scheme for System-on-Chip Designs,\u201d Proceedings of the 2002 Design, Automation and Test in Europe Conference and Exhibition, Aug. 2002, pp. 486-490, IEEE, US.","Primary Class":"714/30","Primary Examiner":"IQBAL, NADEEM","Publication Date":"05/22/2012","Title":"Test device and method for hierarchical test architecture","US Patent References":"7529996DDR input interface to IC test controller circuitry2009-05-05Whetsel714/7317519884TAM controller for plural test access mechanisms2009-04-14Whetsel714/7267506231Wrapper testing circuits and method thereof for system-on-a-chip2009-03-17Chang et al.714/72620080034262DOUBLE DATA RATE TEST INTERFACE AND ARCHITECTURE2008-02-07Whetsel714/72920080010569DEVICE TESTING ARCHITECTURE, METHOD, AND SYSTEM2008-01-10Whetsel714/72420070255986Wrapper testing circuits and method thereof for system-on-a-chip2007-11-01Chang et al.714/7247058862Selecting different 1149.1 TAP domains from update-IR state2006-06-06Whetsel et al.20050268193Module, electronic device and evaluation tool2005-12-01Waayers714/72720050050413Selectively accessing test access ports in a multiple test access port environment2005-03-03Whetsel714/7246631504Hierarchical test circuit structure for chips with multiple circuit blocks2003-10-07Dervisoglu et al.716/1366425100Snoopy test access port architecture for electronic circuits including embedded core with built-in test access port2002-07-23Bhattacharya6381717Snoopy test access port architecture for electronic circuits including embedded core having test access port with instruction driven wake-up2002-04-30Bhattacharya6324662TAP and linking module for scan access of multiple cores with IEEE 1149.1 test access ports2001-11-27Haroun et al.6324614Tap with scannable control circuit for selecting first test data register in tap or second test data register in tap linking module for scanning data2001-11-27Whetsel714/7266122762Memory interface device and method for supporting debugging2000-09-19Kim714/726","View Patent Images":"Download PDF 8185782"},"United States Patent 8689066":{"Abstract":"A method of implementing integrated circuit device testing includes performing baseline testing of a first group of chips using a full set of test patterns, and for chip identified as failing, determining, a score for each test pattern in the full set. The score is indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns. Following the baseline testing, streamlined testing on a second group of chips is performed, using a reduced set of the test patterns having highest average scores as determined by the baseline testing. Following the streamlined testing, full testing on a third group of chips is performed using the full set of test patterns, and updating the average score for each pattern. Further testing alternates between the streamlined testing and the full testing for additional groups of chips.","Application Number":"13/172179","Assignee":"International Business Machines Corporation (Armonk, NY, US)","Attorney, Agent or Firm":"IBM Intellectual Property Law Department (Endicott, NY, US)","Claims":"What is claimed is:1.A method of implementing integrated circuit device testing using adaptive test pattern selection, the method comprising: performing an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determining, by a computing device, a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, performing streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, performing full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resuming determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternating between the streamlined testing and the full testing for additional groups of chips.2.The method of claim 1, wherein the score for each test pattern is determined as follows:Scorefail=total patterns+1\u2212(# of failing patterns); andScore pass=0; wherein, for each failing chip identified during the initial baseline testing and the full testing, Scorefail represents the score for each test pattern in the full set that was failed by the failing chip and Scorepass represents the score for each test pattern in the full set that was not failed by the failing chip.3.The method of claim 2, wherein the reduced set of the test patterns is about 50% of the full set of test patterns.4.The method of claim 2, wherein the first duration is greater than the second duration.5.The method of claim 4, wherein the first duration and the second duration are selected so as to establish a duty cycle of testing about 80% of chips under streamlined testing and about 20% of chips under full testing.6.The method of claim 2, further comprising detecting a reset criteria based on a defined event that results in restarting the initial baseline testing by erasing a current test pattern ranking.7.The method of claim 6, wherein the defined event comprises one or more of: reaching a defined count of failing chips, detecting a change in observed yield, and reaching a beginning of a new lot of wafers.8.A computer program product comprising a non-transitory, tangible computer readable medium having computer readable instructions stored thereon that, when executed by a computer, implement a method of testing an integrated circuit device by using adaptive test pattern selection, the method comprising: performing an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determining a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, performing streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, performing full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resuming determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternating between the streamlined testing and the full testing for additional groups of chips.9.The computer program product of claim 8, wherein the score for each test pattern is determined as follows:Scorefail=total patterns+1\u2212(# of failing patterns); andScorepass=0; wherein, for each failing chip identified during the initial baseline testing and the full testing, Scorefail represents the score for each test pattern in the full set that was failed by the failing chip and Scorepass represents the score for each test pattern in the full set that was not failed by the failing chip.10.The computer program product of claim 9, wherein the reduced set of the test patterns is about 50% of the full set of test patterns.11.The computer program product of claim 9, wherein the first duration is greater than the second duration.12.The computer program product of claim 11, wherein the first duration and the second duration are selected so as to establish a duty cycle of testing about 80% of chips under streamlined testing and about 20% of chips under full testing.13.The computer program product of claim 9, wherein the method further comprises detecting a reset criteria based on a defined event that results in restarting the initial baseline testing by erasing a current test pattern ranking.14.The computer program product of claim 13, wherein the defined event comprises one or more of: reaching a defined count of failing chips, detecting a change in observed yield, and reaching a beginning of a new lot of wafers.15.A system for implementing integrated circuit device testing using adaptive test pattern selection, comprising: a computing network including a processing device in communication with one or more computer memory storage devices; and the processing device configured to: perform an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determine a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, perform streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, perform full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resume determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternate between the streamlined testing and the full testing for additional groups of chips.16.The system of claim 15, wherein the score for each test pattern is determined as follows:Scorefail=total patterns+1\u2212(# of failing patterns); andScorepass=0; wherein, for each failing chip identified during the initial baseline testing and the full testing, Scorefail represents the score for each test pattern in the full set that was failed by the failing chip and Scorepass represents the score for each test pattern in the full set that was not failed by the failing chip.17.The system of claim 16, wherein the reduced set of the test patterns is about 50% of the full set of test patterns.18.The system of claim 16, wherein the first duration and the second duration are selected so as to establish a duty cycle of testing about 80% of chips under streamlined testing and about 20% of chips under full testing.19.The system of claim 16, wherein the processing device is further configured to detect a reset criteria based on a defined event that results in restarting the initial baseline testing by erasing a current test pattern ranking.20.The system of claim 19, wherein the defined event comprises one or more of: reaching a defined count of failing chips, detecting a change in observed yield, and reaching a beginning of a new lot of wafers.","Description":"BACKGROUNDThe present invention relates generally to semiconductor device manufacturing and, more particularly, to integrated circuit test optimization using an adaptive test pattern sampling algorithm.Semiconductor devices are typically fabricated in large lots on semiconductor wafers. The fabrication process includes various steps such as, for example, deposition, lithography, etching, sputtering, and other techniques known to those skilled in the art. As with any other manufacturing process, defects inevitably arise during semiconductor manufacturing. These defects must be detected by the manufacturer before completed integrated circuit devices are delivered to customers.Device testing in a manufacturing environment can be a complex and expensive process. Due to the increasing complexity of integrated circuit devices, the devices can suffer from a wide range of faults, such as shorts or opens in the semiconductor and wiring layers, stuck-at faults, and so on. To facilitate the detection of each of these faults, each device is typically subjected to a large number of different test patterns, as a single test pattern may typically only cover certain types of faults. On the other hand, each test pattern that is run adds to the cost of the overall testing process of the devices.SUMMARYIn one aspect, a method of implementing integrated circuit device testing using adaptive test pattern selection includes performing an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determining, by a computing device, a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, performing streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, performing full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resuming determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternating between the streamlined testing and the full testing for additional groups of chips.In another aspect, a computer program product includes a non-transitory, tangible computer readable medium having computer readable instructions stored thereon that, when executed by a computer, implement a method of implementing integrated circuit device testing using adaptive test pattern selection. The method includes performing an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determining a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, performing streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, performing full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resuming determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternating between the streamlined testing and the full testing for additional groups of chips.In still another aspect, a system for implementing integrated circuit device testing using adaptive test pattern selection includes a computing network having a processing device in communication with one or more computer memory storage devices. The processing device is configured to perform an initial baseline testing of a first group of chips to be tested using a full set of test patterns; for each of the first group of chips identified as failing at least one of the full set of test patterns, determine a score for each test pattern in the full set, the score indicative of an ability of the test pattern to uniquely identify a failing chip with respect to other test patterns, and keeping a running average of the score for each test pattern as subsequent failed chips are identified; following the initial baseline testing, perform streamlined testing on a second group of chips for a first duration, the streamlined testing comprising using a reduced set of the test patterns, the reduced set comprising test patterns having highest scores as determined by the initial baseline testing; following the streamlined testing, perform full testing on a third group of chips for a second duration, the full testing comprising using the full set of the test patterns and, during the full testing, resume determining a score for each test pattern in the full set for each failing device in the third group of chips and updating the running average of the score for each test pattern; and alternate between the streamlined testing and the full testing for additional groups of chips.BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGSReferring to the exemplary drawings wherein like elements are numbered alike in the several Figures:FIG. 1 is a histogram illustrating results of a test pattern fail distribution for logic built-in self test (LBIST) patterns for one physical section of a device;FIG. 2 is a flow diagram illustrating a method for implementing integrated circuit device testing using adaptive test pattern selection, in accordance with an embodiment of the invention;FIG. 3 is a table illustrating hypothetical test results using the method of FIG. 2; andFIG. 4 is a schematic block diagram of a general-purpose computing system suitable for practicing embodiments of the present invention.DETAILED DESCRIPTIONAs indicated above, integrated circuit devices are subjected to large numbers (e.g., hundreds or even thousands) of test patterns in order to ensure defect detection. This is the case, even though it is generally recognized in the semiconductor industry that most defective devices can be caused to fail with many fewer tests than are typically run in a testing process. It is also well recognized that most of the time used to test digital integrated circuits is made up of the running of functional tests. However, the main problem in this regard is that it is not known ahead of time which ones of the available functional tests are going to catch a defective device. Therefore, IC manufacturers typically run all the tests available, and therefore much test time is wasted. Efforts may be made to look at historical pass/fail information with respect to functional test fails, followed by reducing the pattern list, but such a process is iterative and backward looking.Pattern ranking and reordering to reduce test time is also another approach that may be taken within the industry. However, reordering is typically done to reduce the time it takes to detect a failing chip, and the analysis to determine the new order is done after testing a significant amount of product and long term historical data. Still other solutions are backwards looking and static. Functional test fail data are collected and analyzed, and from that analysis, a test program is modified to run the most effective subset of patterns. If for some reason a \u201cmost effective test list\u201d changes, the ability to react to this situation is slow and requires new analysis. When a device is faulty, typically many of the several applied test patterns fail. It is easy to see in hindsight how one could have run fewer patterns and still culled out the failing devices, but the challenge is to adaptively choose the best subset of patterns to run while material is being tested, with no other information provided.Accordingly, disclosed herein is a method to collect data and rank functional test patterns by their ability to fail faulty devices uniquely. An adaptive test algorithm then uses this information to run the most effective sample of patterns on most devices, while still continuing to collect pattern fail statistics on some other devices. As a result, the time for testing good and bad devices is reduced, and with a minimal number of \u201cescapes\u201d of bad devices.As described in further detail below, the exemplary embodiments described herein reorder the test patterns on a test session by test session basis, without considering the historical data from other lets test sessions, and removes patterns with low probability of uniquely catching a defect from the end of the new order, thereby reducing the test time of a good device without significantly impacting quality. In addition, because the reordering does not consider historical data from other test sessions, it is less likely to remove patterns that would catch process specific defects unique to the present material under test.In a given list of test patterns, there will be some frequency of fail for each pattern applied to faulty hardware. By way of illustration, FIG. 1 is a histogram 100 illustrating actual results of a test pattern fail distribution for logic built-in self test (LBIST) patterns for one physical section of a device. The x-axis represents a total number out of a possible 20 different test patterns that cause a given bad chip to fail the test. The y-axis represents what percentage of the total number of bad chips had that specific number of test pattern fails. As can be seen from the data, nearly 50% of the bad devices fail either 19 or 20 out of the 20 total patterns (with about 45% of the bad devices failing all 20 patterns), while smaller percentages of the bad devices fail 18, 17, etc., out of 20 patterns. This data is typical of most functional tests, and illustrates how most faulty devices may be identified by running fewer than the total number of test patterns.However, a difficulty arises with certain faulty devices that only fail a relatively small number of the total test patterns. If, for example, only 10 out of the 20 test patterns are randomly run (i.e., 50% test coverage), then any device that would fail 11 or more of the total patterns will always be guaranteed to fail with only 10 randomly selected patterns and therefore the faulty device may be identified without needing to run all 20 test patterns. On the other hand, devices that fail only 10 or fewer of the 20 total patterns will have some mathematical probability of escape, as illustrated in Table 1 below:TABLE 1Probability of Escape# of Failing Patterns (out of 20)Using 50% Test Coverage11-200100.0000054190.0000595480.0003572370.0015479960.0054179650.0162538740.0433436530.1052631620.2368421110.50000000 In the worst case for this example, a faulty device that fails only 1 of the 20 total test patterns will have a 50% probability of escape if only 10 out of 20 patterns are randomly selected, while a device that fails 2 of the 20 patterns will have about a 24% chance of escape, and so forth. While as a practical matter there are not many integrated circuit devices in the world that fail only a small number of test patterns (such as between 1 to 3 for example), an intelligent scheme for pattern selection can reduce the probability of escape even further.More specifically, the present embodiments introduce the concept of a \u201cscore\u201d for a test pattern with respect to a failing device, wherein:Scorefail=total patterns+1\u2212(# of failing patterns) (Eq. 1)Scorepass=0 (Eq. 2) For example, in a test that runs 10 patterns, if a given device fails and there is only one failing test pattern for the failing device, then the score for that pattern on that device is 10. All other patterns that did not fail receive a score of 0 on that device. On the other hand, where a device fails and all 10 of the test patterns are failing patterns, then each test pattern receives a score of 1. Thus, it will be seen that the higher the score for a test pattern for a given failed device, the more \u201cunique\u201d that test pattern was in determining a faulty device. As a group of test patterns is repeatedly applied to a lot of semiconductor devices, a running average of the uniqueness score for each of the test patterns may be computed as bad chips are discovered during the testing process. Over time, the average score for the patterns may change, and during the course of testing those patterns with the highest average scores may be single out and applied to subsequent chips in a subset of total patterns as they are more likely to better at uniquely identifying bad devices than those with lower average scores.Referring now to FIG. 2, there is shown a flow diagram illustrating a method 200 for implementing integrated circuit device testing using adaptive test pattern selection, in accordance with an embodiment of the invention. In block 202, the method begins with testing of a lot of wafers upon which individual semiconductor chips are manufactured. As indicated in block 204, an initial group of chips is first selected for baseline testing, in which the complete test pattern set is used so that an initial ranking of test pattern scores may be generated.When an individual chip is tested, it will either fail or not, meaning that if a chip fails one or more of the applied test patterns it is considered bad. Those chips that pass all of the applied test patterns are considered good. For each failing chip, then, an individual test score will be computed for all of the applied test patterns in the set for the baseline testing mode, as shown in block 206. In block 208, the score for each test pattern, in view of a failed chip, is computed in accordance with equations 1 and 2 described above.By way of a first example, it is assumed that there are 20 total patterns (A through T) in a test set. During baseline testing, a first failed chip is discovered with the following test results, and calculated scores:TABLE 2TestFail?ScoreAY3BY3CY3DY3EY3FY3GN0HY3IY3JY3KY3LY3MY3NY3OY3PY3QY3RN0SY3TY3 As shown from the table above, all patterns except for test patterns G and R failed for the failing device, thus the 18 failing patterns receive a uniqueness score of 3, while patterns G and R receive a score of 0. As additional failures are discovered during the baseline testing, a running average of the scores for each pattern may also be computed and used to rank the patterns, as reflected in block 210 of FIG. 2. Continuing the above example, it will be assumed that for the next identified failed chip, all 20 patterns failed. This results in each test pattern receiving a 1 score for that chip. Factoring these updated results into the data from Table 2 would yield the following average ranking for the patterns after 2 chip fails:TABLE 3TestAverage ScoreA2B2C2D2E2F2H2I2J2K2L2M2N2O2P2Q2S2T2G0.5R0.5 As can be seen from Table 3 above, test patterns G and R have the lowest average ranking after two failed chips. In the case that the next failed chip in the baseline testing sequence only had 1 of 20 failing patterns, for example K, then the score for pattern K for that chip would be 20, while the score for the remaining 18 patterns would be 0. From this third failed chip, a new ranking would emerge as follows:TABLE 4TestAverage ScoreK8A1.33B1.33C1.33D1.33E1.33F1.33H1.33I1.33J1.33L1.33M1.33N1.33O1.33P1.33Q1.33S1.33T1.33G0.33R0.33 To this point, after the identification of 3 failed chips, test pattern K emerges as an early \u201chigh value\u201d test pattern which would be desired to use for all testing, whereas test patterns G and R emerge as early \u201clow value\u201d test patterns that could be skipped in the interest of testing efficiency. As should be appreciated, actual test scores for an actual number of test patterns would likely converge to a smaller range of values over time during baseline testing.Referring once again to FIG. 2, decision block 212 reflects looping back to block 206 while the baseline testing is still in progress. As will be appreciated, the baseline testing (i.e., testing all patterns) should be performed for a sufficient number of chips so as to obtain a statistically meaningful average score for the tests for ranking purposes, but not for so many chips as to increase the overall testing time. Otherwise, the purpose of test pattern reduction is arguably defeated.Once the initial baseline testing is complete, the process proceeds to block 214, where streamlined testing on additional chips is run using a selected subset of the total patterns (the selection based on the rankings obtained in the baseline testing) for a first defined duration. By \u201cduration\u201d it is contemplated that the streamlined testing may be governed by a specific time period or by a specific number of wafers or chips tested. During the streamlined testing using a reduced set of the total patterns, no pattern scoring or updated averages are calculated. Rather, this represents a time period in which the benefits of the pattern scoring are utilized, in that only the most effective patterns to date are used for reduced testing time while decreasing the chances of bad chip escapes.In keeping with the above test pattern example, it will be assumed that the selected number of the reduced set of patterns to be used in streamlined testing is 10 (i.e., 50% of the total. In this case, of the total set of patterns A through T, the highest ranked 10 patterns after baseline testing (and therefore those used) beginning at block 214 may be, for example: K, A, T, H, C, J, E, L, D, S.So long as decision block 216 determines that the defined first duration is not yet completed, the process loops back to block 214 where streamlined testing continues using the reduced set of patterns. However, once this first duration is complete, the process proceeds to block 218 for a return to full pattern set testing for a second defined duration, including updated scoring and ranking of the test patterns as was done for the baseline testing. In this manner, the rankings of the most effective test patterns may change over the course of additional lot testing. Thus, in the event the originally selected subset for streamlined testing after baseline testing is no longer optimal, the updated full pattern testing in block 218 will determine a new ranking for further streamlined testing. Decision block 220 tracks the second duration of updated full pattern testing/ranking, and loops back to block 218 until the second duration is complete.A cadence may be established and parameterized with respect to the first and second durations. After initial baseline testing, the streamlined testing using a reduced pattern set may be performed at a duty cycle of, for example about 80%, after which the testing process reverts to a full pattern set with updated pattern scoring/ranking for about 20% of the time. As should be appreciated, the first and second durations may be selected so as to strike an appropriate balance between testing with the reduced, optimized test pattern set and full testing so as to dynamically and adaptively update the scoring and ensure the optimization of the pattern ranking. Moreover, the duty cycle may be defined in terms of number of chips. For example, streamlined testing may be used for about 80% of chips to be tested following baseline testing, and full testing may be used for about 20% of chips to be tested following baseline testing.Optionally, during the overall testing process, the method 200 may include detection of a \u201creset\u201d criteria where upon determination some type of defined event, the initial baselining starts over, with the current pattern ranking erased. A reset event may include, for example, reaching a defined count of failing chips, detecting a change in the observed yield, reaching a beginning of a new lot of wafers, etc. This option is reflected by decision block 222 in FIG. 2 where, if a reset event is detected, the process reverts back to block 204 for new baseline testing as described above. While this determination is shown after the full pattern testing portion of the duty cycle in FIG. 2, such a determination of a reset criteria may be inserted at any point following the initial baselining.So long as the testing continues as determined in decision block 224, following completion of the second duration (block 220), and assuming no reset event is detected, the process loops back to block 214 for the streamlined portion of the duty cycle. Finally, once testing is completed, the process ends at block 226.To illustrate the usefulness of briefly returning to full testing and updated patterning ranking for a second duration after a first duration of streamlined testing, FIG. 3 is a table illustrating hypothetical test results using the above described example of baseline testing, streamlined testing, and full pattern testing of the 20 test patterns A through T. Time t0 reflects the start of the initial baseline testing of chips using all 20 patterns A through T. After the completion of the initial baseline testing, in the above example, the top scoring 10 test patterns were ranked in the order of: K, A, T, H, C, J, E, L, D, S. Thus, at the beginning of the first streamlined testing period at time t0, those 10 patterns are used for streamlined testing.At time t2, the testing reverts back to all 20 patterns as reflected in FIG. 3. This may result in a reordering of the rankings as different chips are tested, which in turn could result in a different subset of 10 patterns being used for the next duration of streamlined testing. In the example depicted, it will be seen that at time t3 where the next period of streamlined testing is implemented, tests C, E and S are no longer ranked in the top 10 in scoring and thus are removed from streamlined testing for the time being. Instead, they are replaced by tests B, M and N, whose scores increased during the full testing at time t2. It is also noted, for example, as between the first and second instances of streamlined testing at times t1 and t3, tests A and T (while still in the top 10) have switch places in accordance with the updated rankings.Over time, and as the process reverts between streamlined testing and full testing with updated pattern scoring and ranking, further changes are conceivable. For example, whereas test pattern K was initially ranked as the best for uniquely identifying failing devices, at time t5, test pattern T has taken over the top ranking. In addition, test pattern M is once again removed from streamlined testing as it was no longer in the top ten as of t5.As will thus be appreciated, among the advantages of the above described algorithm include minimal complexity of the data structures and computation in keeping a running score average and sorting the pattern list based on the score. In addition, no past test information is needed since the algorithm adapts as testing of product progresses, and thus makes better decisions on pattern ranking based on the material being tested. Still further, the algorithm stands alone, in that no interaction with other test cells is needed.Actual trials of the above described pattern sampling technique have been conducted on a standard microprocessor. Trials included a re-run of already sorted wafers with a sampling program, and split wafer lots where half the wafers were run process-of-record, and half with pattern sampling. In wafer split lot trials, the devices failing module test were analyzed to get an escape count. In all trials, LBIST patterns were sampled. The baseline sample was five failing devices, and the pattern sampling consisted of half the patterns on 80% of the devices.In the re-run wafer trial, 10 wafers with 3690 chip starts were run with both the process of record (POR) program, and then again with the sampling program. There were 1383 \u201cgoods\u201d and 60 LBIST fails from the POR test; a re-run with the sampling program yielded exactly the same results, with zero escapes. By way of further comparison, for a wafer split lot trial using 2513 starts for the POR test, the resulting module yield was 98.7%. Using 2634 starts for the sampling test, the resulting module yield was 98.8%. Of the modules tested by running the sampling wafer program, 25 of those were analyzed as potential candidates for being actual test escapes. Of the 25 devices analyzed, it was determined that only one module fail was due to wafer pattern sampling. The failing device was determined to have failed only one LBIST pattern, and traceback to wafer test showed that this one pattern was not run on the device.In summary, of all trials conducted, there were only 2 escapes out of 6977 total candidates, or 0.0287%. In both cases, the escapes resulted from devices that failed just a single pattern. The cost of building a bad module for the studied product is about $5, thus two escapes results in a total cost $10. On the other hand, the sampling of LBIST saves half the LBIST test time on 80% of the material. For the studied product, this time saving amounts to about 0.5 seconds per device. At a cost of $0.05/second, the cost of test savings on 6977 devices is about $170. Therefore, the present sampling technique demonstrates a clear cost benefit (>15\u00d7) for this application.Generally, the method embodiments for implementing integrated circuit device testing using adaptive test pattern selection may be practiced with a general-purpose computer and the method may be coded as a set of instructions on removable or hard media for use by the general-purpose computer. FIG. 4 is a schematic block diagram of a general-purpose computing system suitable for practicing embodiments of the present invention. In FIG. 4, computing system 400 has at least one microprocessor or central processing unit (CPU) 405. CPU 405 is interconnected via a system bus 410 to a random access memory (RAM) 415, a read-only memory (ROM) 420, an input/output (I/O) adapter 425 for a connecting a removable data and/or program storage device 430 and a mass data and/or program storage device 435, a user interface adapter 440 for connecting a keyboard 445 and a mouse 450, a port adapter 455 for connecting a data port 460 and a display adapter 465 for connecting a display device 470.ROM 420 contains the basic operating system for computing system 400. The operating system may alternatively reside in RAM 415 or elsewhere as is known in the art. Examples of removable data and/or program storage device 430 include magnetic media such as floppy drives and tape drives and optical media such as CD ROM drives. Examples of mass data and/or program storage device 435 include hard disk drives and non-volatile memory such as flash memory. In addition to keyboard 445 and mouse 450, other user input devices such as trackballs, writing tablets, pressure pads, microphones, light pens and position-sensing screen displays may be connected to user interface 440. Examples of display devices include cathode-ray tubes (CRT) and liquid crystal displays (LCD).A computer program with an appropriate application interface may be created by one of skill in the art and stored on the system or a data and/or program storage device to simplify the practicing of this invention. In operation, information for or the computer program created to run the present invention is loaded on the appropriate removable data and/or program storage device 430, fed through data port 460 or typed in using keyboard 445.In view of the above, the present method embodiments may therefore take the form of computer or controller implemented processes and apparatuses for practicing those processes. The disclosure can also be embodied in the form of computer program code containing instructions embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other computer-readable storage medium, wherein, when the computer program code is loaded into and executed by a computer or controller, the computer becomes an apparatus for practicing the invention. The disclosure may also be embodied in the form of computer program code or signal, for example, whether stored in a storage medium, loaded into and/or executed by a computer or controller, or transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein, when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing the invention. When implemented on a general-purpose microprocessor, the computer program code segments configure the microprocessor to create specific logic circuits. A technical effect of the executable instructions is to implement the exemplary method described above and illustrated in FIG. 2.While the invention has been described with reference to a preferred embodiment or embodiments, it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted for elements thereof without departing from the scope of the invention. In addition, many modifications may be made to adapt a particular situation or material to the teachings of the invention without departing from the essential scope thereof. Therefore, it is intended that the invention not be limited to the particular embodiment disclosed as the best mode contemplated for carrying out this invention, but that the invention will include all embodiments falling within the scope of the appended claims.","Export Citation":"Click for automatic bibliographygeneration","Field of Search":"714/726, 714/33, 714/745, 714/728","Filing Date":"06/29/2011","International Classes":"G01R31/28","Inventors":"Grady, Matthew S. (Burlington, VT, US)Johnson, Mark C. (South Burlington, VT, US)Pepper, Bradley D. (Essex Junction, VT, US)Percy, Dean G. (Stowe, VT, US)Pranys, Joseph C. (South Burlington, VT, US)","Other Classes":"714/745","Other References":"Bahukudumbi, S.; Chakrabarty, K, \u201cPower Management Using Test-Pattern Ordering for Wafer-Level Test During Burn-In,\u201d Very Large Scale Integration (VLSI) Systems, IEEE Transactions on , vol. 17, No. 12, pp. 1730,1741, Dec. 2009.Lima, M.F.; Zarpel\u00e3o, B.B.; Sampaio, L.D.H.; Rodrigues, J. J P C; Abrao, T.; Proen\u00e7a, M.L., \u201cAnomaly detection using baseline and K-means clustering,\u201d Software, Telecommunications and Computer Networks (SoftCOM), 2010 International Conference on , vol., no., pp. 305,309, Sep. 23-25, 2010.Sounil Biswas and R.D. Blanton, \u201cTest Compaction for Mixed-Signal Circuits Using Pass-Fail Test Data,\u201d 26th IEEE VLSI Test Symposium, IEEE Computer Society, p. 299- 308, 2008.Ender Yilmaz & Sule Ozev, \u201cAdaptive Test Elimination for Analog/RF Circuits,\u201d DAC'09, California, pp. 720-725, 2009.","Primary Class":"714/728","Primary Examiner":"BRITT, CYNTHIA H","Publication Date":"04/01/2014","Title":"Integrated circuit test optimization using adaptive test pattern sampling algorithm","US Patent References":"20100088560METHOD AND SYSTEM FOR SELECTING TEST VECTORS IN STATISTICAL VOLUME DIAGNOSIS USING FAILED TEST DATA2010-04-08Chakravarthy et al.714/72420100088054METHODS AND APPARATUS FOR DATA ANALYSIS2010-04-08Miguelanez et al.20090018793METHOD AND SYSTEM FOR REDUCING DEVICE TEST TIME2009-01-15Sakarovitch et al.7474979Integrated circuit device test system and method2009-01-06Stevens et al.20080263423System and Method for Nonlinear Statistical Encoding in Test Data Compression2008-10-23Ward20080234967Test Sequence Optimization Method and Design Tool2008-09-25Vandewiele et al.7421621Application integration testing2008-09-02Zambrana714/38.1420080172576METHOD FOR ENHANCING THE DIAGNOSTIC ACCURACY OF A VLSI CHIP2008-07-17Kusko et al.714/337363557System for at-speed automated testing of high serial pin count multiple gigabit per second devices2008-04-22Evans7284167Automated tests for built-in self test2007-10-16Lee et al.7139676Revising a test suite using diagnostic efficacy evaluation2006-11-21Barford6907378Empirical data based test optimization method2005-06-14Stirrat et al.20050102566Method for diagnosing complex system faults2005-05-12Manley et al.714/256708306Method for diagnosing failures using invariant analysis2004-03-16Bartenstein et al.714/7416603691SEMICONDUCTOR DEVICE INCLUDING BUILT-IN REDUNDANCY ANALYSIS CIRCUIT FOR SIMULTANEOUSLY TESTING AND ANALYZING FAILURE OF A PLURALITY OF MEMORIES AND METHOD FOR ANALYZING THE FAILURE OF THE PLURALITY OF MEMORIES2003-08-05Yoo et al.6473871Method and apparatus for HASS testing of busses under programmable control2002-10-29Coyle et al.714/7156377901Method and apparatus for adaptively learning test measurement delays on an individual device test for reducing total device test time2002-04-23List et al.6367041Self-adaptive test program2002-04-02Statovici et al.","View Patent Images":"Download PDF 8689066"},"United States Patent 9347993":{"Abstract":"Aspects of the invention relate to test generation techniques for test-per-clock. Test cubes may be generated by adding constraints to a conventional automatic test pattern generator. During a test cube merging process, a first test cube is merged with one or more test cubes that are compatible with the first test cube to generate a second test cube. The second test cube is shifted by one bit along a direction of scan chain shifting to generate a third test cube. The third test cube is then merged with one or more test cubes in the test cubes that are compatible with the third test cube to generate a fourth test cube. The shifting and merging operations may be repeated for a predetermined number of times.","Application Number":"13/919984","Assignee":"Mentor Graphics Corporation (Wilsonville, OR, US)","Attorney, Agent or Firm":"MENTOR GRAPHICS (KS) (Orlando, FL, US)","Claims":"What is claimed is:1.A method for generating a test pattern for testing an electronic circuit, comprising: by at least one processor of a computer, generating a plurality of test cubes for testing the electronic circuit; by the at least one processor of the computer, selecting, from the plurality of test cubes, a first test cube to be applied by one or more scan chains of the electronic circuit during the testing; by the at least one processor of the computer, merging the first test cube with one or more test cubes in the plurality of test cubes that are compatible with the first test cube to generate a second test cube to be applied by the one or more scan chains of the electronic circuit during the testing; by the at least one processor of the computer, shifting the second test cube by one bit along a shift direction of the one or more scan chains in the electronic circuit to generate a third test cube, such that the last bit of the second test cube along the shift direction is the second to last bit of the third test cube along the shift direction; and by the at least one processor of the computer, merging the third test cube with one or more test cubes in the plurality of test cubes that are compatible with the third test cube to generate a fourth test cube to be applied by the one or more scan chains of the electronic circuit during the testing, wherein at least one of the one or more test cubes that is compatible with the third test cube is not compatible with the first or second test cubes.2.The method recited in claim 1, further comprising: by the at least one processor of the computer, shifting the fourth test cube by one bit along the shift direction of the one or more scan chains in the electronic circuit to generate a fifth test cube; by the at least one processor of the computer, merging the fifth test cube with one or more test cubes in the plurality of test cubes that are compatible with the fifth test cube to generate a sixth test cube to be applied by the one or more scan chains of the electronic circuit during the testing, wherein at least one of the one or more test cubes that is compatible with the fifth test cube is not compatible with the third or fourth test cubes; and repeating the shifting and the merging for a predetermined number of times.3.The method recited in claim 1, wherein the plurality of test cubes are generated according to a configuration of multiple scan chains of the electronic circuit: a first portion of the multiple scan chains configured to operate in a shifting-launching mode, a second portion of the multiple scan chains configured to operate in a capturing-compacting-shifting mode, and a third portion of the multiple scan chains configured to operate in a mission mode.4.The method recited in claim 3, wherein the capturing-compacting-shifting mode is a mode of compaction with blocking.5.The method recited in claim 3, wherein the capturing-compacting-shifting mode is a mode of compaction without blocking.6.The method recited in claim 3, wherein the shifting-launching mode is the only mode that allows a scan chain to have specified bits.7.One or more non-transitory computer-readable media storing computer-executable instructions for causing one or more processors to perform a method for generating a test pattern for testing an electronic circuit, the method comprising: generating a plurality of test cubes for testing the electronic circuit; selecting a first test cube, from the plurality of test cubes, to be applied by one or more scan chains of the electronic circuit during the testing; merging the first test cube with one or more test cubes in the plurality of test cubes that are compatible with the first test cube to generate a second test cube to be applied by the one or more scan chains of the electronic circuit during the testing; shifting the second test cube by one bit along a direction of scan chain shifting of the one or more scan chains of the electronic circuit to generate a third test cube, such that the last bit of the second test cube along the shift direction is the second to last bit of the third test cube along the shift direction; and merging the third test cube with one or more test cubes in the plurality of test cubes that are compatible with the third test cube to generate a fourth test cube to be applied by the one or more scan chains of the electronic circuit during testing, wherein at least one of the one or more test cubes that is compatible with the third test cube is not compatible with the first or second test cubes.8.The one or more non-transitory computer-readable media recited in claim 7, wherein the method for generating the test pattern for testing the electronic circuit further comprises: shifting the fourth test cube by one bit along the direction of scan chain shifting of the one or more scan chains of the electronic circuit to generate a fifth test cube; merging the fifth test cube with one or more test cubes in the plurality of test cubes that are compatible with the fifth test cube to generate a sixth test cube to be applied by the one or more scan chains of the electronic circuit during testing, wherein at least one of the one or more test cubes that are compatible with the fifth test cube is not compatible with the third or fourth test cubes; and repeating the shifting and the merging for a predetermined number of times.9.The one or more non-transitory computer-readable media recited in claim 7, wherein the plurality of test cubes are generated according to a configuration of scan chains of the electronic circuit: a first portion of the scan chains of the electronic circuit configured to operate in a shifting-launching mode, a second portion of the scan chains of the electronic circuit configured to operate in a capturing-compacting-shifting mode, and a third portion of the scan chains of the electronic circuit configured to operate in a mission mode.10.The one or more non-transitory computer-readable media recited in claim 9, wherein the compaction mode is a mode of compaction with blocking.11.The one or more non-transitory computer-readable media recited in claim 9, wherein the compaction mode is a mode of compaction without blocking.12.The one or more non-transitory computer-readable media recited in claim 9, wherein the shifting-launching mode is the only mode that allows a scan chain to have specified bits.13.A system comprising: one or more processors, the one or more processors programmed to perform a method for generating a test pattern for testing an electronic circuit, the method comprising: generating a plurality of test cubes for testing the electronic circuit; selecting, from the plurality of test cubes, a first test cube to be applied by one or more scan chains of the electronic circuit during the testing; merging the first test cube with one or more test cubes in the plurality of test cubes that are compatible with the first test cube to generate a second test cube to be applied by the one or more scan chains of the electronic circuit during the testing; shifting the second test cube by one bit along a shift direction of the one or more scan chains in the electronic circuit to generate a third test cube, such that the last bit of the second test cube along the shift direction is the second to last bit of the third test cube along the shift direction; and merging the third test cube with one or more test cubes in the plurality of test cubes that are compatible with the third test cube to generate a fourth test cube to be applied by the one or more scan chains of the electronic circuit during the testing, wherein at least one of the one or more test cubes that is compatible with the third test cube is not compatible with the first or second test cubes.14.The system recited in claim 13, wherein the method further comprises: shifting the fourth test cube by one bit along the shift direction of the one or more scan chains in the electronic circuit to generate a fifth test cube; merging the fifth test cube with one or more test cubes in the plurality of test cubes that are compatible with the fifth test cube to generate a sixth test cube to be applied by the one or more scan chains of the electronic circuit during the testing, wherein at least one of the one or more test cubes that is compatible with the fifth test cube is not compatible with the third or fourth test cubes; and repeating the shifting and the merging for a predetermined number of times.15.The system recited in claim 13, wherein the plurality of test cubes are generated according to a configuration of scan chains of the electronic circuit: a first portion of the scan chains of the electronic circuit configured to operate in a shifting-launching mode, a second portion of the scan chains of the electronic circuit configured to operate in a capturing-compacting-shifting mode, and a third portion of the scan chains of the electronic circuit configured to operate in a mission mode.16.The system recited in claim 15, wherein the compaction mode is a mode of compaction with blocking.17.The system recited in claim 15, wherein the compaction mode is a mode of compaction without blocking.18.The system recited in claim 15, wherein the shifting-launching mode is the only mode that allows a scan chain to have specified bits.","Description":"FIELD OF THE INVENTIONThe present invention relates to the field of circuit testing technology. Various implementations of the invention may be particularly useful for scan chain-based testing.BACKGROUND OF THE INVENTIONSince its introduction in the late 1960's, scan-based testing has gained a wide acceptance as a structured design-for-test (DFT) methodology. This methodology connects memory elements such as flip-flops and latches in a circuit to form scan chains and uses them to make internal nodes of the circuit highly controllable and observable. The controllability and observability enables high-quality automated test generation for large industrial circuit designs.A commonly used scheme of the scan-based testing is test-per-scan. In a test-per-scan system, a test pattern is first shifted into scan chains and subsequently applied to the circuit-under-test. The test responses generated by the circuit-under-test are then captured by and shifted out of the scan chains for analysis. In this testing scheme, the shifting in and out operations require much more clock cycles to perform than the actual testing (i.e. launching and capturing) operation does. Moreover, in part due to power concerns, the shifting clock is usually kept slower than the clock for the circuit's normal operation. This further increases time for the data loading and unloading operations.Consider, for example, a circuit design with 100,000 scan cells. These scan cells are divided into 500 scan chains, each 200 scan cells long. Assume the shifting and the normal operating clock frequencies of 50 MHz and 500 MHz, respectively. Applying 20,000 double-capture test patterns requires 4,000,000 shift cycles at 50 MHz and 40,000 capture cycles at 500 MHz. As a result, as low as 1% of cycles, or just 0.1% of time, is spent on the actual testing operation\u2014applying test data and capturing test response data. If a BIST (built-in self-test) method is used for the same circuit design, the test time efficiency could be even lower. With 100K single-capture test patterns, 20,000,000 cycles are needed for scan shifting while only 100,000 cycles are needed for launching and capturing. Using the same clock frequencies as the above example, 99.95% of test time is spent on scan shifting. The above two examples demonstrate that the test-per-scan scheme, though well developed and widely adopted, is not very efficient with respect to testing time.An alternative scheme, test-per-clock, has been developed mainly for BIST. In a conventional test-per-clock BIST system, the outputs of a test pattern generator are directly coupled to the inputs of the circuit-under-test. Accordingly, a new test pattern is applied to the circuit-under-test at every test clock cycle.A 1979 paper by Konemann et al., \u201cBuilt-in logic block observation techniques,\u201d 1979 IEEE Test Conference, which is incorporated herein by reference, describes such a system referred to as BILBO (built-in logic block observer). A BILBO is composed of a flipflop register with additional gates for shift and feedback operations. Four different operational modes can be performed by the BILBO: a mission mode (normal circuit functional mode with scan cells working as latches), a linear shift register mode, a feedback mode, and a reset mode for register resetting. In the feedback mode, the BILBO can work either as a multiple-input signature register (MISR) for compacting test responses or as a linear feedback shift register (LFSR) for generating pseudorandom test patterns. The latter is accomplished by keeping constant values at the parallel inputs of the scan chain.The 1979 paper describes an example of a test-per-clock architecture with BILBOs working in pairs. One BILBO in a BILBO pair is configured to operate in the feedback mode functioning as a linear feedback shift register. This LFSR BILBO generates and launches a test pattern every test clock cycle. In the meantime, the other BILBO in the pair is configured to operate also in the feedback mode but functioning as a multiple-input signature generator. This MISR BILBO captures a test response every test clock cycle and compacts it with its previously compacted test response to form a new compacted test response. After a number of test clock cycles, a test response signature is eventually shifted out of the MISR BILBO by switching its operational mode from the feedback mode to the linear shift register mode. The unloaded test response signature can then be analyzed.Another test-per-clock BIST system is described in a 1989 paper by Krasniewski et al., \u201cCircular self-test path: a low cost BIST technique for VLSI circuits,\u201d IEEE Trans. CAD, vol. 8, pp. 46-55, 1989, which is incorporated herein by reference. This system uses a feedback shift register with the last flipflop being supplied to the first flipflop. This shift register serves simultaneously for test pattern generation and test response compaction.Compared to the test-per-scan scheme, the test-per-clock scheme is more time-efficient because no slow shifting operation is needed for every test pattern. However, the conventional test-per-clock BIST scheme may have a problem on power consumption. In the traditional test-per-clock BIST scheme, all scan chains change their contents every clock cycle no matter whether they are used for pattern generation or for test response compaction. This can lead to excessive circuit toggling and thus power dissipation. Moreover, the traditional test-per-clock scheme has been developed mainly for BIST. It is desirable to develop a new test-per-clock scheme that not only is more time-efficient than the test-per-scan scheme but also addresses the limitations of the existing test-per-clock scheme. Disclosed below are techniques related to a new test-per-clock scheme, in particular, test generation techniques for the new test-per-clock scheme to be applicable to deterministic testing.BRIEF SUMMARY OF THE INVENTIONAspects of the invention relate to test generation techniques for test-per-clock. Test cubes may be generated by adding constraints to a conventional automatic test pattern generator. The constraints may be based on configurations of scan chains. In a configuration of the scan chains, a first portion of the scan chains is configured to operate in a shifting-launching mode; a second portion of the scan chains is configured to operate in a capturing-compacting-shifting mode; and a third portion of the scan chains is configured to operate in a mission mode. The capturing-compacting-shifting mode may be a mode of capturing-compacting-shifting with blocking or a mode of capturing-compacting-shifting without blocking. The shifting-launching mode may be the only mode that allows a scan chain to have specified bits.During a test cube merging process, a first test cube is selected from test cubes generated for a particular scan chain configuration. The first test cube is then merged with one or more test cubes in the test cubes that are compatible with the first test cube to generate a second test cube.The second test cube is shifted by one bit along a direction of scan chain shifting to generate a third test cube. The third test cube is then merged with one or more test cubes in the test cubes that are compatible with the third test cube to generate a fourth test cube. The shifting and merging operations may be repeated for a predetermined number of times.BRIEF DESCRIPTION OF THE DRAWINGSFIG. 1 illustrates an example of a test architecture for test-per-clock based on dynamically partitioned and reconfigurable scan chains that may be employed by various embodiments of the invention.FIG. 2 illustrates a flow chart describing methods of test-per-clock based on dynamically-partitioned configurable scan chains that may be employed by various embodiments of the invention.FIG. 3 illustrates an example of how the scan chains 121-125 in FIG. 1 interact with each other during testing.FIG. 4 illustrates a flow chart describing methods of test cube merging that may be employed by various embodiments of the invention.FIG. 5 illustrates an example of a test cube merging process for one scan chain according to various embodiments of the invention.FIG. 6 illustrates a programmable computer system with which various embodiments of the invention may be employed.DETAILED DESCRIPTION OF THE INVENTIONVarious aspects of the present invention relate to test generation techniques for test-per-clock. In the following description, numerous details are set forth for the purpose of explanation. However, one of ordinary skill in the art will realize that the invention may be practiced without the use of these specific details. In other instances, well-known features have not been described in details to avoid obscuring the present invention.Some of the techniques described herein can be implemented in software instructions stored on a computer-readable medium, software instructions executed on a computer, or some combination of both. Some of the disclosed techniques, for example, can be implemented as part of an electronic design automation (EDA) tool. Such methods can be executed on a single computer or on networked computers.The detailed description of a method or a device sometimes uses terms like \u201cmerge\u201d and \u201cshift\u201d to describe the disclosed method or the device function/structure. Such terms are high-level abstractions. The actual operations or functions/structures that correspond to these terms will vary depending on the particular implementation and are readily discernible by one of ordinary skill in the art. It should also be appreciated by one of ordinary skill in the art that the term \u201ccoupled\u201d means \u201cconnected directly or indirectly.\u201dAlthough the operations of the disclosed methods are described in a particular sequential order for convenient presentation, it should be understood that this manner of description encompasses rearrangements, unless a particular ordering is required by specific language set forth below. For example, operations described sequentially may in some cases be rearranged or performed concurrently. Moreover, for the sake of simplicity, the disclosed flow charts and block diagrams typically do not show the various ways in which particular methods can be used in conjunction with other methods.FIG. 1 illustrates an example of a test architecture for test-per-clock that may be employed by various embodiments of the invention. The test architecture 100 comprises a test stimuli source 110, scan chains 121-125, a test response collector 130, a configuration register 140 and a configuration source 150. The test stimuli source 110 may be an ATE (automated test equipment), a test data decompressor driven by an ATE, a PRPG (pseudorandom pattern generator), or any device that can supply test patterns in some form. The ATE is commonly used for deterministic testing. The deterministic testing usually employs test patterns generated by ATPG (automatic test pattern generation). To test a large circuit, compressed test patterns are often used.Before being shifted into scan chains, the compressed test patterns are decompressed by the test data decompressor. For non-deterministic testing such as BIST, the PRPG can serve as the test stimuli source.The test response collector 130 in the test architecture 100 may be the same ATE used as the test stimuli source 110, a test response compactor, or any device that can collect and perhaps analyze test responses shifted out of the scan chains. The test response compactor may compact test responses spatially, temporally, or both. The spatial compaction may be achieved by using a spatial compactor constructed with elementary gates such as AND, OR, NAND and NOR gates. The temporal compaction may be accomplished by using, for example, a multiple-input signature register (MISR).The test stimuli source 110 and the test response collector 130 described above are similar to those used in a conventional test architecture. The scan chains 121-125 in the test architecture 100, however, are configured differently from conventional scan chains. Unlike conventional scan chains, scan chains used in various embodiments of the invention can operate, depending on a control signal, in one of at least three modes: a shifting-launching mode, a capturing-compacting-shifting mode and a mission mode. In the mission mode, scan chains perform regular circuit functions; in the shifting-launching and capturing-compacting-shifting modes, scan chains are used for testing the circuit. Specifically, scan chains in the shifting-launching mode are responsible for controlling the internal states of the circuit-under-test. They shift test data in and applying them to the circuit-under-test every clock cycle. Moreover, they do not capture any test responses. Scan chains in the capturing-compacting-shifting mode, on the other hand, are responsible for collecting test response data generated by the circuit-under-test. They shift out one bit of a previously compacted test response signal while compacting remaining bits of the previously compacted test response signal with a currently-captured test response signal to form a currently compacted test response signal.In FIG. 1, the scan chains 121, 123 and 125 are shown to work in the shifting-launching mode, the capturing-compacting-shifting mode and the mission mode, respectively. The control signal for mode switching is generated by the configuration source 150 and applied to the scan chains 121, 123 and 125 by the configuration register 140. FIG. 1 only illustrates one configuration (partition) of the scan chains. Different partitions of the scan chains can be obtained by varying the control signal. The content of the configuration register 140 can be reloaded during a test session, depending on various requirements. In particular, the control signal may be varied with test patterns applied. The configuration source 150 may be an on-chip device or an external device.As seen in the figure, a majority of the scan chains operate in the mission mode. This arrangement can alleviate power issues because logic states associated with these scan chains closely resemble those when the circuit works in its designed functional mode. Only a small portion of the scan chains may cause extrinsic circuit toggling. In a conventional at-speed scan test, by contrast, a capture clock burst is applied to all scan chains which can result in a sudden current change within a few nanoseconds and thereby circuit failures.FIG. 2 illustrates a flow chart 200 describing methods of test-per-clock based on dynamically-partitioned configurable scan chains that may be employed by various embodiments of the invention. FIG. 3 illustrates an example of how the scan chains 121-125 in FIG. 1 interact with each other during testing. To simplify the figure, only one scan chain is used to represent scan chains in each operation mode. For ease of understanding, methods of test-per-clock based on dynamically partitioned and reconfigurable scan chains that may be employed according to various embodiments of the invention will be described with reference to the flow chart 200 in FIG. 2 and the test architecture 100 illustrated in FIG. 3. It should be appreciated, however, that alternate implementations of a test architecture may be used to perform the methods of test-per-clock based on dynamically-partitioned configurable scan chains illustrated by the flow chart 200 according to various embodiments of the invention. Likewise, the test architecture 100 may be employed to perform other methods of test-per-clock based dynamically-partitioned configurable scan chains according to various embodiments of the invention.In operation 210, test stimuli are shifted from a stimuli source (test stimuli source 110) into a first portion of a plurality of scan chains in a circuit (scan chains 121) one bit per scan chain to form a new test pattern as illustrated by an arrow 350. The connections between the test stimuli source 110 and the scan chains 123 and 125 are blocked as illustrated by arrows 370 with broken lines.Immediately after being formed, in operation 220, the new test pattern is applied to the circuit. The new test pattern propagates through the combinational part of the circuit until a test response reaches a second portion of the plurality of scan chains (scan chains 123) as illustrated by an arrow 310. A circuit response caused by the new test pattern also reaches a third portion of the plurality of scan chains (scan chains 125) as illustrated by an arrow 320. This circuit response will circulate within the circuit and eventually reach the scan chains 123 as illustrated by arrows 330.In operation 230, the scan chains 123 shift out previously compacted test response data one bit per scan chain to the test response collector 130 as illustrated by an arrow 360. The connections between the test response collector 130 and the scan chains 121 and 125 are blocked as illustrated by arrows 380 with broken lines.At about the same time as the operation 230, in operation 240, the test response corresponding to the new test pattern is compacted with the previously compacted test response data to generate newly compacted test response data in the scan chains 123. As shown in FIG. 3, the scan chains 123 are also employed to drive the circuit as illustrated by arrows 340, which is referred to as a mode of capturing-compacting-shifting without blocking. This functionality can be disabled if needed and the scan chains operate in a mode referred to as a mode of capturing-compacting-shifting with blocking.As noted previously, the scan chains 121, 123 and 125 are configured to operate in the shifting-launching mode, the capturing-compacting-shifting mode and the mission mode, respectively, based on the control signal stored in the configuration register 140. The above four operations may be performed once for every clock cycle for a predetermined number of times. At the end, a different control signal may be loaded into the configuration register 140 to reconfigure the scan chains. The reconfigured scan chains are then employed for the next test pattern(s). This dynamic partitioning and reconfiguring approach contrasts not only the conventional scan method but also the BILBO approach discussed in the background section.Another difference between various embodiments of the present invention and the BILBO-based techniques may lie in the operation of test response compaction. As previously noted, a BILBO scan chain in the feedback mode works as a multiple-input signature generator for compacting test responses: Test responses are captured and compacted for a number of clock cycles (corresponding to the same number of test patterns) to generate a signature. No bit of the compacted test response signal is shifted out during that time period. Instead, the signature is shifted out after a number of test patterns are applied. By contrast, a scan chain in the capturing-compacting-shifting mode according to various embodiments of the invention does not have a feedback loop. Moreover, one bit of previously compacted test response data is shifted out every clock cycle.By adopting the test-per-clock scheme, various embodiments of the invention remove the lengthy scan shift-in phase used in the test-per-scan scheme and perform launch-capture testing every clock cycle. This allows more test patterns to be applied within a certain period of time and may improve the fault coverage. Alternatively, one can choose to apply the same number of test patterns as that of a conventional scan test, yet in a much shorter period of time, thereby reducing the test cost.By dynamically partitioning and reconfiguring the scan chains, the disclosed test-per-clock scheme can allow the majority of scan chains to operate in the mission mode to alleviate power issues without significant impact on test generation and fault coverage. The control signal remains static after a given configuration is established. It can, therefore, be placed and routed with no rigid timing constrains similar to those of scan enable signals whose distribution and delivery, especially for the at-speed test purpose, must meet non-flexible timing closure conditions. The low-power capabilities may enable applying test patterns at higher, close to the functional, frequency, which can further increase fault coverage metrics.Conventional automatic test pattern generation and test cube merging techniques are designed for test-per-scan. To apply the disclosed test-per-clock scheme to deterministic testing, new automatic test pattern generation and test cube merging techniques need to be developed. FIG. 4 illustrates a flow chart 400 describing methods of test cube merging that may be employed by various embodiments of the invention.Initially, in operation 410, a test cube (referred to as the first test cube) is selected from a plurality of test cubes. The plurality of test cubes may be generated by adding various constrains to a conventional automatic test pattern generator. One such constraint that may be employed by various embodiments of the invention is force scan cells in the mission mode to operate as non-scan memory elements. The automatic test pattern generator is only allowed to specify stimuli and justification data in scan cells in the shifting-launching mode. The observation values of these scan cells in the shifting-launching mode are set to unknown value (X) as they do not observe data arriving from the circuit-under-test. Meanwhile, scan cells in the capturing-compacting-shifting mode are not allowed to specify stimuli but are allowed to capture test responses. Whenever a fault propagates to a scan chain in the capturing-compacting-shifting mode, it is temporarily marked as detected. This conjecture may be invalidated after additional analysis of fault aliasing. The control signals used to configure scan cells are constrained to appropriate values. It prevents data produced by the circuit from being captured during subsequent cycles of sequential fault simulation.Next, in operation 420, the first test cube is merged with one or more test cubes in the plurality of test cubes that are compatible with the first test cube to generate a second test cube. Two test cubes are compatible if they do not have conflicting specified bits. This merging operation can be performed following how a conventional merging operation performs. The merged test cube usually has more specified bits than the original test cubes.Next, in operation 430, the second test cube is shifted by one bit along a direction of scan chain shifting to generate a third test cube. Suppose bits 0 and N are the last and first bits of a test cube to be shifted into scan chains, respectively. The operation 430 shifts the second test cube to form the third test cube such that for each scan chain, bit 0 of the second test cube becomes bit 1 of the third test cube and bit N\u22121 of the second test cube becomes bit N of the third test cube. Bit 0 of the third test cube has an unspecified value.Next, in operation 440, the third test cube is merged with one or more test cubes in the plurality of test cubes that are compatible with the third test cube to generate a fourth test cube. Due to the shifting operation 430, some test cubes, incompatible with the second test cube, become compatible with and thus can be merged with the third test cube.Similar to operation 430, the fourth test cube may be shifted by one bit along the direction of scan chain shifting to generate a fifth test cube. Also similar to operation 440, the fifth test cube may be merged with one or more test cubes in the test cubes that are compatible with the fifth test cube to generate a sixth test cube. Such shifting and merging operations may be repeated for a predetermined number of times.FIG. 5 illustrates an example of the above process for one scan chain. In clock cycle 1, two test cubes, 530 and 540, are merged for loading scan chain 500. In clock cycle 2, the content of the scan chain 500, the merging result of test cubes 510 and 520, is shifted right (direction of scan chain shifting) by one bit. As a result, test cube 520 becomes compatible with and thus merged with the current content of the scan chain 500. Next, in clock cycle 3, the content of the scan chain 500 is shifted again by one bit along the direction of scan chain shifting. The shifted content of the scan chain 500 is then merged with the test cube 510 to form new content of the scan chain 500. Under this scheme, many originally incompatible test cubes may be merged and the filling rate can be significantly increased.Various embodiments of the invention may be implemented through the execution of software instructions by a computing device, such as a programmable computer. FIG. 6 shows an illustrative example of such a programmable computer (a computing device 601). As seen in this figure, the computing device 601 includes a computing unit 603 with a processing unit 605 and a system memory 607. The processing unit 605 may be any type of programmable electronic device for executing software instructions, but will conventionally be a microprocessor. The system memory 607 may include both a read-only memory (ROM) 609 and a random access memory (RAM) 611. As will be appreciated by those of ordinary skill in the art, both the read-only memory (ROM) 609 and the random access memory (RAM) 611 may store software instructions for execution by the processing unit 605.The processing unit 605 and the system memory 607 are connected, either directly or indirectly, through a bus 613 or alternate communication structure, to one or more peripheral devices. For example, the processing unit 605 or the system memory 607 may be directly or indirectly connected to one or more additional memory storage devices, such as a \u201chard\u201d magnetic disk drive 615, a removable magnetic disk drive 617, an optical disk drive 619, or a flash memory card 621. The processing unit 605 and the system memory 607 also may be directly or indirectly connected to one or more input devices 623 and one or more output devices 625. The input devices 623 may include, for example, a keyboard, a pointing device (such as a mouse, touchpad, stylus, trackball, or joystick), a scanner, a camera, and a microphone. The output devices 625 may include, for example, a monitor display, a printer and speakers. With various examples of the computer 601, one or more of the peripheral devices 615-625 may be internally housed with the computing unit 603. Alternately, one or more of the peripheral devices 615-625 may be external to the housing for the computing unit 603 and connected to the bus 613 through, for example, a Universal Serial Bus (USB) connection.With some implementations, the computing unit 603 may be directly or indirectly connected to one or more network interfaces 627 for communicating with other devices making up a network. The network interface 627 translates data and control signals from the computing unit 603 into network messages according to one or more communication protocols, such as the transmission control protocol (TCP) and the Internet protocol (IP). Also, the interface 627 may employ any suitable connection agent (or combination of agents) for connecting to a network, including, for example, a wireless transceiver, a modem, or an Ethernet connection. Such network interfaces and protocols are well known in the art, and thus will not be discussed here in more detail.It should be appreciated that the computer 601 is illustrated as an example only, and it not intended to be limiting. Various embodiments of the invention may be implemented using one or more computing devices that include the components of the computer 601 illustrated in FIG. 6, which include only a subset of the components illustrated in FIG. 6, or which include an alternate combination of components, including components that are not shown in FIG. 6. For example, various embodiments of the invention may be implemented using a multi-processor computer, a plurality of single and/or multiprocessor computers arranged into a network, or some combination of both.Some other embodiments of the invention may be implemented by software instructions, stored on a non-transitory computer-readable medium, for instructing one or more programmable computers/computer systems to perform operations such as those shown in the flow chart 400 in FIG. 4. As used herein, the term \u201cnon-transitory computer-readable medium\u201d refers to computer-readable medium that are capable of storing data for future retrieval, and not propagating electro-magnetic waves. The non-transitory computer-readable medium may be, for example, a magnetic storage device, an optical storage device, a \u201cpunched\u201d surface type device, or a solid state storage device.CONCLUSIONWhile the invention has been described with respect to specific examples including presently preferred modes of carrying out the invention, those skilled in the art will appreciate that there are numerous variations and permutations of the above described systems and techniques that fall within the spirit and scope of the invention as set forth in the appended claims. For example, while specific terminology has been employed above to refer to electronic design automation processes, it should be appreciated that various examples of the invention may be implemented using any desired combination of electronic design automation processes.","Export Citation":"Click for automatic bibliographygeneration","Field of Search":"714/733, 714/731, 714/726-727","Filing Date":"06/17/2013","International Classes":"G01R31/28; G01R31/3183; G01R31/3185","Inventors":"Rajski, Janusz (West Linn, OR, US)Solecki, Jedrzej (Poznan, PL)Tyszer, Jerzy (Poznan, PL)Mrugalski, Grzegorz (Swardzez, PL)","Other References":"B. Konemann, J. Mucha and G. Zwiehoff, Institut : \u201cBuilt-In Logic Block Observation Techniques\u201d 1979 IEEE Test Conference, Cherry Hill, New Jersey (1979).A. Krasniewski and S. Pilarski: \u201cCircular Self-Test Path: A Low-Cost BIST Technique for VLSI Circuits\u201d, IEEE Transactions on Computer Aided Design, vol. 8, No. 1 (Jan. 1989).","Primary Class":"1/1","Primary Examiner":"LAMARRE, GUY J","Publication Date":"05/24/2016","Title":"Test generation for test-per-clock","US Patent References":"20140372818Test-Per-Clock Based On Dynamically-Partitioned Reconfigurable Scan Chains2014-12-18Rajski et al.20120217989ARCHITECTURE, SYSTEM, METHOD, AND COMPUTER-ACCESSIBLE MEDIUM FOR EXPEDITED-COMPACTION FOR SCAN POWER REDUCTION2012-08-30Sinanoglu20110231721LOW POWER COMPRESSION OF INCOMPATIBLE TEST CUBES2011-09-22Czysz et al.714/72920100287430MULTIPLE-CAPTURE DFT SYSTEM TO REDUCE PEAK CAPTURE POWER DURING SELF-TEST OR SCAN TEST2010-11-11Wang et al.20100275077At-Speed Scan Testing With Controlled Switching Activity2010-10-28Rajski et al.714/73120090259900TEST PATTERN COMPRESSION FOR AN INTEGRATED CIRCUIT TEST ENVIRONMENT2009-10-15Rajski et al.714/72620090070646Multiple-Capture DFT system for scan-based integrated circuits2009-03-12Wang et al.20080235544Built-in self-test of integrated circuits using selectable weighting of test patterns2008-09-25Lai et al.714/72920070113129Method and Apparatus for Testing Logic Circuit Designs2007-05-17Balakrishnan et al.714/72620030097614Method and apparatus for at-speed testing of digital circuits2003-05-22Rajski et al.20020120896Multiple-capture DFT system for detecting or locating crossing clock-domain faults during self-test or scan-test2002-08-29Wang et al.","View Patent Images":"Download PDF 9347993"},"WIPO Patent Application WO/2003/065056":{"Abstract":"The invention relates to a test adapter system (1) for connecting test needles (4) of a test adapter (2) to a control device (3) for testing an especially component-carrying printed board assembly (5). Said system comprises at least two superposed, double-sided printed circuit-boards (61, 62, 63). Said printed circuit boards (61, 62, 63) respectively comprise test needle connection points (7) for test needles (4) of the test adapter (2), on a first side (U), and connection points (8) for the control device, on a second side (L) opposing the first side (U). The test needle connection points (7) of each printed circuit-board (61, 62, 63) are connected to control device connection points (8) of the same printed circuit-board (61, 62, 63) by means of a connecting structure (9), and the printed circuit-boards (61, 62, 63) are superposed in such a way that the second side (L) of a printed circuit-board (61, 62) with the control device connection points (8) located thereon, and the first side (U) of the underlying adjacent printed circuit-board (62, 63) with the test needle connection points (7) located thereon, are arranged in such a way that they face each other. The printed circuit-boards (61, 62, 63) also comprise passages (10U, 10L) which are formed in such a way that control device connection points (8) arranged on the second side (L) of a printed circuit-board (61, 62) can be directly contacted by means of passages (10L) formed in an underlying printed circuit-board (62,63), and test needle connection points (7) arranged on the first side (U) of the underlying printed circuit-board (62, 63) can be directly contacted by means of passages (10U) formed in the overlying printed circuit-board (61, 62).","Application Number":"PCT/EP2003/000858","Assignee":"TEST PLUS ELECTRONIC GMBH (DE)RAINER OTT (DE)","Attorney, Agent or Firm":"K\u00f6rber, Wolfhart (Sonnenstrasse 33, M\u00fcnchen, DE)","Claims":"ANSPR\u00dcCHE1. l. Testadaptersystem (1) zum Verbinden von Testnadeln (4) eines Testadapters (2) miteiner Pr\u00fcfeinrichtung (3) zum Testen einer insbesondere best\u00fccktenLeiterplatine (5),aufweisend wenigstens.2. zwei \u00fcbereinander angeordnete doppelseitigeLeiterplatten (61, 62,63), wobeidie Leiterplatten (6l, 62, 63) jeweils auf einer ersten Seite (U) TestnadelAnschlusspunkte (7) f\u00fcr Testnadeln (4) des Testadapters (2) und auf einer der erstenSeite (U) abgewandten zweiten Seite (L) Pr\u00fcfeinrichtungsAnschlusspunkte (8) f\u00fcrdie Pr\u00fcfeinrichtung (3) aufweisen,die TestnadelAnschlusspunkte (7) einer jeden Leiterplatte (61, 62, 63) \u00fcber eineVerbindungsstruktur (9) mit Pr\u00fcfeinrichtungsAnschlusspunkten (8) der selbenLeiterplatte (61, 62, 63) verbunden sind, unddie Leiterplatten (6,, 62, 63) so \u00fcbereinander angeordnet sind, dass die zweiteSeite (L) einer Leiterplatte (61, 62) mit den darauf angeordneten Pr\u00fcfeinrichtungsAnschlusspunkten (8) und die erste Seite (U) der darunterliegenden benachbartenLeiterplatte (62,63) mit den darauf angeordneten TestnadelAnschlusspunkten (7)einander zugewandt sind,wobei die Leiterplatten (61, 62, 63) ferner Durchbr\u00fcche (10U, 1OL) aufweisen, die soangeordnet sind, dass auf der zweiten Seite (L) einer Leiterplatte (6l, 62)angeordnete Pr\u00fcfeinrichtungsAnschlusspunkte (8) durch in eine darunterliegendeLeiterplatte (62,63) eingebrachte Durchbr\u00fcche (lOL) direkt kontaktierbar sind, undauf der ersten Seite (U) der darunterliegenden Leiterplatte (62, 63) angeordneteTestnadelAnschlusspunkte (7) durch in die dar\u00fcberliegende Leiterplatte (61, 62)eingebrachte Durchbr\u00fcche (10U) direkt kontaktierbar sind.3. Testadaptersystem nach Anspruch 1,dadurch gekennzeichnet,dass die Durchbr\u00fcche (10U, 10L) als in die Leiterplatten (6l, 62,63) eingebrachteL\u00f6cher ausgef\u00fchrt sind.4. Testadaptersystem nach Anspruch 1 oder 2dadurch gekennzeichnet,dass die \u00fcbereinander angeordneten Leiterplatten (61, 62, 63) miteinander verklebtsind.5. Testadaptersystem nach Anspruch 3,dadurch gekennzeichnet,dass die \u00fcbereinander angeordneten Leiterplatten (61, 62, 63) durch eine vorgebohrteKlebefolie miteinander verklebt sind.6. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die \u00fcbereinander angeordneten Leiterplatten (6,, 62, 63) miteinander verstiftetsind.7. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die TestnadelAnschlusspunkte (7) und die Pr\u00fcfeinrichtungsAnschlusspunkte (8) vergoldete Kontaktfl\u00e4chen aufweisen.8. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass zwischen den \u00fcbereinander angeordneten Leiterplatten (61, 62, 63) eineIsolierschicht (12) vorgesehen ist.9. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die TestnadelAnschlusspunkte (7) elektrisch leitende Elemente (14) aufweisen,die mit ihrem einen Ende mit der Verbindungsstruktur (9) einerLeiterplatte (61, 62, 63) verbunden sind, und an ihrem freien Ende die TestnadelAnschlusspunkte (7) bilden, wobei die elektrisch leitenden Elemente (14) durch diein die wenigstens eine andere Leiterplatte (6\"62, 63) eingebrachtenDurchbr\u00fcche (10U, 10L) hindurchgef\u00fchrt und gegen die auf der wenigstens einenanderen Leiterplatte (61, 62, 63) befindliche Verbindungsstruktur (9) isoliert sind.10. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die Pr\u00fcfeinrichtungsAnschlusspunkte (8) elektrisch leitende Elemente (14)aufweisen, die mit ihrem einen Ende mit der Verbindungsstruktur (9) einerLeiterplatte (61, 62, 63) verbunden sind, und an ihrem freien Ende diePr\u00fcfeinrichtungsAnschlusspunkte (8) bilden, wobei die elektrisch leitendenElemente (14) durch die in die wenigstens eine andere Leiterplatte (6\"62, 63)eingebrachten Durchbr\u00fcche (10U, 10L) hindurchgef\u00fchrt und gegen die auf derwenigstens einen anderen Leiterplatte (61, 62, 63) befindliche Verbindungsstruktur (9)isoliert sind.11. Testadaptersystem nach Anspruch 8 oder 9,dadurch gekennzeichnet,dass die elektrisch leitendenden Elemente (14) Stifte sind.12. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die \u00fcbereinander angeordneten Leiterplatten (61, 62, 63) so in demTestadaptersystem angeordnet sind, dass eine Leiterplatte (61, 62, 63) aufNadelh\u00fclsen (15) der Testnadeln (4) aufliegt.13. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass auf wenigstens einer der \u00fcbereinander angeordneten Leiterplatten (6l)elektrische Bauteile (13) angeordnet sind.14. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die TestnadelAnschlusspunkte (7) einer jeden Leiterplatte (61, 62, 63) \u00fcberDurchkontaktierungen (17) durch die jeweilige Leiterplatte (61, 62, 63) mit denPr\u00fcfeinrichtungsAnschlusspunkten (8) der selben Leiterplatte (61, 62, 63) verbundensind.15. Testadaptersystem nach einem der vorangegangenen Anspr\u00fcche,dadurch gekennzeichnet,dass die Pr\u00fcfeinrichtung (3) Kontaktteile (18) aufweist, die mit einem Ende mitgefederten Kontaktelementen (19) der Pr\u00fcfeinrichtung (3) in Anlage kommen, eineelektrische Verbindung zwischen Pr\u00fcfeinrichtungsAnschlusspunkten (8) derLeiterplatten (61, 62, 63) und den Kontaktelementen (19) der Pr\u00fcfeinrichtung (3)herstellen, und an ihren freien Enden einen geringeren Durchmesser aufweisen, alsdie Kontaktelemente (19) der Pr\u00fcfeinrichtung (3).16. Testadaptersystem nach Anspruch 14,dadurch gekennzeichnet,dass die Kontaktteile (18) jeweils einen Fu\u00df (20) und einen Stift (21) aufweisen,wobei der Fu\u00df (20) so ausgebildet ist, dass er auf die gefedertenKontaktelemente (19) der Pr\u00fcfeinrichtung (3) aufgelegt werden kann, und derStift (21) mit einem Ende an dem Fu\u00df (20) befestigt ist, und mit seinem freien Endezum Kontaktieren der Pr\u00fcfeinrichtungsAnschlusspunkte (8) ausgebildet ist.17. Testadaptersystem nach Anspruch 14 oder 15,dadurch gekennzeichnet,dass die Kontakteile (18) zum Ausgleich von Wegeunterschieden in derKontaktierung der Pr\u00fcfeinrichtungsAnschlusspunkte (8) unterschiedlicherLeiterplatten (61, 62, 63) unterschiedliche KontaktteilH\u00f6hen aufweisen.18. Testadaptersystem nach einem der Anspr\u00fcche 14,15 oder 16,dadurch gekennzeichnet,dass der Kontaktdurchmesser der Kontaktteile (18) an den Pr\u00fcfeinrichtungsAnschlusspunkten (8) der Leiterplatten (61, 62, 63) zwischen 0,6 mm und 0,2 mmbetr\u00e4gt.","Description":"\"Testadaptersystem zum Verbinden von Testnadeln eines Testadaptersmit einer Pr\u00fcfeinrichtung\"Die vorliegende Erfindung betrifft ein Testadaptersystem zum Verbinden von Testnadeln eines Testadapters mit einer Pr\u00fcfeinrichtung zum Testen einer insbesondere best\u00fcckten Leiterplatine. Testadaptersysteme werden insbesondere in der Serienfertigung von best\u00fcckten und unbest\u00fcckten Leiterplatinen in Verbindung mit automatischen Testsystemen eingesetzt. Sie dienen zur Kontaktierung von bis zu mehreren tausend auf einer zu pr\u00fcfenden Leiterplatine angeordneten Testpunkten mittels Testnadeln und erm\u00f6glichen so eine individuelle, schnell wechselbare elektrische Verbindung zwischen der zu pr\u00fcfenden Leiterplatine und einer Pr\u00fcfeinrichtung. Je nach Gr\u00f6\u00dfe der zu pr\u00fcfenden Leiterplatine und dem verwendeten Testverfahren werden mit einem Testadapter zwischen 200 bis ca. 5000 Kontaktpunkte gleichzeitig kontaktiert. Die Unterscheidung zwischen Testadaptersystemen f\u00fcr best\u00fcckte und unbest\u00fcckte Leiterplatinen ist dabei nicht unerheblich, da beim Pr\u00fcfen von unbest\u00fcckten Leiterplatinen lediglich einfache Leerlauf-und Kurzschlusstests von Interesse sind, und die Pr\u00fcfeinrichtung entsprechend einfach aufgebaut sein kann. Beim Pr\u00fcfen best\u00fcckter Leiterplatinen m\u00fcssen jedoch auch die jeweiligen Bauteilparameter erfasst werden, was hohe technische Anforderungen an die verwendete Pr\u00fcfeinrichtung stellt. Aus den vorgenannten Punkten verf\u00fcgen Pr\u00fcfeinrichtungen zum Pr\u00fcfen von unbest\u00fcckten Leiterplatinen \u00fcber eine erheblich gr\u00f6\u00dfere Zahl von Testkan\u00e4len und somit Anschl\u00fcssen f\u00fcr das Testadaptersystem als Pr\u00fcfeinrichtungen f\u00fcr best\u00fcckte Leiterplatinen. Da es sich insbesondere bei Pr\u00fcfeinrichtungen f\u00fcr best\u00fcckte Leiterplatinen um sehr teure Ger\u00e4te handelt (die Ger\u00e4te m\u00fcssen in der Lage sein, in k\u00fcrzester Zeit die Funktionsf\u00e4higkeit einer best\u00fcckten Leiterplatine zu beurteilen und somit die Bauteilcharakteristika einer Vielzahl von elektrischen Bauelementen zu messen), werden diese in der Regel als Universalger\u00e4t f\u00fcr beliebige best\u00fcckte Leiterplatinen und mit einer universellen Schnittstelle ausgeliefert. Diese Schnittstelle besteht i. d. R. aus einer Platte, die in einem Raster eine gewisse Anzahl von Pr\u00fcfeinrichtungs- Anschlusseinrichtungen (z. B. Kontaktfl\u00e4chen oder gefederte Kontakte) aufweist. Es ist naheliegend, dass die Anordnung der Pr\u00fcfeinrichtungs-Anschlusseinrichtungen in den seltensten F\u00e4llen geeignet ist, direkt \u00fcber eine Testnadel mit Testpunkten einer zu testenden Leiterplatine verbunden zu werden. Hierf\u00fcr ist in der Regel eine Aufspreizung und Zuordnung der Testnadeln der einzelnen Testpunkte zu den Pr\u00fcfeinrichtungs- Anschlusseinrichtungen erforderlich. Im einfachsten Fall kann eine solche Aufspreizung und Zuordnung durch eine direkte Drahtverbindung zwischen der jeweiligen Testnadel und der jeweiligen Pr\u00fcfeinrichtungs-Anschlusseinrichtung erfolgen. Da Testadaptersysteme in der Regel nur zum Testen einer bestimmten vorgegebenen Leiterplatine verwendet werden, werden Testadaptersysteme \u00fcblicherweise als individualisierte Einzelst\u00fccke hergestellt. Ein typisches Testadaptersystem zum Testen von best\u00fcckten Leiterplatinen ist in der DE 199 07 727 gezeigt und wird in Figur 4 n\u00e4her erl\u00e4utert : In Figur 4 bezeichnet das Bezugszeichen 41 eine Nadeltr\u00e4gerplatte, in der Testnadeln 43 zum Kontakt von Kolben 44 der Testnadeln mit Testpunkten 45 einer zu pr\u00fcfenden Leiterplatine 46 angeordnet sind. Dazu sind in die Nadeltr\u00e4gerplatte 41 Bohrungen eingebracht, wobei der Bohrdurchmesser jeweils in etwa dem Durchmesser der zugeordneten Testnadel 43 entspricht. Wahlweise k\u00f6nnen die Testnadeln 43 dabei in den Bohrungen befindlichen H\u00fclsen 49 gelagert sein. Die zu pr\u00fcfende Leiterplatine 46 wird von einer Leiterplatinentr\u00e4gerplatte 42 getragen. Die Leiterplatinentr\u00e4gerplatte 42 weist Bohrungen 48 f\u00fcr die Testnadeln 43 auf und ist so angeordnet, dass sich die Kolben 44 der Testnadeln 43 im in Figur 4 gezeigten Bereitschaftszustand nicht \u00fcber die der zu pr\u00fcfenden Leiterplatine 46 zugewandten Oberfl\u00e4che der Leiterplatinentr\u00e4gerplatte 42 hinaus erstrecken, so dass die Kolben 44 der Testnadeln 43 im Bereitschaftszustand gesch\u00fctzt sind. Zum Durchf\u00fchren einer Messung wird die Leiterplatinentr\u00e4gerplatte 42 und mit dieser die Leiterplatine 46 durch eine Pneumatik oder aufgrund eines im Zwischenraum zwischen Leiterplatinentr\u00e4gerplatte 42 und Nadeltr\u00e4gerplatte 41 erzeugten Vakuums abgesenkt, so dass die Kolben 44 der Testnadeln 43 mit den Testpunkten 45 der zu pr\u00fcfenden Leiterplatine 46 in Kontakt kommen. Zum Anschluss einer nicht dargestellten Pr\u00fcfeinrichtung, die die Auswertung der mit Hilfe der Testnadeln 43 gemessenen Gr\u00f6\u00dfen vornimmt, sind an dem der zu pr\u00fcfenden Leiterplatine 46 abgewandten Ende der Testnadeln 43 Testnadel- Anschlusseinrichtungen 40 vorgesehen, die elektrisch mit nicht dargestellten Pr\u00fcfeinrichtungs-Anschlusseinrichtungen verbindbar sind. Die Testnadel-Anschlusseinrichtungen 40 sind in Figur 4 durch gefederte Kontakte realisiert. Alternativ ist jedoch auch beispielsweise die Verwendung von\"Wire-Wrap\"- Pfosten, oder Steckkontakten bekannt. Aufgrund der oben erw\u00e4hnten gro\u00dfen Zahl an Testpunkten und entsprechend gro\u00dfen Zahl an erforderlichen Verbindungen zwischen Testnadel-Anschlusseinrichtungen und Pr\u00fcfeinrichtungs-Anschlusseinrichtungen sind derartige direkte Drahtverbindungen aufgrund der mangelnden \u00dcbersichtlichkeit und des hohen erforderlichen manuellen Arbeitsaufwandes in der Praxis jedoch kaum mehr zu realisieren. Das Problem, Verbindungen zwischen Testnadel-Anschlusseinrichtungen und Pr\u00fcfeinrichtungs-Anschlusseinrichtungen zu schaffen, wird durch die steigende Miniaturisierung von elektrischen Bauelementen weiter versch\u00e4rft, da die Testpunkte auf den zu pr\u00fcfenden Leiterplatinen immer dichter zusammenr\u00fccken. War vor einigen Jahren noch ein Mindestabstand der Testpunkte von 0,1 inch (2, 54 mm) gebr\u00e4uchlich, so sind die zu pr\u00fcfenden Testpunkte heute zunehmend nur mehr 0,025 inch (0,635 mm) oder noch weniger beabstandet. Dabei ist zu beachten, dass die Verteilung der Testpunkte \u00fcber die Leiterplatine nicht konstant ist, sondern sich in der Regel Bereiche mit eng beieinander liegenden Testpunkten und Bereiche mit weiter voneinander beabstandeten Testpunkten abwechseln. Dies liegt in der Natur der Bauelemente, mit denen die zu pr\u00fcfende Leiterplatine best\u00fcckt ist bzw. noch best\u00fcckt wird. Zur L\u00f6sung des Problems, unter Vermeidung einer Vielzahl von einzelnen Drahtverbindungen elektrische Verbindungen zwischen Testnadel- Anschlusseinrichtungen und Pr\u00fcfeinrichtungs-Anschlusseinrichtungen zu schaffen, sind zwei grunds\u00e4tzliche L\u00f6sungsans\u00e4tze bekannt : Zum einen ist es bekannt, die Testnadeln nicht immer senkrecht zu der Pr\u00fcfeinrichtung und der zu pr\u00fcfenden Leiterplatine auszurichten, sondern einzelne Testnadeln im Bedarfsfall schr\u00e4g zu stellen, so dass \u00fcber die schr\u00e4ggestellten Testnadeln elektrische Verbindungen von Testpunkten zu nicht senkrecht darunter befindlichen Pr\u00fcfeinrichtungs-Anschlusseinrichtungen m\u00f6glich sind. Nachteilig an diesem bekannten Verfahren ist, dass es ein erhebliches Know-how erfordert, und der Arbeitsaufwand zur Herstellung eines entsprechenden Testadaptersystems hoch ist. Weiter kann auch mit dieser bekannten L\u00f6sung nicht sichergestellt werden, dass das Problem, drahtlose elektrische Verbindungen zwischen Testnadel-Anschlusseinrichtungen und Pr\u00fcfeinrichtungs-Anschlusseinrichtungen zu schaffen, vollst\u00e4ndig gel\u00f6st wird, da sich die schr\u00e4ggestellten Testnadeln zum einen nicht ber\u00fchren d\u00fcrfen, und die Schr\u00e4gstellung der Testnadeln zum anderen ein gewisses Ma\u00df an Neigung nicht \u00fcberschreiten darf. Weiter ist es bekannt, zwischen den Testnadel-Anschlusseinrichtungen und den Pr\u00fcfeinrichtungs-Anschlusseinrichtungen eine Multilayer-Platine vorzusehen, die eine Verbindungsstruktur aufweist, die es erlaubt, elektrische Verbindungen zwischen Testnadel-Anschlusseinrichtungen und Pr\u00fcfeinrichtungs-Anschlusseinrichtungen zu schaffen. Unter dem Begriff einer\"Multilayer-Platine\"wird eine Vielzahl (mindestens zwei) von miteinander verklebten und verpressten zweiseitigen Platinen verstanden. Die einzelnen zweiseitigen Platinen k\u00f6nnen dabei f\u00fcr sich jeweils Durchkontaktierungen aufweisen. Zwischen den einzelnen Platinen ist jeweils eine Isolationsschicht vorgesehen, die in eine Klebeschicht integriert sein kann. Um eine elektrische Verbindung zwischen der zug\u00e4nglichen Au\u00dfenseite der Multilayer-Platine und der auf den einzelnen Platinen befindlichen Verbindungsstruktur zu schaffen, bzw. um die Verbindungsstrukturen der einzelnen Platinen miteinander elektrisch zu verbinden, weisen Multilayer-Platinen Bohrungen auf, die metallisch beschichtet werden, um eine Durchkontaktierung zu schaffen. Da die Multilayer-Platine mit den einzelnen Platinen und den jeweils dazwischen befindlichen Klebeschichten und/oder Isolationsschichten insgesamt ein inhomogenes Gef\u00fcge bildet, ist es n\u00f6tig, die Platinen unter gro\u00dfer Hitze (\u00fcblich sind zwischen 160\u00b0 Celsius und 180\u00b0 Celsius) und hohem Druck miteinander zu verpressen, da bereits geringste Relativbewegungen der Platinen untereinander die Durchkontaktierungen unterbrechen w\u00fcrden. Weil das f\u00fcr die Herstellung hochwertiger Platinen \u00fcblicherweise verwendete Glasfaser-Tr\u00e4germaterial ab 130\u00b0 Celsius bleibend thermisch verformbar ist, und bei h\u00f6heren Temperaturen zudem zum Schrumpfen neigt, m\u00fcssen die einzelnen Platinen vor dem Verpressen zu einer Multilayer-Platine ein \u00dcberma\u00df aufweisen. Da der Schrumpfprozess aufgrund der auf den einzelnen Platinen aufgebrachten Verbindungsstruktur und ggf. in die Platinen eingebrachten L\u00f6cher jedoch nicht \u00fcber die Fl\u00e4che der einzelnen Platinen konstant ist, und es zudem nur schwer m\u00f6glich ist, die \u00fcbereinander angeordneten Platinen beim Verpressen gleichm\u00e4\u00dfig zu erw\u00e4rmen, weisen Multilayer-Platinen immer ein erhebliches Ma\u00df an geometrischer Ungenauigkeit auf. Da die einzelnen Platinen der Multilayer-Platine vor dem Verkleben und Verpressen der einzelnen Platinen zu einer Multilayer-Platine und dem Einbringen von Durchkontaktierungen durch die Multilayer-Platine keine echten Kontaktstellen aufweisen, ist es nur mit sehr hohem Aufwand m\u00f6glich, die einzelnen Platinen vor dem Verkleben und Verpressen auf ihre Funktionsf\u00e4higkeit zu testen. Auch nach dem Verkleben und Verpressen kann nur die Multilayer-Platine insgesamt und k\u00f6nnen nicht die einzelnen Platinen auf seine/ihre Funktionsf\u00e4higkeit getestet werden,so dass Fehler auf einzelnen Platinen kaum lokalisiert und behoben werden k\u00f6nnen.Aufgrund dieser Probleme wird in der Praxis bei der Herstellung einzelner,individueller Multilayer-Platinen, wie es f\u00fcr den Testadapterbau aufgrund der individuellen Ausgestaltung des Testadapters erforderlich ist, zumeist ein \u00dcberschuss (\u00fcblich ist der Faktor 3) an Multilayer-Platinen produziert, wobei die fehlerhaften Multilayer-Platinen durch Tests aus der Gesamtheit der hergestellten Multilayer- Platinen aussortiert werden. Aufgrund der obengenannten Probleme ist die Herstellung von Multilayer-Platinen sehr kosten-und zeitaufwendig. Ausgehend hiervon ist es Aufgabe der vorliegenden Erfindung, ein Testadaptersystem zum Verbinden von Testnadeln eines Testadapters mit einer Pr\u00fcfeinrichtung zum Testen einer insbesondere best\u00fcckten Leiterplatine zur Verf\u00fcgung zu stellen, das auf einfache, robuste und kosteng\u00fcnstige Weise eine elektrische Verbindung zwischen den Testnadeln und der Pr\u00fcfeinrichtung erm\u00f6glicht.. Die Aufgabe wird gem\u00e4\u00df dem unabh\u00e4ngigen Anspruch 1 gel\u00f6st. Die Erfindung wird in ihren Unteranspr\u00fcchen weitergebildet. Erfindungsgem\u00e4\u00df wird ein Testadaptersystem zum Verbinden von Testnadeln eines Testadapters mit einer Pr\u00fcfeinrichtung zum Testen einer insbesondere best\u00fcckten Leiterplatine offenbart, aufweisend wenigstens zwei \u00fcbereinander angeordnete doppelseitige Leiterplatten, wobei die Leiterplatten jeweils auf einer ersten Seite Testnadel-Anschlusspunkte f\u00fcr Testnadeln des Testadapters und auf einer der ersten Seite abgewandten zweiten Seite Pr\u00fcfeinrichtungs-Anschlusspunkte f\u00fcr die Pr\u00fcfeinrichtung aufweisen, die Testnadel-Anschlusspunkte einer jeden Leiterplatte \u00fcber eine Verbindungsstruktur, mit Pr\u00fcfeinrichtungs-Anschlusspunkten der selben Leiterplatte verbunden sind, und die Leiterplatten so \u00fcbereinander angeordnet sind, dass die zweite Seite einer Leiterplatte mit den darauf angeordneten Pr\u00fcfeinrichtungs-Anschlusspunkten und die erste Seite der darunterliegenden benachbarten Leiterplatte mit den darauf angeordneten Testnadel-Anschlusspunkten einander zugewandt sind, wobei die Leiterplatten ferner Durchbr\u00fcche aufweisen, die so angeordnet sind, dass auf der zweiten Seite einer Leiterplatte angeordnete Pr\u00fcfeinrichtungs-Anschlusspunkte durch in eine darunterliegende Leiterplatte eingebrachte Durchbr\u00fcche direkt kontaktierbar sind, und auf der ersten Seite der darunterliegenden Leiterplatte angeordnete Testnadel- Anschlusspunkte durch in die dar\u00fcberliegende Leiterplatte eingebrachte Durchbr\u00fcche direkt kontaktierbar sind. Somit ist es mit dem erfindungsgem\u00e4\u00dfen Testadaptersystem m\u00f6glich, innenliegenden Testnadel-Anschlusspunkte bzw. Pr\u00fcfeinrichtungs-Anschlusspunkte von \u00fcbereinander angeordneten Leiterplatten direkt zu kontaktieren, so dass auf die bei Multilayer- Platinen erforderlichen Durchkontaktierung durch ein inhomogenes Gef\u00fcge verzichtet werden kann. Durch das Vorsehen von \u00fcbereinander angeordneten doppelseitigen Leiterplatten wird eine Vielzahl von Verbindungsebenen bereitgestellt, die ein hohes Ma\u00df an Flexibilit\u00e4t bei der Erstellung der Verbindungsstruktur zwischen den Testnadeln des Testadapters und Anschlusseinrichtungen der Pr\u00fcfeinrichtung erlauben. Da die \u00fcbereinander angeordneten Leiterplatten im Gegensatz zu einer Multilayer- Platine bei der Herstellung des erfindungsgem\u00e4\u00dfen Testadaptersystems nicht durch Verpressen unter Hitze oder ein L\u00f6tbad thermisch beansprucht werden m\u00fcssen, l\u00e4sst sich das Testadaptersystem geometrisch sehr ma\u00dfhaltig und genau herstellen. Weiter ist es \u00fcber die Testnadel-Anschlusspunkte und Pr\u00fcfeinrichtungs-Anschlusspunkte sehr einfach m\u00f6glich, die einzelnen \u00fcbereinander angeordneten doppelseitigen Leiterplatten einzeln zu testen und ggf. einzelne defekte Leiterplatten auszutauschen oder zu reparieren. Somit kann das erfindungsgem\u00e4\u00dfe Testadaptersystem auch auf einfache Weise an Modifikationen der zu pr\u00fcfenden Leiterplatine angepasst werden. Weiter ist es besonders vorteilhaft, dass das erfindungsgem\u00e4\u00df vorgeschlagene Testadaptersystem mit den im Testadapterbau vorhandenen Maschinen (z. B. Bohreinrichtungen etc. ) und den kosteng\u00fcnstigen und genauen Fertigungstechniken zur Herstellung doppelseitiger Leiterplatten hergestellt werden kann. Somit kann die Herstellung des Testadaptersystems ohne Hilfe eines auf die Herstellung von Multilayer-Platinen spezialisierten Betriebes in einem auf den Testadapterbau ausgerichteten Betrieb erfolgen, wodurch die Wertsch\u00f6pfung im Testadapterbau erh\u00f6ht werden kann. Vorzugsweise sind die Durchbr\u00fcche als in die Leiterplatten eingebrachte L\u00f6cher ausgef\u00fchrt, da derartige Durchbr\u00fcche mit den im Testadapterbau allgemein verwendeten automatisierten und hochpr\u00e4zisen Bohrsystemen leicht erstellt werden k\u00f6nnen. Da die einzelnen \u00fcbereinander angeordneten Leiterplatten vorzugsweise jeweils nur eine geringe Dicke aufweisen, um ein Verlaufen des Bohrers zu verhindern, kann es zu Erh\u00f6hungen der Gesamtstabilit\u00e4t der \u00fcbereinander angeordneten doppelseitigen Leiterplatten vorteilhaft sein, wenn die Leiterplatten miteinander verklebt sind. Dies kann besonders einfach und zuverl\u00e4ssig \u00fcber eine vorgebohrte Klebefolie erfolgen. Ein weiterer Vorteil miteinander verklebter Leiterplatten ist darin zu sehen, dass das Eindringen von Schmutz zwischen die Leiterplatten so wirkungsvoll verhindert wird. Um die Flexibilit\u00e4t der Anlage im Hinblick auf eine Behebung von Fehlern einzelner Leiterplatten und die Anpassungsf\u00e4higkeit an Modifikationen der zu pr\u00fcfenden Leiterplatine zu erhalten, ist es jedoch alternativ sehr vorteilhaft, wenn die \u00fcbereinander angeordneten Leiterplatten miteinander verstiftet sind. Weiter ist es vorteilhaft, wenn die Testnadel-Anschlusspunkte und die Pr\u00fcfeinrichtungs- Anschlusspunkte vergoldete Kontaktfl\u00e4chen aufweisen, da so ein zuverl\u00e4ssiger elektrischer Kontakt zwischen den Testnadeln und den Testnadel-Anschlusspunkten bzw. den Pr\u00fcfeinrichtungs-Anschlusspunkten und Anschlusseinrichtungen der Pr\u00fcfeinrichtung gew\u00e4hrleistet werden kann. Zur Vermeidung von unerw\u00fcnschten elektrischen Verbindungen zwischen den Verbindungsstrukturen der einzelnen \u00fcbereinander angeordneten Leiterplatten ist gem\u00e4\u00df einer bevorzugten Ausf\u00fchrungsform der vorliegenden Erfindung zwischen den \u00fcbereinander angeordneten Leiterplatten eine Isolierschicht vorgesehen. Eine entsprechend ausgebildete Isolierschicht kann auch geeignet sein, das Eindringen von Fremdk\u00f6rpern zwischen \u00fcbereinander angeordneten Leiterplatten zu verhindern. Gem\u00e4\u00df einer alternativen Ausf\u00fchrungsform weisen die Testnadel-Anschlusspunkte elektrisch leitende Elemente auf, die mit ihrem einen Ende mit der Verbindungsstruktur einer Leiterplatte verbunden sind, und an ihrem freien Ende die Testnadel- Anschlusspunkte bilden, wobei die elektrisch leitenden Elemente durch die in die wenigstens eine andere Leiterplatte eingebrachten Durchbr\u00fcche hindurchgef\u00fchrt und gegen die auf der wenigstens einen anderen Leiterplatte befindliche Verbindungsstruktur isoliert sind. Entsprechend k\u00f6nnen auch die Pr\u00fcfeinrichtungs-Anschlusspunkte elektrisch leitende Elemente aufweisen, die mit ihrem einen Ende mit der Verbindungsstruktur einer Leiterplatte verbunden sind, und an ihrem freien Ende die Pr\u00fcfeinrichtungs-Anschlusspunkte bilden, wobei die elektrisch leitenden Elemente durch die in die wenigstens eine andere Leiterplatte eingebrachten Durchbr\u00fcche hindurchgef\u00fchrt und gegen die auf der wenigstens einen anderen Leiterplatte befindliche Verbindungsstruktur isoliert sind. Hierdurch ist es m\u00f6glich, innenliegende Pr\u00fcfeinrichtungs-Anschlusspunkte bzw. Testnadel-Anschlusspunkte durch au\u00dfenliegende Leiterplatten hindurch nach au\u00dfen zu f\u00fchren. Bei diesen elektrisch leitenden Elementen kann es sich im einfachsten Fall um Stifte handeln. Zur Erh\u00f6hung der Stabilit\u00e4t der \u00fcbereinander angeordneten Leiterplatten ist es von Vorteil, wenn die \u00fcbereinander angeordneten Leiterplatten so in dem erfindungsgem\u00e4\u00dfen Testadaptersystem angeordnet sind, dass eine Leiterplatte auf Nadelh\u00fclsen der Testnadeln aufliegt. Hierdurch ist es m\u00f6glich, die r\u00e4umliche Lage der \u00fcbereinander angeordneten Leiterplatten mittels einer Vielzahl von Nadelh\u00fclsen \u00fcber die ganze Fl\u00e4che des Testadapters zu definieren und stabilisieren. Sollen von dem Testadaptersystem zus\u00e4tzliche Versorgungseinrichtungen oder Hilfseinrichtungen bereitgestellt werden, so k\u00f6nnen auf wenigstens einer der \u00fcbereinander angeordneten Leiterplatten elektrische Bauteile angeordnet sein. Innerhalb einer jeden Leiterplatte sind die Testnadel-Anschlusspunkte vorzugsweise \u00fcber Durchkontaktierungen durch die jeweilige Leiterplatte mit den Pr\u00fcfeinrichtungs- Anschlusspunkten der selben Leiterplatte verbunden, da dies bei zweiseitigen Platinen auf besonders einfache und zuverl\u00e4ssige Weise mit einfachen Mitteln m\u00f6glich ist. Weiter ist es besonders vorteilhaft, wenn die Pr\u00fcfeinrichtung Kontaktteile aufweist, die mit einem Ende mit gefederten Kontaktelementen der Pr\u00fcfeinrichtung in Anlage kommen, eine elektrische Verbindung zwischen Pr\u00fcfeinrichtungs-Anschlusspunkten der Leiterplatten und den Kontaktelementen der Pr\u00fcfeinrichtung herstellen, und an ihren freien Enden einen geringeren Durchmesser aufweisen, als die Kontaktelemente der Pr\u00fcfeinrichtung. Hierdurch ist es m\u00f6glich, die f\u00fcr gefederte Kontaktelemente der Pr\u00fcfeinrichtung aufgrund von Toleranzen erforderlichen gro\u00dfen Kontaktfl\u00e4chen an den Pr\u00fcfeinrichtungs-Anschlusspunkten zu verkleinern, so dass die Pr\u00fcfeinrichtungs- Anschlusspunkte relativ klein ausgef\u00fchrt werden k\u00f6nnen. In der Folge kann zwischen benachbarten Pr\u00fcfeinrichtungs-Anschlusspunkten der Leiterplatten eine gr\u00f6\u00dfere Anzahl von Leitungen der Verbindungsstruktur angeordnet werden, wodurch die auf den Leiterplatten zur Verf\u00fcgung stehenden Fl\u00e4chen besser genutzt werden k\u00f6nnen. Gem\u00e4\u00df einer bevorzugten Ausf\u00fchrungsform weisen die Kontaktteile jeweils einen Fu\u00df und einen Stift auf, wobei der Fu\u00df so ausgebildet ist, dass er auf die gefederten Kontaktelemente der Pr\u00fcfeinrichtung aufgelegt werden kann, und der Stift mit einem Ende an dem Fu\u00df befestigt ist, und mit seinem freien Ende zum Kontaktieren der Pr\u00fcfeinrichtungs-Anschlusspunkte ausgebildet ist. Derartige Kontaktteile sind in ihrer Herstellung sehr kosteng\u00fcnstig, und k\u00f6nnen einfach durch Auflegen mit gefederten Kontaktelementen der Pr\u00fcfeinrichtung in Anlage kommen. Wenn der Federweg der gefederten Kontaktelemente der Pr\u00fcfeinrichtung dem Ausgleich von Wegeunterschieden bei der Kontaktierung der Pr\u00fcfeinrichtungs-Anschlusspunkte unterschiedlicher \u00fcbereinander angeordneter Leiterplatten nicht ausreicht, ist es vorteilhaft, wenn die Kontaktteile zum Ausgleich von Wegeunterschieden in der Kontaktierung der Pr\u00fcfeinrichtungs-Anschlusspunkte unterschiedliche Kontaktteil- H\u00f6hen aufweisen. Vorzugsweise betr\u00e4gt der Kontaktdurchmesser der Kontaktteile an den Pr\u00fcfeinrichtungs- Anschlusspunkten der Leiterplatten zwischen 0,6 mm und 0,2 mm Im Folgenden wird die vorliegende Erfindung anhand von Zeichnungen n\u00e4her erl\u00e4utert. Dabei zeigtFigur 1 schematisch eine erste bevorzugte Ausf\u00fchrungsformdes erfindungsgem\u00e4\u00dfen Testadaptersystems,Figur 2 schematisch einen vergr\u00f6\u00dferten Ausschnitt einerzweiten bevorzugten Ausf\u00fchrungsform deserfindungsgem\u00e4\u00dfen Testadaptersystems,Figur 3 schematisch einen vergr\u00f6\u00dferten Ausschnitt eineralternativen dritten Ausf\u00fchrungsform des erfindungs-gem\u00e4\u00dfen Testadaptersystems, undFigur 4 ein Testadaptersystem zum Testen von best\u00fccktenLeiterplatinen nach dem Stand der Technik. In den Figuren 1, 2 und 3 sind gleiche Elemente mit den gleichen Bezugszeichen versehen. Die in Figur 1 dargestellte erste bevorzugte Ausf\u00fchrungsform eines erfindungsgem\u00e4\u00dfen Testadaptersystems 1 zum Verbinden von Testnadeln 4 eines Testadapters 2 mit einer Pr\u00fcfeinrichtung 3 zum Testen einer insbesondere best\u00fcckten Leiterplatine 5 weist drei \u00fcbereinander angeordnete doppelseitige Leiterplatinen 61, 62, 63 auf. Auf der den Testnadeln 4 und somit der zu pr\u00fcfenden Leiterplatine 5 zugewandten Seite U der Leiterplatten 61, 62, 63 sind jeweils Testnadel-Anschlusspunkte 7 f\u00fcr Testnadeln 4 des Testadapters 2 angeordnet. Auf der den Testnadeln 4 und somit der zu pr\u00fcfenden Leiterplatine 5 abgewandten Seite L der doppelseitigen Leiterplatten 61, 62, 63 sind jeweils Pr\u00fcfeinrichtungs-Anschlusspunkte 8 f\u00fcr die Pr\u00fcfeinrichtung 3 vorgesehen. Somit sind die Leiterplatten 61, 62, 63 so \u00fcbereinander angeordnet, dass die der zu pr\u00fcfenden Leiterplatine 5 abgewandte Seite L der Leiterplatten 61 bzw. 62 mit den darauf angeordneten Pr\u00fcfeinrichtungs-Anschlusspunkten 8 und die der zu pr\u00fcfenden Leiterplatine 5 zugewandte Seite U der darunterliegenden benachbarten Leiterplatten 62 bzw. 63 mit den darauf angeordneten Testnadel-Anschlusspunkten 7 einander zugewandt sind. Wie in Verbindung mit der Figur 2 nachstehend n\u00e4her erl\u00e4utert wird, sind die Testnadel-Anschlusspunkte 7 einer jeden Leiterplatte 61, 62, 63 \u00fcber eine in Figur 1 nicht gezeigte Verbindungsstruktur 9 mit den Pr\u00fcfeinrichtungs-Anschlusspunkten 8 der selben Leiterplatte 61, 62, 63 verbunden. Damit die auf der der zu pr\u00fcfenden Leiterplatine 5 abgewandten Seite L der Leiterplatten 61, 62 angeordneten Pr\u00fcfeinrichtungs-Anschlusspunkte 8 durch darunterliegende Leiterplatten 62, 63 bzw. die auf der der zu pr\u00fcfenden Leiterplatine 5 zugewandten Seite U der Leiterplatten 62, 63 angeordneten Testnadel-Anschlusspunkte 7 durch dar\u00fcberliegende Leiterplatten 61, 62 hindurch direkt kontaktierbar sind, weisen die Leiterplatten 61, 62,63 entsprechend angeordnete und dimensionierte Durchbr\u00fcche 10U, 10L auf. In den in Figuren 1 und 2 gezeigten bevorzugten Ausf\u00fchrungsformen kontaktieren die Testnadeln 4 die Testnadel-Anschlusspunkte 7 der Leiterplatten 6,, 62, 63 nicht direkt, sondern \u00fcber gefederte Kontakte 22. Hierf\u00fcr sind die Testnadeln 4 in Nadelh\u00fclsen 15 angeordnet. Alternativ k\u00f6nnen die gefederten Kontakte aber auch direkt an den Testnadeln ausgebildet sein. Die Kontaktierung der Testnadel-Anschlusspunkte durch die Testnadeln kann alternativ auch v\u00f6llig ohne gefederte Kontakte erfolgen. Die elektrische Verbindung mit der Pr\u00fcfeinrichtung 3 erfolgt in den in Figuren 1 und 2 dargestellten Ausf\u00fchrungsbeispielen \u00fcber gefederte Kontaktelemente 19. Es ist offensichtlich, dass in Figur 1 nicht die ganze Pr\u00fcfeinrichtung 3, sondern nur die gefederten Kontaktelemente 19 der Pr\u00fcfeinrichtung 3 dargestellt sind. Somit ist es mit dem erfindungsgem\u00e4\u00dfen Testadaptersystem 1 m\u00f6glich, innenliegenden Testnadel-Anschlusspunkte 7 bzw. Pr\u00fcfeinrichtungs-Anschlusspunkte 8 von \u00fcbereinander angeordneten Leiterplatten 61, 62, 63 direkt zu kontaktieren und so eine elektrische Verbindung zwischen den Testnadeln 4 und der Pr\u00fcfeinrichtung 3 bereitzustellen. Das erfindungsgem\u00e4\u00dfe Testadaptersystem 1 l\u00e4sst sich auf einfache und kosteng\u00fcnstige Weise mit den im Pr\u00fcfadapterbau und den in der Herstellung doppelseitiger Leiterplatten bekannten Vorrichtungen und Verfahren herstellen, und ist \u00e4u\u00dferst robust, da es im Gegensatz zu Multilayer-Platinen auf problematische Durchkontaktierungen (elektrische Verbindungen) zwischen den einzelnen Leiterplatten 61, 62, 63 und somit durch ein inhomogenes Gef\u00fcge verzichtet. Da die Leiterplatten 61, 62,63 bei der Herstellung des erfindungsgem\u00e4\u00dfen Testadaptersystems thermisch nicht beansprucht werden m\u00fcssen, ist das vorgeschlagene Testadaptersystem ferner geometrisch sehr ma\u00dfhaltig. Um eine zuverl\u00e4ssige elektrische Verbindung zwischen den gefederten Kontakten 22 der Testnadeln 4 und den Testnadel-Anschlusspunkten 7 bzw. den gefederten Kontaktelementen 19 der Pr\u00fcfeinrichtung 3 und den Pr\u00fcfeinrichtungs- Anschlusspunkten 8 sicherzustellen, sind die Testnadel-Anschlusspunkte 7 und die Pr\u00fcfeinrichtungs-Anschlusspunkte 8 gem\u00e4\u00df. der beschriebenen ersten bevorzugten Ausf\u00fchrungsform vergoldet. In dem in Figur 1 gezeigten Beispiel sind die \u00fcbereinander angeordneten doppelseitigen Leiterplatten 61, 62, 63 \u00fcber einen Stift 11 gegeneinander verstiftet, so dass es m\u00f6glich ist, die einzelnen doppelseitigen Leiterplatten 61, 62, 63 bei Bedarf voneinander zu trennen um beispielsweise einzelne Leiterplatten auszutauschen oder zu reparieren. Anstelle von durch Verstiften k\u00f6nnen die einzelnen Leiterplatten aber auch beispielsweise durch Verschrauben o. \u00e4. l\u00f6sbar gegeneinander fixiert werden. Bei sehr d\u00fcnnen Leiterplatten kann es weiter vorteilhaft sein, zus\u00e4tzlich eine in den Figuren nicht gezeigte Stabilisatorplatte zur Stabilisierung der Leiterplatten vorzusehen. In einer nicht dargestellten alternativen Ausf\u00fchrungsform kann es zur Erh\u00f6hung der Gesamtstabilit\u00e4t der zum Vermeiden eines Verlaufens eines Bohrers beim Erstellen der Durchbr\u00fcche vorzugsweise sehr d\u00fcnnen Leiterplatten 61, 62, 63 jedoch auch vorteilhaft sein, die Leiterplatten6\"62, 63 miteinander beispielsweise \u00fcber eine vorgebohrte Klebefolie dauerhaft miteinander zu verkleben. Im Gegensatz zur Herstellung von Multilayer- Platinen braucht das Verkleben in diesem Fall nicht unter hohen Temperaturen und Dr\u00fccken zu erfolgen, da keine Durchkontaktierungen eingebracht werden m\u00fcssen. Wie in Figur 2 anhand eines vergr\u00f6\u00dferten Ausschnitts einer zweiten bevorzugten Ausf\u00fchrungsform des erfindungsgem\u00e4\u00dfen Testadaptersystems 1 gezeigt, sind die Testnadel-Anschlusspunkte 7 jeder Leiterplatte 61, 62, 63 \u00fcber eine Verbindungsstruktur 9, die im in Figur 2 gezeigten Beispiel durch auf den einzelnenLeiterplatten 61, 62, 63 vorgesehene Leiterbahnen gebildet wird, \u00fcber Durchkontaktierungen 17 mit Pr\u00fcfeinrichtungs-Anschlusspunkten 8 derselben Leiterplatte 6\"62, 63 verbunden. Wie in Figur 1 sind auch in Figur 2 die Leiterplatten 61, 62, 63 so \u00fcbereinander angeordnet, dass die den Testnadeln 4 abgewandten Seiten L der Leiterplatten 6l bzw. 62mit den darauf angeordneten Pr\u00fcfeinrichtungs-Anschlusspunkten 8 und die den Testnadeln 4 zugewandten Seiten U der darunter liegenden benachbarten Leiterplatinen 62 bzw. 63 mit den darauf angeordneten Testnadel-Anschlusspunkten 7 jeweils einander zugewandt sind. Die einzelnen Leiterplatten 61, 62, 63 weisen Durchbr\u00fcche 10U, 1OL in Form von (Bohr-) L\u00f6chern auf, die so angeordnet und ausgebildet sind, dass die auf der den Testnadeln 4 abgewandten Seiten L der Leiterplatten 61, 62 angeordneten Pr\u00fcfeinrichtungs-Anschlusspunkte 8 durch in die darunter liegenden Leiterplatten 62, 63 eingebrachte Durchbr\u00fcche 10 direkt kontaktierbar sind, und die auf der den Testnadeln 4 zugewandten Seite U der unteren Leiterplatten 62, 63 angeordneten Testnadel-Anschlusspunkte 7 durch in die dar\u00fcber liegenden Leiterplatten 61, 62 eingebrachte Durchbr\u00fcche 10U direkt kontaktierbar sind. In der in Figur 2 dargestellten zweiten Ausf\u00fchrungsform des erfindungsgem\u00e4\u00dfen Testadaptersystems 1 ist zudem zwischen den einzelnen \u00fcbereinander angeordneten Leiterplatten 61, 62, 63 jeweils eine Isolierschicht 12 vorgesehen. Bei dieser Isolierschicht kann es sich im einfachsten Fall um einen Lack handeln, mit dem die einzelnen doppelseitigen Leiterplatinen 61, 62, 63 beschichtet werden. Es kann jedoch auch eine vorgebohrte Isolationsfolie verwendet werden. Eine derartige Folie kann zudem das Eindringen von Fremdk\u00f6rpern zwischen den \u00fcbereinander angeordneten Leiterplatten 61, 62, 63 verhindern. Um Hilfsfunktionen (wie z. B. eine bestimmte Versorgungsspannung) bereitstellen zu k\u00f6nnen, sind auf der obersten Leiterplatte 6t ferner elektrische Bauteile 13 angeordnet. Es versteht sich von selbst, dass die elektrischen Bauteile 13 generell auf jeder beliebigen Leiterplatte 61, 62, 63 angeordnet sein k\u00f6nnen. Zur Erh\u00f6hung der Stabilit\u00e4t der \u00fcbereinander angeordneten Leiterplatten 6\"62, 63 liegt die der zu pr\u00fcfenden Leiterplatine 5 und somit den Testnadeln 4 am n\u00e4chstliegendsten angeordnete Leiterplatte 6, gem\u00e4\u00df der zweiten bevorzugten Ausf\u00fchrungsform mit ihrer der zu pr\u00fcfenden Leiterplatine 5 und somit den Testnadeln 4 zugewandten Seite U auf Nadelh\u00fclsen 15 der Testnadeln 4 auf. Somit wird die Gesamtheit der \u00fcbereinanderangeordneten Leiterplatten 61, 62, 63 \u00fcber die Leiterplatte 61 durch eine Vielzahl vonNadelh\u00fclsen 15 der Testnadeln 4 gehalten und stabilisiert.Um geringf\u00fcgigen Modifikationen der zu pr\u00fcfenden Leiterplatine 5 Rechnung tragen zuk\u00f6nnen, ist in dem in Figur 2 gezeigte Beispiel zus\u00e4tzlich eine \u00c4nderungsebenevorgesehen, in der eine direkte Verdrahtung 16 einzelner Testnadeln 4 \u00fcber diejeweiligen Nadelh\u00fclsen 15 m\u00f6glich ist.Da die gefederten Kontaktelemente 19 der in den Figuren 1 und 2 gezeigtenPr\u00fcfeinrichtung 3 Kontaktdurchmesser von beispielsweise 2 mm und entsprechendgro\u00dfe Durchbr\u00fcche l \u00d6L erforderlich machen, sind an den gefedertenKontaktelementen 19 der Pr\u00fcfeinrichtung 3 Kontaktteile 18 vorgesehen, die mit einemEnde mit den gefederten Kontaktelementen 19 der Pr\u00fcfeinrichtung 3 in Anlagekommen, eine elektrische Verbindung zwischen Pr\u00fcfeinrichtungs-Anschlusspunkten 8der Leiterplatten 61, 6\"63 und den Kontaktelementen 19 der Pr\u00fcfeinrichtung 3herstellen, und an ihren freien Enden einen geringeren Durchmesser aufweisen, als dieKontaktelemente 19 der Pr\u00fcfeinrichtung 3.Die Kontaktteile 18 weisen in dem gezeigten Beispiel jeweils einen Fu\u00df 20 und einenStift 21 auf, wobei der Fu\u00df 20 so ausgebildet ist, dass er auf ein gefedertesKontaktelement 19 der Pr\u00fcfeinrichtung 3 aufgelegt werden kann, und der Stift 21 mitseinem einen Ende an dem Fu\u00df 20 befestigt ist, und mit seinem freien anderen Endezum Kontaktieren der Pr\u00fcfeinrichtungs-Anschlusspunkte 8 ausgebildet ist. Hierdurch ist es m\u00f6glich, den erforderlichen Kontaktdurchmesser an den Pr\u00fcfeinrichtungs-Anschlusspunkten 8 auf zwischen 0,6 mm und 0,2 mm, vorzugsweise 0,4 mm zuverringern, so dass zwischen zwei benachbarten Pr\u00fcfeinrichtungs-Anschlusspunkten 8im vorliegenden Falle sieben zus\u00e4tzliche Leitungen der Verbindungsstruktur 9vorgesehen werden k\u00f6nnen.In der Figur 1 sind die F\u00fc\u00dfe 20 der Kontaktteile 18 in Bohrungen gef\u00fchrt, die in eine\u00fcber den Kontaktelementen 19 der Pr\u00fcfeinrichtung 3 angeordnete Platte eingebrachtsind. Alternativ k\u00f6nnen die Kontaktteile 18 jedoch auch beispielsweise durchAufstecken l\u00f6sbar mit den Kontaktelementen 19 der Pr\u00fcfeinrichtung 3 verbunden sein,so dass auf eine F\u00fchrung der Kontaktteile 18 verzichtet werden kann. In diesem Fallk\u00f6nnen die F\u00fc\u00dfe 20 der Kontaktteile 18 entsprechend, beispielsweise in Form einerH\u00fclse, die auf die Kontaktelemente 20 aufgesteckt werden kann, ausgebildet sein.Es ist zu beachten, dass auch die Durchbr\u00fcche 10 f\u00fcr die Stifte 21 der Kontaktteile 18verglichen mit den Durchbr\u00fcchen 1OL, die f\u00fcr die Kontaktelemente 19 erforderlichw\u00e4ren, entsprechend kleiner ausgef\u00fchrt werden k\u00f6nnen. Somit k\u00f6nnen im vorliegendenFall auch zwischen zwei benachbarten Durchbr\u00fcchen 10L f\u00fcr die Stifte 21 derKontaktteile 18 sieben zus\u00e4tzliche Leitungen der Verbindungsstruktur 9 vorgesehen werden. Somit ist es durch das Vorsehen der Kontaktteile 18 m\u00f6glich, die von den Leiterplatten 6l, 62, 63 bereitgestellten Fl\u00e4chen besser ausnutzen zu k\u00f6nnen, so dass nur eine m\u00f6glichst kleine Anzahl von \u00fcbereinander angeordneten Leiterplatten 6l, 62, 63 erforderlich ist. Wie aus den Figuren 1 und 2 au\u00dferdem deutlich wird, weisen die Stifte 21 der Kontaktteile 18 unterschiedliche L\u00e4ngen auf, so dass die Kontaktteile 18 zum Ausgleich von Wegeunterschieden in der Kontaktierung der Pr\u00fcfeinrichtungs-Anschlusspunkte 8 verschiedener Leiterplatten 61, 62, 63 unterschiedliche Kontaktteil-H\u00f6hen aufweisen. Dadurch ist es m\u00f6glich, auch auf Leiterplatten 6l, 62, 63 angeordnete Pr\u00fcfeinrichtungs- Anschlusspunkte 8 zu kontaktieren, die alleine aufgrund des Federweges der gefederten Kontaktelemente 19 der Pr\u00fcfeinrichtung 3 nicht mehr sicher kontaktierbar w\u00e4ren. Aufgrund der Federwege der gefederten Kontaktelemente 19 der Pr\u00fcfeinrichtung 3 ist es jedoch nicht erforderlich, f\u00fcr jede Leiterplatte 6l, 62, 63 Kontaktteile 18 mit unterschiedlichen Kontaktteil-H\u00f6hen vorzusehen, so dass in Figur 1 Pr\u00fcfeinrichtungs- Anschlusspunkte 8 auf zwei \u00fcbereinander angeordneten Leiterplatten 62, 63 mit Kontaktteilen 18 kontaktiert werden k\u00f6nnen, die die gleiche Kontaktteil-H\u00f6he aufweisen. In Figur 3 ist eine alternative Ausf\u00fchrungsform des erfindungsgem\u00e4\u00dfen Testadaptersystems dargestellt, dass sich von den in Figuren 1 und 2 gezeigten Ausf\u00fchrungsformen insbesondere dadurch unterscheidet, dass die Pr\u00fcfeinrichtungs- Anschlusspunkte 8 bzw. Testnadel-Anschlusspunkte 7 elektrisch leitende Elemente 14 in Form von L\u00f6tstiften aufweisen. Die elektrisch leitenden Elemente 14 sind jeweils mit ihrem einen Ende mit der Verbindungsstruktur 9 der sie tragenden Leiterplatte 6l, 62, 63 verbunden, und bilden an ihrem freien Ende die Pr\u00fcfeinrichtungs-Anschlusspunkte 8 bzw. Testnadel- Anschlusspunkte 7. Dabei sind die elektrisch leitenden Elemente 14 durch die in die jeweils dar\u00fcberliegende bzw. darunterliegende Leiterplatte 61, 62, 63 eingebrachtenDurchbr\u00fcche 10U, 10L hindurchgef\u00fchrt und gegen die auf der jeweils dar\u00fcberliegenden bzw. darunterliegenden Leiterplatte 61, 62, 63 befindliche Verbindungsstruktur 9 isoliert.Somit f\u00fchren die elektrisch leitenden Elemente 14 die Pr\u00fcfeinrichtungs-Anschlusspunkte 8 bzw. die Testnadel-Anschlusspunkte 7 der sie tragendenLeiterplatte 61, 62, 63 durch die in die jeweils anderen Leiterplatten 61, 62, 63 eingebrachten Durchbr\u00fcche 10U, 1OL hindurch nach au\u00dfen. In dem gezeigten Beispiel ist f\u00fcr jeden Pr\u00fcfeinrichtungs-Anschlusspunkt 8 und f\u00fcr jeden Testnadel-Anschlusspunkt 7 ein elektrisch leitendes Element 14 vorgesehen, das jeweils nur mit der Verbindungsstruktur 9 der es tragenden Leiterplatte 61, 62, 63 elektrisch verbunden, und gegen die Verbindungsstruktur 9 auf den anderen Leiterplatten 61, 62, 63 isoliert ist. Gem\u00e4\u00df einer nicht gezeigten alternativen Ausf\u00fchrungsform k\u00f6nnen die elektrisch leitenden Elemente 14 jedoch auch beispielsweise nur f\u00fcr Pr\u00fcfeinrichtungs- Anschlusspunkte 8 oder nur f\u00fcr Testnadel-Anschlusspunkte 7 oder nur f\u00fcr innenliegende Anschlusspunkte vorgesehen sein. Vorteilhaft an dieser dritten Ausf\u00fchrungsform ist insbesondere, dass keine Wegunterschiede bei der Kontaktierung der Testnadel-Anschlusspunkte 7 durch die gefederten Kontakte 22 der Testnadeln 4 bzw. keine Wegunterschiede bei der Kontaktierung der Pr\u00fcfeinrichtungs-Anschlusspunkte 8 durch die gefederten Kontaktelemente 19 der Pr\u00fcfeinrichtung 3 ausgeglichen werden m\u00fcssen.","Export Citation":"Click for automatic bibliographygeneration","Filing Date":"01/28/2003","Foreign References":"63408932002-01-2245516751985-11-05DE19716945A11998-11-0561408302000-10-31","International Classes":"G01R1/073; (IPC1-7): G01R1/073","Inventors":"RAINER OTT (DE)","Publication Date":"08/07/2003","Title":"TEST ADAPTER SYSTEM FOR CONNECTING TEST NEEDLES OF A TEST ADAPTER TO A CONTROL DEVICE","View Patent Images":"Download PDF WO/2003/065056A1"},"WIPO Patent Application WO/2014/020883":{"Abstract":"A network test device according to the present invention comprises: an asynchronous process conversion unit (11) which reads in test code which describes a software test configuration, determines whether a portion is present in the test code which denotes an asynchronous process and is capable of conversion to a synchronous process, and converts the portion which is capable of conversion to the synchronous process to a synchronous method call; and an execution unit (12) which executes a software test based on the converted test code.","Application Number":"PCT/JP2013/004573","Assignee":"NEC CORP (JP)","Attorney, Agent or Firm":"IWAKABE, Fuyuki et al. (JP)Rock face Fuyuki (JP)","Export Citation":"Click for automatic bibliographygeneration","Filing Date":"07/29/2013","International Classes":"H04L12/24; G06F11/28; H04L12/70","Inventors":"TAKAMIYA YASUHITO (JP)","Other References":"YASUHITO TAKAMIYA ET AL.: \"Konna Yonaka ni OpenFlow de Network o Programming!\", TREMA-HEN DAI 9 KAI TEST FIRST DE AGILE NI, SOFTWAREDESIGN, 18 January 2012 (2012-01-18), pages 110 - 115TAKUTO WADA: \"Genba de Yakudatsu Jissen Knowhow Web Kaihatsu no Beshi Bekarazu Kiken na Cord\", KUSARU TEST, FUANTEI NA INFURA KARA NO DAKKYAKU CAPTER 2, TEST-HEN, vol. 63, 25 July 2011 (2011-07-25), pages 26 - 37YASUHITO TAKAMIYA ET AL.: \"Konna Yonaka ni OpenFlow de Network o Programming Trema-hen Dai 7 Kai Shin Series Shido!\", OPENFLOW-KAI NO RAILS KOTO TREMA NYUMON, SOFTWAREDESIGN, 18 November 2011 (2011-11-18), pages 104 - 109","Publication Date":"02/06/2014","Title":"NETWORK TEST DEVICE, NETWORK TEST METHOD, AND NETWORK TEST PROGRAM","View Patent Images":"Download PDF WO/2014/020883A1"}}]]
